---
title: "Choosing harmonies based on average maximum pairwise distance of distributions"
output:
  html_document:
    theme: united
    highlight: tango
    toc: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(readr)
library(gravitas)
library(tidyverse)
```

# Pointers

- A major result in the field of EVT is the probability density of the maximum or minimum can only be one of Weibull, Gumbel or Freschet distribution, independent of the underlying data or process. But the normalising constants vary depending on the underlying distribution of the variables. Hence to normalize appropriately, it is important to assume a distribution of distances in our case.

- Under broad conditions, the similarities that arise from any distribution $L^p$ norms - a class of commonly applied distance matrix from one feature vector to other vectors could be

  a) Normal: Pekalska and Duin assumed that Lp-distances between
feature vectors are normally distributed, if the feature values are independent, identically distributed, and have limited variance.  We can not assume that feature values are independent.(“The Dissimilarity Representation for Pattern Recognition | Series in Machine Perception and Artificial Intelligence.”   n.d. Accessed May 8, 2020.    https://www.worldscientific.com/worldscibooks/10.1142/5965.)  

  b) Gamma: Ferencz, Miller and Malik have considered the
Gamma distribution to model the L2-distances.
This is intuitive since if the reponse variable follows
Normal distribution, then $L_2$ norm distance measure which
is similar to taking squares of differences of Normal
variables would follow a Chi-Squared distribution, a special
case of Gamma distribution.(Ferencz, A., E. G. Learned-Miller, and J. Malik. 2005. “Building a Classification Cascade for Visual Identification from One Example.” In Tenth IEEE International Conference on Computer Vision (ICCV’05) Volume 1, 1:286–93 Vol. 1.)  
 
  c) Weibull: Weibull distributed, if feature vectors are
correlated and non-identically distributed.
(Burghouts, Gertjan, Arnold Smeulders, and Jan-Mark
Geusebroek. 2008. “The Distribution Family of Similarity
Distances.” In Advances in Neural Information Processing
Systems 20, edited by J. C. Platt, D. Koller, Y. Singer, and
S. T. Roweis, 201–8. Curran Associates, Inc.)

- For each of the cases, the norming constants are a function
of the paramters which have been estimated using method of moments.

 Norming constants are taken from Embrechts, Paul, Claudia   Klüppelberg, and Thomas Mikosch. 2013. Modelling Extremal Events: For Insurance and Finance. Springer Science & Business Media.

  a) **Normal**  
  $D_{k} \sim N(\mu, \sigma^2)$  
    *Normalising constants*:  
    $a_k = \mu − \sigma\Phi^{-1}(1/k) \quad \quad b_k = -\sigma/\Phi^{-1}(1/k)$  
    *Estimated parameters*:  
    $\hat{\mu}=\dfrac{1}{n}\sum\limits_{i=1}^n X_i \quad \quad \hat{\sigma^2}=\dfrac{1}{n}\sum\limits_{i=1}^n (X_i-\bar{X})^2$  
    $\hat{\Phi^{-1}(1/k)} =  (1 - \frac{1}{k})_{th}$ sample quantile
  
  b) **Gamma**  
  $D_{k} \sim \gamma(\alpha, \beta)$  
    *Normalising constants:*  
    $b_k = (\frac{1}{\beta} (ln n + (\alpha - 1)ln ln n - ln       \gamma(\alpha))  \quad \quad a_k = \frac{1}{\beta}$  
    *Estimated parameters:*  
    $\alpha = (\mu/s)^2 \quad \quad \beta = (s^2/\mu)$

 
  c)  **Weibull** 
  
\begin{equation}

f_D(d; \lambda, k) = \left\{ \begin{array}{cl}
    \frac{k}{\lambda}(\frac{d}{\lambda})^{k-1} e^{-(d/\lambda)^k} & \ ; \ d \geq 0 \\
    0 & \ ; \ d < 0 \end{array} \right. \
\end{equation}  
    *Normalising constants:*  
  $b_k = F^{-1}(1-1/n)  \quad \quad a_k = A(b_k)$, where $A(x)$ is an auxilliary function which can be chosen as $(1-F(x)/f(x))$.
  
  \begin{equation}
F(x) = 1 - e^{{-(\frac{d}{\lambda})}^k}
\end{equation}
    *Estimated parameters:*  
  $k = (\frac{\sigma}{\mu})^{-1.086} \quad \quad \lambda = \frac{\mu}{\Gamma(1+1/k)} \quad \quad \hat{\mu}=\dfrac{1}{n}\sum\limits_{i=1}^n D_i=\bar{D} \quad \quad \hat{\sigma^2}=\dfrac{1}{n-1}\sum\limits_{i=1}^n (X_i-\bar{D})^2$  
  


<!-- # Algorithm -->

<!--  1. Suppose $C_1$ and $C_2$ are two cyclic granularities such that $C_1$ maps index set to a set $\{A_1, A_2, A_3, \dots, A_I$\}, and $C_2$ maps index set to a set $\{B_1, B_2, B_3, \dots, B_J$\} and $v$ is the measured variable. Hence for each combination ($A_i$, $B_j$), we have s subset of the time series variable $v_{ij} \subseteq v$, $\forall i = {1, 2, \dots, I}$ and $\forall j = {1, 2, \dots, J}$ -->

<!--  2. There will be $J$ groups corresponding to each level $A_i$ of $C_1$. We compute the pairwise differences in distributions of these $J$ groups. Thus there will be  $k = \binom{J}{2}$ pairwise distances corresponding to each $A_i$. Let $D_1$,...,$D_k$ be these distances and let their maximum be $M_k$. -->

# Smart meter data

## Distances follow Weibull

```{r}
library(readr)
smart_weibull <- read_rds("data/smart_harmony_wb.rds")  %>% mutate(rank_weibull = row_number())
```


## Distances follow Gamma

 <!-- 3.1. Suppose the reponse variable follows Normal distribution. Then any distance measure which is similar to taking squares of differences of Normal variables would follow a Chi-Squared distribution, a special case of Gamma distribution. Hence if we proceed with the assumption that the $D_i$ distribution has Gamma distribution, then under EVT the maximum converges to Gumbel distribution and lim $P(M_k - b_k)/a_k)$ converges to a limiting Gumbel distribution where $b_k = (\frac{1}{\beta} (ln n + (\alpha - 1)ln ln n - ln \gamma(\alpha))$ and $a_k = \frac{1}{\beta}$. Here $\alpha$ and $\beta$ could be estimated using $(\mu/s)^2$ and $(s^2/\mu)$ respectively. -->

 <!-- 4.1. For each facet, we have a normalised variable using Step 3.1. We can take the maximum across all facets as the final mesasure. But this maximum is not normalized against the number of facet levels. Or we can take the mean (to be discussed). -->

```{r}
smart_gamma <- read_rds("data/smart_gamma.rds")  %>% mutate(rank_gamma = row_number())
```


## Distances follow Normal

<!--  3.3. Let $D_{k} \sim N(\mu, \sigma^2)$. Then for $a_k = \mu − \sigma\Phi^{-1}(1/k)$ and $b_k = -\sigma/\Phi^{-1}(1/k)$, we have we have $P(\frac{M_k - a_k}{b_k} \leq z) \xrightarrow{} G(z)$, where $G$ is the standard Gumbel distribution. So normalization could be done  using $\frac{M_k - a_k}{b_k}$, where $\Phi^{-1}(1/k)$ could be approximated by $(1 - \frac{1}{k})$ sample quantile and $\mu$ and $\sigma$ by sample mean and standard deviation.  -->

<!--  4.3. We have been able to normalize for the number of levels of x-axis variable using Step 3.2. Now  -->
<!-- $\forall A_i, \quad i \in \{1, 2, \dots, I\}$, we have a normalised variable each of which follows a standard Gumbel distribution. Now we need to combine these normalised variables across different facets in a way so that the number of facet levels do not play a role. For this we can take the mean, median or any quantiles of these normalised variables. But the median (and any quantiles) of these Gumbel distributions grow at the rate of (some power of) $log n$ with $n \xrightarrow{} \infty$. Hence, median($N_i$)/log($I$) could serve as the final measure. -->


```{r}
library(readr)
smart_normal <- read_rds("data/smart_harmony_norm.rds") %>% mutate(rank_normal = row_number())

library(readr)
smart_chi <-read_rds("data/smart_harmony_chisq.rds") %>% mutate(rank_chi = row_number())
```

```{r, echo = FALSE, eval = FALSE}
smart_meter10 %>%
  filter(customer_id %in% c(10017936)) %>%
  prob_plot("hour_day",
    "wknd_wday",
    response = "general_supply_kwh",
    plot_type = "quantile",
    symmetric = TRUE,
    quantile_prob = c(0.01, 0.1, 0.25, 0.5, 0.75, 0.9, 0.99)
  ) +
  scale_y_sqrt() +
  #ggtitle(" (b) Area quantile plot faceted by weekend-weekday") +
  ylab("electricity demand [KWh]") + xlab("hours of the day") + ggtitle("") + ylab("")+ 
  theme_minimal()
```



<!--  5. Steps 1 to 5 are repeated for every harmony pair and harmony pairs rearranged from highest to lowest MMPD (final measure). Harmony pair with higher MMPD would be more interesting as it would mean that the harmony pair exhibits more variations in distributions on an average between different levels of $C_2$. -->



## Version 1 (General - suggested by Rob)

 3.2. If the $D_i$ distribution has heavy tails, then under EVT the maximum converges to Frechet and lim $P(M_k / a_k)$ converges to a limiting distribution where $a_k$ = the $(1-\frac{1}{k})$ quantile of the $D_i$ distribution. So normalization could be done  using $M_k / a_k$.

 4.2. For each facet, we have a normalised variable using Step 3.2. We can take the maximum across all facets as the final mesasure. But this maximum is not normalized against the number of facet levels. Or we can take the mean (to be discussed).
 
```{r}
smart_general <- read_rds("data/smart_general.rds") %>% mutate(rank_general = row_number())

data_unite <- smart_chi %>% 
  left_join(smart_weibull, by = c("facet_variable", "x_variable", "facet_levels", "x_levels")) %>% 
   rename("MMPD_chisq" = "mean_max_variation.x", "MMPD_weibull" = "mean_max_variation.y") %>% 
    left_join(smart_gamma,  by = c("facet_variable", "x_variable", "facet_levels", "x_levels")) %>%  
  rename("MMPD_gamma" = "mean_max_variation") %>% 
  left_join(smart_normal,  by = c("facet_variable", "x_variable", "facet_levels", "x_levels")) %>% 
  rename("MMPD_normal" = "mean_max_variation") %>% 
   left_join(smart_general,  by = c("facet_variable", "x_variable", "facet_levels", "x_levels")) %>% 
  rename("MMPD_general" = "mean_max_variation") %>%  select(-c(facet_levels, x_levels)) 


data_unite %>% select(-c(MMPD_normal, MMPD_gamma, MMPD_weibull, MMPD_general, -MMPD_chisq)) %>% knitr::kable()
data_unite %>% select(-c(rank_normal, rank_gamma, rank_weibull, rank_general, rank_chi)) %>% knitr::kable()
```


<!-- ```{r, eval=FALSE, echo=FALSE} -->
<!-- read_rds("data/smart_harmony_ak.rds") -->
<!-- ``` -->

<!-- ```{r, eval = FALSE} -->
<!-- smart_meter10 %>% -->
<!--   filter(customer_id %in% c(10017936)) %>% -->
<!--   prob_plot("day_week", -->
<!--     "day_month", -->
<!--     response = "general_supply_kwh", -->
<!--     plot_type = "quantile", -->
<!--     symmetric = TRUE, -->
<!--     quantile_prob = c(0.01, 0.1, 0.25, 0.5, 0.75, 0.9, 0.99) -->
<!--   ) + -->
<!--   scale_y_sqrt() + -->
<!--   #ggtitle(" (b) Area quantile plot faceted by weekend-weekday") + -->
<!--   ylab("electricity demand [KWh]") + xlab("hours of the day") + ggtitle("") + ylab("")+  -->
<!--   theme_minimal() -->
<!-- ``` -->


<!-- ## Version 4 (old benchmark) -->

<!--  3.4. For each $i \in \{1, 2, \dots, I\}$, the maximum pairwise distance could be chosen from  $\binom{I}{2}$ distances using $D_{i}$ = max($d_{jl}$)/$J$(max($d_{jl}$) - min($d_{jl}$)) $\forall j, l = {1, 2, \dots, J}$. -->

<!--  4.4. Mean maximum pairwise distance (MMPD) over $i = {1, 2, \dots, I}$ is computed by -->
<!-- $MMPD = (1/I)\sum_{i=1}^{l}{D_{i}}$. -->


<!-- ```{r, eval = FALSE, echo=FALSE} -->
<!-- library(readr) -->
<!-- read_rds("data/smart_harmony_n.rds") %>% knitr::kable() -->
<!-- ``` -->

<!-- ```{r, echo = FALSE, eval = FALSE} -->
<!-- smart_meter10 %>% -->
<!--   filter(customer_id %in% c(10017936)) %>% -->
<!--   prob_plot("week_month", -->
<!--     "wknd_wday", -->
<!--     response = "general_supply_kwh", -->
<!--     plot_type = "quantile", -->
<!--     symmetric = TRUE, -->
<!--     quantile_prob = c(0.01, 0.1, 0.25, 0.5, 0.75, 0.9, 0.99) -->
<!--   ) + -->
<!--   scale_y_sqrt() + -->
<!--   #ggtitle(" (b) Area quantile plot faceted by weekend-weekday") + -->
<!--   ylab("electricity demand [KWh]") + xlab("hours of the day") + ggtitle("") + ylab("")+  -->
<!--   theme_minimal() -->
<!-- ``` -->


# Cricket data


## Distances follow Weibull
```{r}
cric_weibull <- read_rds("data/ smart_cric_weibull.rds")%>% mutate(rank_weibull = row_number())
```

## Distances follow Gamma

```{r}
library(readr)
cric_gamma <-read_rds("data/ smart_cric_gamma.rds") %>% mutate(rank_gamma = row_number())
```

## Distances follow Normal 
```{r}
cric_normal <-read_rds("data/ smart_cric_normal.rds")%>% mutate(rank_normal = row_number())
```

## Distances follow general 
```{r}
cric_general <- read_rds("data/ smart_cric_general.rds")%>% mutate(rank_general = row_number())


data_unite <- smart_normal %>% 
  left_join(smart_gamma, by = c("facet_variable", "x_variable", "facet_levels", "x_levels")) %>%
  rename("MMPD_normal" = "mean_max_variation.x", "MMPD_gamma" = "mean_max_variation.y") %>% 
    left_join(smart_weibull,  by = c("facet_variable", "x_variable", "facet_levels", "x_levels")) %>%  rename("MMPD_weibull" = "mean_max_variation") %>% 
  left_join(smart_general,  by = c("facet_variable", "x_variable", "facet_levels", "x_levels")) %>%  rename("MMPD_general" = "mean_max_variation") %>% 
  select(-c(facet_levels, x_levels))


data_unite %>% select(-c(MMPD_normal, MMPD_gamma, MMPD_weibull, MMPD_general))
data_unite %>% select(-c(rank_normal, rank_gamma, rank_weibull, rank_general))
```