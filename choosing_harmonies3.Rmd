---
title: Screening harmonies
authors:
- name: Sayani Gupta
  affiliation: Department of Econometrics and Business Statistics, Monash University
  email: Sayani.Gupta@monash.edu

bibliography: bibliography.bib
output:
  bookdown::pdf_book:
    #base_format: rticles::asa_article
    fig_height: 5
    fig_width: 8
    fig_caption: yes
    dev: "pdf"
---

```{r initial, echo = FALSE, cache = FALSE, include = FALSE}
options("knitr.graphics.auto_pdf" = TRUE)
library(knitr)
library(tidyverse)
library(lubridate)
library(lvplot)
library(ggridges)
library(viridis)
library(tsibble)
library(gravitas)
library(ggpubr)
opts_chunk$set(
  echo = FALSE, warning = FALSE, message = FALSE, comment = "#>",
  fig.path = "figure/", fig.align = "center", fig.show = "hold",
  cache = FALSE, cache.path = "cache/",
  out.width = ifelse(is_html_output(), "100%", "\\textwidth")
)
knitr::opts_knit$set(root.dir = here::here())
```

```{r external, include = FALSE}
# read_chunk('scripts/main.R')
```

```{r load}

```

# Idea

Even after excluding clashes, the list of harmonies left could be large and overwhelming for human consumption. Hence, there is a need to rank the  harmonies basis how well they capture the variation in the measured variable and additionally reduce the number of harmonies for further exploration/visualization. Gestalt theory suggests that when items are placed in close proximity, people assume that they are in the same group because they are close to one another and apart from other groups. Hence, displays that capture more variation within different categories in the same group would be important to bring out different patterns of the data. Thus the idea here is to rate a harmony pair higher if this variation between different levels of the x-axis variable is higher on an average across all levels of facet variables.


# Computing distances

One of the potential ways to evaluate this variation is by computing the pairwise distances between the distributions of the measured variable. We do this through Jensen-Shannon divergence which is based on Kullback-Leibler divergence. Probability distributions are represented through sample quantiles instead of kernel density estimate so that there is minimal dependency on selecting kernel or bandwidth.

 We shall call this measure of variation as  Median Maximum Pairwise Distances (MMPD)

# Normalize distances

The harmony pairs could be arranged from highest to lowest average maximum pairwise distances across different levels of the harmonies. But maximum is not robust to the number of levels and is higher for harmonies with higher levels. Thus these maximum pairwise distances need to be normalized for different harmonies in a way that eliminates the effect of different levels. The Fisher–Tippett–Gnedenko theorem in the field of Extreme Value Theory states that the maximum of a sample of iid random variables after proper re- normalization can converge in distribution to only one of Weibull, Gumbel or Freschet distribution, independent of the underlying data or process. The normalizing constants, however, vary depending on the underlying distribution and hence it is important to assume a distribution of distances in our case.

## Theoretical evidence

@Menendez1997-in and @Grosse2002-ex provide studies of the statistical properties of the Jensen-Shannon divergences and suggest that the theoretical asymptotic distribution of Jensen-Shannon divergence converges to a Chi-squared distribution. Let $p^{(1)} \equiv (p_1^{(1)}, p_2^{(1)}, \dots, p_k^{(1)})$ and $p^{(2)} \equiv (p_1^{(2)}, p_1^{(2)}, \dots, p_k^{(2)})$ denote two probability distributions, where $k$ is the number of components of the probability vector p. Then 2N(ln2)D is known to converge to {$\chi^2$} distribution with degrees of freedom = (k - 1) and 

$D[p^{(1)}, p^{(2)}] = H((p^{(1)} + p^{(2)})/2)  - H(p^{(1)}) - H(p^{(2)})$, $H_{(p)} = \sum_{i = 1}^{k} p_ilog_2p_i$ and N is the total number of events.

## Empirical evidence

However, since we are dealing with small finite samples, a more appropriate approach would be to look at the distribution of the samples through histogram, density plots or using QQ-plot to see how well the empirical quantiles match the theoretical quantiles. The QQ plots of four harmony pairs are plotted below. It could be seen that Chi-square distribution serves as a pretty good fit to the data (specially in the extreme right tail).
 
```{r}
library(tsibbledata)
library(ggplot2)
library(tsibble)
library(lvplot)
library(dplyr)
library(gravitas)
library(purrr)
library(magrittr)
sm <- smart_meter10 %>%
filter(customer_id %in% c(10017936))
.data = sm
gran1 = "wknd_wday"
gran2 = "hour_day"
response  = "general_supply_kwh"
```

### Distribution fitting of distances for the harmony pair (weekend/weekday, hour-of-day)

```{r}
.data %>% qqplot_distance(gran1 = "wknd_wday", gran2 = "hour_day", response = "general_supply_kwh")
```

### Distribution fitting of distances for the harmony pair (day-of-week, hour-of-day)

```{r}
.data %>% qqplot_distance(gran1 = "day_week", gran2 = "hour_day", response = "general_supply_kwh")
```


### Distribution fitting of distances for the harmony pair (hour-of-day, week-of-month)

```{r}
.data %>% qqplot_distance(gran1 = "hour_day", gran2 = "week_month", response = "general_supply_kwh")
```


### Distribution fitting of distances for the harmony pair (day-of-month, day-of-week)

```{r}
.data %>% qqplot_distance(gran1 = "day_month", gran2 = "day_week", response = "general_supply_kwh")
```

# Estimating parameters

Currently, MME is used. But MASS::fitdistr() and package fitdistrplus also provide methods to estimate parameters through MLE. WIP.

# Choose thresholds for harmonies

Threholds could be chosen for distances (chi-squared) or maximum distance (Gumbel distribution). 

Critical values of the Chi-squared statistic could be obtained for appropriate degrees of freedom. 

Chi-squared statistic: And test values less than critical value would imply that the distances are not significantly different from zero , implying distributions are similar. If distributions are similar most times, then the plot is not interesting. Hence, all pairs for which most of the pairwise distances are significantly different from zero would only be included in the harmony rank table.

Gumbel statistic: The test decides if the sample of maximum distance is from Gumbel or not. If it is from Gumbel, the value of the test statistic should be ideally zero. And we want to take all pairs for which the statistic is significantly different from zero. So we choose test values greater than the Gumbel critical value at 5% significance.

# Results


##  Smart meter data

### Maximum distance between levels of x-axis variable and median across levels of facet variable

```{r}
library(readr)
smart_weibull <- read_rds("data/reverse_smart_weibull.rds")  %>% mutate(rank_weibull = row_number())

smart_gamma <- read_rds("data/reverse_smart_gamma.rds")  %>% mutate(rank_gamma = row_number())

smart_normal <- read_rds("data/reverse_smart_normal.rds") %>% mutate(rank_normal = row_number())

smart_chi <-read_rds("data/reverse_smart_chisq.rds") %>% mutate(rank_chi = row_number())
smart_general <- read_rds("data/reverse_smart_general.rds") %>% mutate(rank_general = row_number())

data_unite <- smart_chi %>% 
  left_join(smart_weibull, by = c("facet_variable", "x_variable", "facet_levels", "x_levels")) %>% 
   rename("chisq" = "mean_max_variation.x", "weibull" = "mean_max_variation.y") %>% 
    left_join(smart_gamma,  by = c("facet_variable", "x_variable", "facet_levels", "x_levels")) %>%  
  rename("gamma" = "mean_max_variation") %>% 
  left_join(smart_normal,  by = c("facet_variable", "x_variable", "facet_levels", "x_levels")) %>% 
  rename("normal" = "mean_max_variation") %>% 
   left_join(smart_general,  by = c("facet_variable", "x_variable", "facet_levels", "x_levels")) %>% 
  rename("general" = "mean_max_variation") 
```


```{r}
data_unite %>% 
  select(-c(normal, gamma, weibull, general, chisq)) %>%
  dplyr::rename("normal"  = "rank_normal",
         "gamma"  = "rank_gamma",
         "weibull"  = "rank_weibull",
         "general"  = "rank_general",
         "chi"  = "rank_chi",
         "f_L" = "facet_levels",
         "x_L" = "x_levels") %>% 
  knitr::kable(format = "latex")
  
  threshold <- read_rds("data/smart_harmony_threshold.rds") %>% 
               mutate(thresval = "select") %>% 
    select(facet_variable, x_variable, thresval)

data_unite %>% 
  select(-c(normal, gamma, weibull, general, chisq)) %>%
  left_join(threshold, 
            by = c("facet_variable", "x_variable"))%>%
  select(-facet_levels, -x_levels) %>% 
    knitr::kable(format = "latex")



# data_unite %>%
#   select(-c(rank_normal, rank_gamma, rank_weibull, rank_general, rank_chi)) %>%
#   filter()
#   knitr::kable()
```



### Maximum distance between levels of facet variable and median across levels of x-axis variable


```{r}
library(readr)
smart_weibull <- read_rds("data/smart_harmony_wb.rds")  %>% mutate(rank_weibull = row_number())

smart_gamma <- read_rds("data/smart_gamma.rds")  %>% mutate(rank_gamma = row_number())

smart_normal <- read_rds("data/smart_harmony_norm.rds") %>% mutate(rank_normal = row_number())

smart_chi <-read_rds("data/smart_harmony_chisq.rds") %>% mutate(rank_chi = row_number())
smart_general <- read_rds("data/smart_general.rds") %>% mutate(rank_general = row_number())

data_unite <- smart_chi %>% 
  left_join(smart_weibull, by = c("facet_variable", "x_variable", "facet_levels", "x_levels")) %>% 
   rename("chisq" = "mean_max_variation.x", "weibull" = "mean_max_variation.y") %>% 
    left_join(smart_gamma,  by = c("facet_variable", "x_variable", "facet_levels", "x_levels")) %>%  
  rename("gamma" = "mean_max_variation") %>% 
  left_join(smart_normal,  by = c("facet_variable", "x_variable", "facet_levels", "x_levels")) %>% 
  rename("normal" = "mean_max_variation") %>% 
   left_join(smart_general,  by = c("facet_variable", "x_variable", "facet_levels", "x_levels")) %>% 
  rename("general" = "mean_max_variation") 

```


```{r}
data_unite %>% 
  select(-c(normal, gamma, weibull, general, chisq)) %>% 
  dplyr::rename("normal"  = "rank_normal",
         "gamma"  = "rank_gamma",
         "weibull"  = "rank_weibull",
         "general"  = "rank_general",
         "chi"  = "rank_chi") %>% 
  knitr::kable(format = "latex")

# data_unite %>%
#   select(-c(rank_normal, rank_gamma, rank_weibull, rank_general, rank_chi)) %>% 
#   knitr::kable()
```


## Graphical evidence

```{r, echo = FALSE}
p1 <- smart_meter10 %>%
  filter(customer_id %in% c(10017936)) %>%
  prob_plot("wknd_wday",
    "hour_day",
    response = "general_supply_kwh",
    plot_type = "boxplot",
    #symmetric = TRUE,
    #quantile_prob = c(0.01, 0.1, 0.25, 0.5, 0.75, 0.9, 0.99)
  ) +
  scale_y_sqrt() +
  #ggtitle(" (b) Area quantile plot faceted by weekend-weekday") +
  ylab("electricity demand [KWh]") + xlab("hours of the day") + ggtitle("") + ylab("")+ 
  theme_minimal() + 
  ggtitle("Rank 1 Section 6.1.1")  + 
  scale_x_discrete(breaks = seq(0, 23, 5))


p2 <- smart_meter10 %>%
  filter(customer_id %in% c(10017936)) %>%
  prob_plot("hour_day",
    "wknd_wday",
    response = "general_supply_kwh",
    plot_type = "boxplot",
    #symmetric = TRUE,
    #quantile_prob = c(0.01, 0.1, 0.25, 0.5, 0.75, 0.9, 0.99)
  ) +
  scale_y_sqrt() +
  #ggtitle(" (b) Area quantile plot faceted by weekend-weekday") +
  ylab("electricity demand [KWh]") + xlab("") + ggtitle("") + ylab("")+ 
  theme_minimal() + 
  ggtitle("Rank 1 Section 6.1.2") + scale_x_discrete(labels = c('wday','wend'))

```

```{r, echo = FALSE}
p3 <- smart_meter10 %>%
  filter(customer_id %in% c(10017936)) %>%
  prob_plot("week_month",
    "hour_day",
    response = "general_supply_kwh",
    plot_type = "boxplot",
    #symmetric = TRUE,
    #quantile_prob = c(0.01, 0.1, 0.25, 0.5, 0.75, 0.9, 0.99)
  ) +
  scale_y_sqrt() +
  #ggtitle(" (b) Area quantile plot faceted by weekend-weekday") +
  ylab("electricity demand [KWh]") + xlab("hours of the day") + ggtitle("") + ylab("")+ 
  theme_minimal() + 
  ggtitle("Rank 2 Section 6.1.2") + 
  scale_x_discrete(breaks = seq(0, 23, 5))

p4 <- smart_meter10 %>%
  filter(customer_id %in% c(10017936)) %>%
  prob_plot("hour_day",
    "week_month",
    response = "general_supply_kwh",
    plot_type = "boxplot",
    #symmetric = TRUE,
    #quantile_prob = c(0.01, 0.1, 0.25, 0.5, 0.75, 0.9, 0.99)
  ) +
  scale_y_sqrt() +
  #ggtitle(" (b) Area quantile plot faceted by weekend-weekday") +
  ylab("electricity demand [KWh]") + xlab("week of the month") + ggtitle("") + ylab("")+ 
  theme_minimal()  + 
  ggtitle("Rank 2 Section 6.1.2")


ggpubr::ggarrange(p1, p2,  ncol = 2)

ggpubr::ggarrange(p3, p4,  ncol = 2)
```


```{r}
prob_plot(.data,  gran1 = "day_week", gran2 = "day_month", plot_type = "boxplot")

prob_plot(.data,  gran1 = "wknd_wday", gran2 = "day_month", plot_type = "boxplot")

prob_plot(.data,  gran1 = "wknd_wday", gran2 = "hour_day", plot_type = "boxplot")


```

## cricket data


```{r}
cricket_data <- read_rds("data/cricket_data.rds")

  hierarchy_model <- tibble::tibble(
      units = c("index", "over", "inning", "match"),
      convert_fct = c(1, 20, 2, 1))

hierarchy_tbl <- hierarchy_model

response <- "runs_per_over"

harmonies_cric <- cricket_data %>% harmony(lgran = "over", ugran = "match", filter_in = c("lag_field", "over"), hierarchy_tbl = hierarchy_model)



```


### Distribution fitting of distances for the harmony pair (lag_field, over)

```{r}
cricket_data  %>% qqplot_distance(gran1 = "lag_field", gran2 = "over", response = "runs_per_over", hierarchy_tbl = hierarchy_model)
```



```{r}
cric_weibull <- read_rds("data/cric_weibull.rds") %>% mutate(rank_weibull = row_number())

cric_gamma <-read_rds("data/cric_gamma.rds") %>% mutate(rank_gamma = row_number())


cric_normal <-read_rds("data/cric_normal.rds")%>% mutate(rank_normal = row_number())


cric_general <- read_rds("data/cric_general.rds")%>% mutate(rank_general = row_number())

cric_chisq <- read_rds("data/cric_chisq.rds")%>% mutate(rank_chisq = row_number())


data_unite <- cric_chisq %>% 
  left_join(cric_weibull, by = c("facet_variable", "x_variable", "facet_levels", "x_levels")) %>% 
   rename("chisq" = "mean_max_variation.x", "weibull" = "mean_max_variation.y") %>% 
    left_join(cric_gamma,  by = c("facet_variable", "x_variable", "facet_levels", "x_levels")) %>%  
  rename("gamma" = "mean_max_variation") %>% 
  left_join(cric_normal,  by = c("facet_variable", "x_variable", "facet_levels", "x_levels")) %>% 
  rename("normal" = "mean_max_variation") %>% 
   left_join(cric_general,  by = c("facet_variable", "x_variable", "facet_levels", "x_levels")) %>% 
  rename("general" = "mean_max_variation") 
```

```{r}
data_unite %>% 
  select(-c(normal, gamma, weibull, general, chisq)) %>%
  dplyr::rename("normal"  = "rank_normal",
         "gamma"  = "rank_gamma",
         "weibull"  = "rank_weibull",
         "general"  = "rank_general",
         "chi"  = "rank_chisq") %>% 
  knitr::kable(format = "latex")

# data_unite %>%
#   select(-c(rank_normal, rank_gamma, rank_weibull, rank_general, rank_chi)) %>% 
#   knitr::kable()
```



### Maximum distance between levels of facet variable and median across levels of x-axis variable

```{r}
cric_weibull <- read_rds("data/ smart_cric_weibull.rds") %>% mutate(rank_weibull = row_number())

cric_gamma <-read_rds("data/ smart_cric_gamma.rds") %>% mutate(rank_gamma = row_number())


cric_normal <-read_rds("data/ smart_cric_normal.rds")%>% mutate(rank_normal = row_number())


cric_general <- read_rds("data/ smart_cric_general.rds")%>% mutate(rank_general = row_number())

cric_chisq <- read_rds("data/smart_cric_chisq.rds")%>% mutate(rank_chisq = row_number())

data_unite <- cric_chisq %>% 
  left_join(cric_weibull, by = c("facet_variable", "x_variable", "facet_levels", "x_levels")) %>% 
   rename("chisq" = "mean_max_variation.x", "weibull" = "mean_max_variation.y") %>% 
    left_join(cric_gamma,  by = c("facet_variable", "x_variable", "facet_levels", "x_levels")) %>%  
  rename("gamma" = "mean_max_variation") %>% 
  left_join(cric_normal,  by = c("facet_variable", "x_variable", "facet_levels", "x_levels")) %>% 
  rename("normal" = "mean_max_variation") %>% 
   left_join(cric_general,  by = c("facet_variable", "x_variable", "facet_levels", "x_levels")) %>% 
  rename("general" = "mean_max_variation") 
```

```{r}
data_unite %>% 
  select(-c(normal, gamma, weibull, general, chisq)) %>%
  dplyr::rename("normal"  = "rank_normal",
         "gamma"  = "rank_gamma",
         "weibull"  = "rank_weibull",
         "general"  = "rank_general",
         "chi"  = "rank_chisq") %>% 
  knitr::kable(format = "latex")

# data_unite %>%
#   select(-c(rank_normal, rank_gamma, rank_weibull, rank_general, rank_chi)) %>% 
#   knitr::kable()
```


```{r}
cricket_data <- read_rds("data/cricket_data.rds")
cricket_data %>%
  filter(over!=1) %>%
  prob_plot("over", "lag_field",
  hierarchy_model,
  response = "run_rate",
  plot_type = "violin",
  symmetric = FALSE,
 quantile_prob = c(0.25, 0.5, 0.75)) +
   #ggtitle("(b) Runs per over across overs faceted by number of wickets in previous over") +
  ylab("runs per over")  +
  xlab("number of wickets in previous over") +
  ggtitle("b") +
   theme(plot.title = element_text(face = "bold")) +  theme_minimal()
```


# Bibliography

```{r write-bib, eval = FALSE}
write_bib(c("dplyr", "tidyr", "tsibble", "magrittr", "rlang", "gravitas", "knitr", "rmarkdown"), file = "rpkgs.bib")
```
