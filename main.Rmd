---
title: Choosing and rating harmonies
authors:
- name: Sayani Gupta
  affiliation: Department of Econometrics and Business Statistics, Monash University
  email: Sayani.Gupta@monash.edu

bibliography: bibliography.bib
output:
  bookdown::pdf_book:
    #base_format: rticles::asa_article
    fig_height: 5
    fig_width: 8
    fig_caption: yes
    dev: "pdf"
---

```{r initial, echo = FALSE, cache = FALSE, include = FALSE}
options("knitr.graphics.auto_pdf" = TRUE)
library(knitr)
library(tidyverse)
library(lubridate)
library(lvplot)
library(ggridges)
library(viridis)
library(tsibble)
library(gravitas)
library(ggpubr)
library(readr)

opts_chunk$set(
  echo = FALSE, warning = FALSE, message = FALSE, comment = "#>",
  fig.path = "figure/", fig.align = "center", fig.show = "hold",
  cache = TRUE, cache.path = "cache/",
  out.width = ifelse(is_html_output(), "100%", "\\textwidth")
)
knitr::opts_knit$set(root.dir = here::here())
read_chunk('main.R')
```

```{r external, include = FALSE}

```

```{r load}

```

```{r rank_harmony}

```

```{r global_threshold}

```

```{r}
set.seed(321)
```


# Introduction

Even after excluding clashes, the list of harmonies left could be large and overwhelming for human consumption. Hence, there is a need to rank the harmonies basis how well they capture the variation in the measured variable and additionally reduce the number of harmonies for further exploration/visualization. Assuming a numeric response variable, our graphics are displays of distributions compared across combinations of categorical variables, one placed at x-axis and the other on the facet. Gestalt theory suggests that when items are placed in close proximity, people assume that they are in the same group because they are close to one another and apart from other groups. Hence, displays that capture more variation within different categories in the same group would be important to bring out different patterns of the data. Here, we have two main objectives:

- To choose harmonies for which distributions of categories are significantly different 
- To rank the selected harmonies from highest to lowest variation in the distribution of their categories. The idea here is to rate a harmony pair higher if this variation between different levels of the x-axis variable is higher on an average across all levels of facet variables.

# A new test statistic

## Distance between distributions

One of the potential ways to evaluate this variation is by computing the pairwise distances between the distributions of the measured variable. We do this through Jensen-Shannon distance which is based on Kullback-Leibler divergence.

The Jensen-Shanon distance between two probability distribution $p_1$ and $p_2$ is given by $$d = [D(p_1, r) + D(p_2, r)]/2 \quad where \quad r = (p_1 + p_2)/2$$ where,
$$D(p_1,p_2) = \int^{\infty}_{-\infty}p_1(x)log\frac{p_1(x)}{p_2(x)}\,dx$$ is the Kullback-Leibler divergence between $p_1$ and $p_2$. Probability distributions are estimated through quantiles instead of kernel density so that there is minimal dependency on selecting kernel or bandwidth. 

We call this measure of variation as  Median Maximum Pairwise Distances (MMPD).

## Normalize distances

The harmony pairs could be arranged from highest to lowest average maximum pairwise distances across different levels of the harmonies. But maximum is not robust to the number of levels and is higher for harmonies with higher levels. Thus these maximum pairwise distances need to be normalized for different harmonies in a way that eliminates the effect of different levels. The Fisher–Tippett–Gnedenko theorem in the field of Extreme Value Theory states that the maximum of a sample of iid random variables after proper re- normalization can converge in distribution to only one of Weibull, Gumbel or Freschet distribution, independent of the underlying data or process.

More formally, $d_{1},d_{2}\ldots ,d_{n}$ be a sequence of independent and identically-distributed pairwise distances and $M_{n}=\max\{d_{1},\ldots ,d_{n}\}$. Then Fisher–Tippett–Gnedenko theorem [@De_Haan2007-yx] suggests that if a sequence of pairs of real numbers $(a_{n}, b_{n})$ exists such that each $a_{n}>0$ and $\lim _{{m\to \infty }}P\left({\frac  {M_{n}-b_{n}}{a_{n}}}\leq x\right)=F(x)$, where $F$ is a non-degenerate distribution function, then the limit distribution $F$ belongs to either the Gumbel, Fréchet or Weibull family. The normalizing constants $(a_{n}, b_{n})$ vary depending on the underlying distribution of the pairwise distances. Hence to normalize appropriately, it is important to assume a distribution of these distances. 

## Distribution of distances

### Theoretical evidence

JS distances are distributed as chi-squared with $m$ df where we discretize the continuous distribution with $m$ discrete values. Taking sample percentiles to approximate the integral would mean taking $m = 99$.
With large $m$, chi-squared is asymptotically normal by the CLT. Thus, by CLT, ${\chi^2}_{m} \tilde{} N(m, 2m)$, which would depend on the number of discretization used to approximate the continuous distribution. Then $b_n = 1-1/n$ quantile of the normal distribution and $a_n = 1/[n*\phi(b_n)]$ where $\phi$ is the normal density function. $n$ is the number of pairwise comparisons being made.

### Empirical evidence

Distribution of JS distances is assumed to be normal but the mean and variance are estimated from the sample, rather than deducing it from the number of discretization used to approximate the continuous distribution.

## Algorithm

\noindent The algorithm employed for computing MMPD is summarized as follows:
<!-- Algorithm -->

<!-- 1. Suppose $C_i$ and $C_2$ are two cyclic granularities such that $C_i$ maps index set to a set $\{A_1, A_2, A_3, \dots, A_l$\}, and $C_2$ maps index set to a set $\{B_1, B_2, B_3, \dots, B_m$\} and $v$ is the measured variable. Hence for each combination ($A_k$, $B_l$), we have the time series variable $v_{ij} \subseteq v$, $\forall i = {1, 2, \dots, l}$ and $\forall j = {1, 2, \dots, m}$ -->

- **Input:** Data corresponding to all harmony pairs, i.e., data sets of the form $(C_i, C_j, v)$ 
$\forall i, j \in N_C$  
- **Output:** MMPD (Median Maximum Pairwise Distances) measuring the average variation across different levels of $C_i$ and $C_j$ $\forall i, j \in N_C$  

1. Fix harmony pair $(C_i, C_j)$.

2. Fix $k$. Then there are $L$ groups corresponding to level $A_k$ of $C_i$.

3. Compute  $m = \binom{L}{2}$ pairwise distances between distributions of $L$ unordered levels and $m = L-1$ pairwise distances for $L$ ordered categories.

4. Identify maximum within the $m$ computed distances.

5. Compute normalized maximum distance ($NM$) using appropriate norming constants.
<!--so that the distribution of the normalized maximum converges to a Gumbel distribution as $m\rightarrow\infty$.-->


6. Use Steps 1-5 to compute normalized maximum distance for $\forall k \in  \{1, 2, \ldots, K\}$.

7. Compute MMPD = median $(NM_1, NM_2, \dots, NM_K)$/log($K$).

8. Repeat Steps 1 to 7 for all harmony pairs.

### Interpreting the test statistic

# The statistical test

## Algorithm for threshold 

**Assumption:** random permutation without considering ordering 
(global)

1. Given the data; $\{v_t: t=0, 1, 2, \dots, T-1\}$, the MMPD is computed and is represented by $MMPD_{obs}$.

2. From the original sequence a random permutation is obtained: $\{v_t^*: t=0, 1, 2, \dots, T-1\}$.

3. MMPD is computed for all random permutation of the data and is represented by $MMPD_{sample}$.

4.  Steps (2) and (3) are repeated a large number
of times M (e.g. 1000).

5. For each permutation, one $MMPD_{sample}$ value is obtained.

6. $95^{th}$ percentile of this $MMPD_{sample}$ distribution is computed and stored in $MMPD_{threshold}$.

7. If  $MMPD_{obs}> MMPD_{threshold}$, harmony pairs are accepted. Only one threshold for all harmony pairs.

Pros: Considering thresholds global for all harmony pairs would imply less computation time.

Cons: Only one threshold for all harmony pairs means we are assuming distribution of all harmonies pairs are similar, which might not be the case.But nevertheless, it is a good benchmark.


```{r, eval = FALSE, echo = FALSE}
smart_harmony <-read_rds("data/smart_harmony_nonst.rds")
smart_harmony
```



```{r smart_harmony,eval = FALSE, echo = FALSE}

sm <- smart_meter10 %>% dplyr::filter(customer_id %in% c("10017936"))

harmonies <- sm %>% 
  harmony(ugran = "month",
          filter_in = "wknd_wday",
          filter_out = c("hhour", "fortnight"))


harmony_tbl =  harmonies

smart_harmony <- sm %>% 
  rank_harmony(harmony_tbl = harmonies,
               response = "general_supply_kwh", 
               dist_ordered = TRUE)

smart_harmony %>% 
  mutate(MMPD = round(MMPD, 3), max_pd = round(max_pd, 3)) %>% 
  mutate(rankn = row_number()) %>%
  rename("rankun" = "r") %>% kable()
```


## Level and power

To estimate the sampling distribution of the test statistic we need many samples generated under the null hypothesis. If the null hypothesis is true, changing the exposure would have no effect on the outcome. By randomly shuffling the exposures we can make up as many data sets as we like. If the null hypothesis is true the shuffled data sets should look like the real data, otherwise they should look different from the
real data. The ranking of the real test statistic among the shuffled test statistics gives a p-value.

<!-- Consider two cyclic granularities $A$ and $B$ with $2$ and $3$categories. Thus, the harmony table consisting of all possible harmony pairs (assuming all pairs are harmonies), would look like the following: -->

```{r harmony_min}
# harmonies <- tibble::tibble(facet_variable = c("A", "B", "A", "C", "B", "C"),
#                             x_variable  = c("B","A", "C", "A", "C", "B"),
#                             facet_levels = c(2, 3, 2, 4, 3, 4),
#                             x_levels = c(3, 2, 4, 2, 4, 3))
# 
# harmonies <- tibble::tibble(facet_variable = c("A", "B"),
#                             x_variable  = c("B","A"),
#                             facet_levels = c(2, 3),
#                             x_levels = c(3, 2))
#                             
# harmonies %>% knitr::kable()
```

<!-- The output table has the value of MMPD (normalized median maximum pairwise distances), gt_MMPD(global threshold of MMPD indicator). -->

### Scenario 1: Simulated same normal distributions for all combinations of categories for all harmony pairs.

Failure to reject the null hypothesis when there is in fact no significant effect.


```{r samenull_2by4}

```

*Conclusion*: The test does not select harmony pairs when distributions of categories are same


### Scenario 2: Simulated different distributions for all combinations of categories for harmony pairs for few levels.



```{r diffnull_2by4}

```


*Conclusion*: The test select the harmony pair for which distribution of x-axis categories are significantly different


### Scenario 3: Simulated different distributions for all combinations of categories for all harmony pairs with many levels.


```{r diffnull_7by11}
```

*Conclusion*: The test indicates that both harmony pairs do not have significant variation.


### Scenario 4: Simulated different distributions for all combinations of categories for all harmony pairs with many levels - very different distribution across x-axis


```{r diffnull_7by11normal}
```

*Conclusion*: The test indicates that only the first harmony pair has significant variation.


### Scenario 5: Simulated different distributions for all combinations of categories for all harmony pairs with many levels - very different distribution across facets


```{r diffnull_7by11normal2}
```


<!-- *Conclusion*:  -->



<!-- ## Scenario 4: Cumulative 3 levels with 2, 7 and 11 and testing level and power -->

<!-- ```{r samenull_3levels} -->

<!-- ``` -->


<!-- *Conclusion*: With 3 levels the test incorrectly chooses 1 harmony pair with similar distribution. The harmony pair which is displayed. -->

<!-- <!-- ```{r diffnull_3levels} --> -->

<!-- <!-- ``` --> -->

<!-- *Conclusion*: The test with MMPD selects just one pair, as opposed to the test with maximum. This needs to be checked against what we expect from the test. The harmony pairs which are selected (either through MMPD or maximum) are displayed. -->


<!-- # ```{r} -->
<!-- # harmonies <- tibble::tibble(facet_variable = c("A", "B"),x_variable  = c("B","A"), facet_levels = c(2, 3),x_levels = c(3, 2)) -->
<!-- #  -->
<!-- # har1 <- harmonies[1,] -->
<!-- #  -->
<!-- # sim_dist1 = c(rep(distributional::dist_normal(mu = 10, sigma = 5),2),rep(distributional::dist_exponential(10),2), rep(distributional::dist_weibull(0.5, 2),2)) -->
<!-- #  -->
<!-- # data1 <- sim_distharmony1(har1, sim_dist = sim_dist1) -->
<!-- # data1 -->
<!-- #  -->
<!-- # data1 %>% unnest(sim_dist) %>% -->
<!-- #   ggplot(aes(x = Var2, y = sim_dist)) + -->
<!-- #   facet_wrap(~Var1) + geom_boxplot() + ggtitle("Same distribution 2 by 3") -->
<!-- #  -->
<!-- # response = "sim_dist" -->
<!-- #  -->
<!-- # MMPD_distribution <- data1 %>% -->
<!-- #   select(-dist) %>%  -->
<!-- #   unnest(sim_dist) %>%  -->
<!-- #   list() %>%  -->
<!-- #   global_threshold(harmony_tbl = har1, -->
<!-- #                    response = "sim_dist", -->
<!-- #                    dist_distribution = "normal", -->
<!-- #                    dist_ordered = TRUE, -->
<!-- #                    create_gran_data = FALSE, nsamp = 20) -->
<!-- #  -->
<!-- # # as_tibble(sample_MMPD) %>% mutate(id = row_number()) %>%  -->
<!-- # #   ggplot() + geom_histogram(aes(x = value)) -->
<!-- #  -->
<!-- # ``` -->
<!-- #  -->

# Application

# Conclusion