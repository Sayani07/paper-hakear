---
title: Screening harmonies
authors:
- name: Sayani Gupta
  affiliation: Department of Econometrics and Business Statistics, Monash University
  email: Sayani.Gupta@monash.edu

bibliography: bibliography.bib
output:
  bookdown::pdf_book:
    #base_format: rticles::asa_article
    fig_height: 5
    fig_width: 8
    fig_caption: yes
    dev: "pdf"
---

```{r initial, echo = FALSE, cache = FALSE, include = FALSE}
options("knitr.graphics.auto_pdf" = TRUE)
library(knitr)
library(tidyverse)
library(lubridate)
library(lvplot)
library(ggridges)
library(viridis)
library(tsibble)
library(gravitas)
library(ggpubr)
library(readr)
opts_chunk$set(
  echo = FALSE, warning = FALSE, message = FALSE, comment = "#>",
  fig.path = "figure/", fig.align = "center", fig.show = "hold",
  cache = FALSE, cache.path = "cache/",
  out.width = ifelse(is_html_output(), "100%", "\\textwidth")
)
knitr::opts_knit$set(root.dir = here::here())
```

```{r external, include = FALSE}
# read_chunk('scripts/main.R')
```

```{r load}

```

# Idea

Even after excluding clashes, the list of harmonies left could be large and overwhelming for human consumption. Hence, there is a need to rank the  harmonies basis how well they capture the variation in the measured variable and additionally reduce the number of harmonies for further exploration/visualization. Gestalt theory suggests that when items are placed in close proximity, people assume that they are in the same group because they are close to one another and apart from other groups. Hence, displays that capture more variation within different categories in the same group would be important to bring out different patterns of the data. Thus the idea here is to rate a harmony pair higher if this variation between different levels of the x-axis variable is higher on an average across all levels of facet variables.


# Computing distances

One of the potential ways to evaluate this variation is by computing the pairwise distances between the distributions of the measured variable. We do this through Jensen-Shannon distance which is based on Kullback-Leibler divergence. Probability distributions are represented through sample quantiles instead of kernel density estimate so that there is minimal dependency on selecting kernel or bandwidth.

We shall call this measure of variation as  Median Maximum Pairwise Distances (MMPD)

# Normalize distances

The harmony pairs could be arranged from highest to lowest average maximum pairwise distances across different levels of the harmonies. But maximum is not robust to the number of levels and is higher for harmonies with higher levels. Thus these maximum pairwise distances need to be normalized for different harmonies in a way that eliminates the effect of different levels. The Fisher–Tippett–Gnedenko theorem in the field of Extreme Value Theory states that the maximum of a sample of iid random variables after proper re- normalization can converge in distribution to only one of Weibull, Gumbel or Freschet distribution, independent of the underlying data or process. The normalizing constants, however, vary depending on the underlying distribution and hence it is important to assume a distribution of distances in our case.


# Does normalisation work?
(Show with by comparing with maximum and 
showing for similar levels)
# Does it match with the threshold?
# Should they tally with each other?


```{r rank harmony}
library(gravitas)
library(ggplot2)
library(dplyr)
sm <- smart_meter10 %>%
filter(customer_id %in% c("10017936"))
harmonies <- sm %>%
harmony(ugran = "month",
filter_in = "wknd_wday",
filter_out = c("hhour", "fortnight"))
.data = sm
response  = "general_supply_kwh"
harmony_tbl =  harmonies
smart_harmony <- .data %>% rank_harmony(harmony_tbl = harmonies,
response = "general_supply_kwh", dist_ordered = FALSE)
```




# Choose thresholds for harmonies

| facets/x-axis     	| A_1  	| A_2  	| A_3  	| .. 	| .. 	| A_K  	|
|-----	|------	|------	|------	|----	|----	|------	|
| B_1 	| p_11 	| p_12 	| p_13 	| .. 	| .. 	| p_1K 	|
| B_2 	|      	|      	|      	|    	|    	|      	|
| B_3 	|      	|      	|      	|    	|    	|      	|
| ..  	|      	|      	|      	|    	|    	|      	|
| ..  	|      	|      	|      	|    	|    	|      	|
| B_L 	| p_L1 	| p_L2 	| p_L3 	| .. 	| .. 	| p_LK 	|


$H_{01}: p_{11} = p_{21} = \ldots = p_{L1}$  
$H_{02}: p_{12} = p_{22} = \ldots = p_{L2}$  
\vdots
$H_{0K}: p_{1K} = p_{2K} = \ldots = p_{LK}$  


$m$ = $L \choose 2$ (unordered)  
$m$ = $L-1$ (ordered)  

|  facets/distances	| A_1  	| A_2  	| A_3  	| .. 	| .. 	| A_K  	|
|------------------	|------	|------	|------	|----	|----	|------	|
| d_1              	| d_11 	| d_12 	| d_13 	| .. 	| .. 	| d_1K 	|
| d_2              	|      	|      	|      	|    	|    	|      	|
| d_3              	|      	|      	|      	|    	|    	|      	|
| ..               	|      	|      	|      	|    	|    	|      	|
| ..               	|      	|      	|      	|    	|    	|      	|
| d_m              	| d_m1 	| d_m2 	| d_m3 	 .. 	| .. 	| d_mK 	|

$H_{01}: d_{11} = d_{21} = \ldots = d_{m1} = 0$  
$H_{02}: d_{12} = d_{22} = \ldots = d_{m2} = 0$  
\vdots
$H_{0K}: d_{1K} = d_{2K} = \ldots = d_{mK} = 0$  

 - can do ANOVA at this stage
 - interpretation of results (if interaction of levels significant when testing if means of distributions of distances are equal to zero )

| facets/max-dist 	| A_1       	| A_2       | .. 	| .. 	| A_K       	|
|-----------------	|-----------	|-----------	|-----------	|----	|----	|-----------	|
| max-dist        	| max(d_11, .., dm1) 	| max(d_12, ...d_m2) 	| .. 	| .. 	| max(d_1K,...d_mK) 	|


$H_{01}: max(d_{11}, .., d_{m1}) = 0$  
$H_{02}: max(d_{12}, ...d_{m2})  = 0$  
\vdots
$H_{0K}: max(d_{1K},...d_{mK}) = 0$  

 -  normalised maximum distribution follows standardised Gumbel distribution
 -  multiple hypothesis testing problem where p-values needs to be adjusted with Fisher's combination test (preferred) or Bonferroni's correction
 - What is the test statistic for multiple hypothesis problem?
 
Permutation test:

<!-- paiwise percentile tests for distances. Each facet is a category with m ordered/unordered pairwise distances. We are testing if the 95th percentile of these facets are equal. If at least two of them are different, we keep the harmony pair, else remove them from the list. -->

<!-- 1st screening criterion: 95th percentile different for different facet labels -->

<!-- 2nd screening/ranking criterion: within the harmonies foir which facet levels are different, MMPD is used to rank them -->

**Assumption:** random permutation without considering ordering 
(Local)

1. Given the original sequence for $\{C_i, C_j\}$; $\{v_t: t=0, 1, 2, \dots, T-1\}$, the MMPD is computed and is represented by $MMPD_{obs}$.

2. From the original sequence a random permutation is obtained: $\{v_t^*: t=0, 1, 2, \dots, T-1\}$.

3. MMPD is computed for all random permutation and is represented by $MMPD_{sample}$.

4.  Steps (2) and (3) are repeated a large number
of times M (e.g. 1000).

5. For each permutation, one $MMPD_{sample}$ value is obtained.

6. $95^{th}$ percentile of this $MMPD_{sample}$ distribution is computed and stored in $MMPD_{threshold}$.

7. If  $MMPD_{obs}> MMPD_{threshold}$, then it implies the observed MMPD is 95% of the times higher than the any other random permutation of the original sequence.

Pros: Considering thresholds locally for each harmony pairs would imply that data is reshuffled only within that harmony pair and generated MMPDs are only reflection of how MMPDs are when measured between that harmony pairs only.


Cons: The threshold value is considered locally for each harmony pairs and hence it does not align the original MMPD values we get. That is, a harmony pair with lower MMPD might get selected over that with a higher MMPD. Difficult to understand but it means that although MMPD value is smaller, it is significantly different from zero.


**Assumption:** random permutation without considering ordering 
(Local)

1. Given the data; $\{v_t: t=0, 1, 2, \dots, T-1\}$, the MMPD is computed and is represented by $MMPD_{obs}$.

2. From the original sequence a random permutation is obtained: $\{v_t^*: t=0, 1, 2, \dots, T-1\}$.

3. MMPD is computed for all random permutation of the data and is represented by $MMPD_{sample}$.

4.  Steps (2) and (3) are repeated a large number
of times M (e.g. 1000).

5. For each permutation, one $MMPD_{sample}$ value is obtained.

6. $95^{th}$ percentile of this $MMPD_{sample}$ distribution is computed and stored in $MMPD_{threshold}$.

7. If  $MMPD_{obs}> MMPD_{threshold}$, harmony pairs are accepted. Onlyone threshold for all harmony pairs.

Pros: Considering thresholds global for all harmony pairs would imply less computation time.

Cons: Only one threshold for all harmony pairs might not be an appropriate measure but a good benchmark.


```{r}
library(readr)
signi <- read_rds("data/significant_harmonies.rds")
signi
local_thres <- c(FALSE, TRUE, TRUE, FALSE, TRUE, TRUE, TRUE, FALSE, TRUE, FALSE, FALSE, TRUE, TRUE, FALSE, FALSE, FALSE)

signi %>% select(-facet_levels, -x_levels) %>% 
  mutate(local_threshold = local_thres) %>% knitr::kable(format = "latex")

```

<!-- **Assumption:** random permutation considering ordering -->

<!-- Intuition? -->

<!-- Original: -->

<!-- | facets/observation     	| 1  	| 2  	| 3  	| .. 	| .. 	| n  	| -->
<!-- |-----	|------	|------	|------	|----	|----	|------	| -->
<!-- | B_1 	| x_1 	| x_2 	| x_3 	| .. 	| .. 	| x_n 	| -->
<!-- | B_2 	| y_1 	| y_2 	| y_3 	| .. 	| .. 	| y_n 	| -->
<!-- | B_3 	|      	|      	|      	|    	|    	|      	| -->
<!-- | ..  	|      	|      	|      	|    	|    	|      	| -->
<!-- | ..  	|      	|      	|      	|    	|    	|      	| -->
<!-- | B_L 	| z_1 	| z_2 	| z_3 	| .. 	| .. 	| z_n 	| -->


<!-- Unordered: Permuting across levels -->

<!-- | facets/observation     	| 1  	| 2  	| 3  	| .. 	| .. 	| n  	| -->
<!-- |-----	|------	|------	|------	|----	|----	|------	| -->
<!-- | B_1 	| y_3 	| x_2 	| z_2 	| .. 	| .. 	| y_1 	| -->
<!-- | B_2 	| x_n 	| y_2 	| x_1 	| .. 	| .. 	| z_3 	| -->
<!-- | B_3 	|      	|      	|      	|    	|    	|      	| -->
<!-- | ..  	|      	|      	|      	|    	|    	|      	| -->
<!-- | ..  	|      	|      	|      	|    	|    	|      	| -->
<!-- | B_L 	| x_10 	| x_3 	| y_n 	| .. 	| .. 	| x_5 	| -->


<!-- Ordered: Permuting from the same levels -->

<!-- | facets/observation     	| 1  	| 2  	| 3  	| .. 	| .. 	| n  	| -->
<!-- |-----	|------	|------	|------	|----	|----	|------	| -->
<!-- | B_1 	| x_3 	| x_10 	| x_100 	| .. 	| .. 	| x_1 	| -->
<!-- | B_2 	| y_n 	| y_2 	| y_10 	| .. 	| .. 	| y_3 	| -->
<!-- | B_3 	|      	|      	|      	|    	|    	|      	| -->
<!-- | ..  	|      	|      	|      	|    	|    	|      	| -->
<!-- | ..  	|      	|      	|      	|    	|    	|      	| -->
<!-- | B_L 	| z_10 	| z_200 	| z_10 	| .. 	| .. 	| z_5 	| -->



```{r}
sm <- smart_meter10 %>%
filter(customer_id %in% c(10017936))
.data = sm
sm %>% prob_plot("week_month", "day_week", plot_type = "boxplot")

sm %>% prob_plot("day_month", "hour_day", plot_type = "quantile", symmetric = FALSE, quantile_prob = c(0.05, 0.25, 0.5, 0.75, 0.95))


```

 
 

# Results


##  Smart meter data

normal: standard normal ordered distances  
normal_nonstd: non-standard normal ordered distances  
normal_un: standard normal unordered distances  
normal_nonstd_un: non-standard normal unordered   distances

```{r allgraph}
library(readr)
smart_normal <- read_rds("data/ smart_harmony_normal.rds")  %>% mutate(rank_normal = row_number())

smart_normal_nonstd <- read_rds("data/smart_harmony_nonstd.rds") %>% mutate(rank_normal_nonstnd = row_number())


smart_normal_un <- read_rds("data/smart_harmony_normal_unordered.rds")  %>% mutate(rank_normal_un = row_number())

smart_normal_nonstd_un <- read_rds("data/smart_harmony_nonstd_unordered.rds") %>% mutate(rank_normal_nonstnd_un = row_number())

smart_normal %>% 
  left_join(smart_normal_nonstd, by = c("facet_variable", "x_variable", "facet_levels", "x_levels")) %>% 
   rename("normal" = "mean_max_variation.x", "normal_nonstd" = "mean_max_variation.y") %>%
  
  left_join(smart_normal_un, by = c("facet_variable", "x_variable", "facet_levels", "x_levels")) %>% 
  rename("normal_un" = "mean_max_variation") %>%
  
  left_join(smart_normal_nonstd_un, by = c("facet_variable", "x_variable", "facet_levels", "x_levels")) %>% 
  rename("normal_nonstd_un" = "mean_max_variation")%>% select(-c(normal, normal_nonstd, normal_un, normal_nonstd_un))%>%
  dplyr::rename("normal"  = "rank_normal",
         "normal_nonstd"  = "rank_normal_nonstnd",
         "normal_un"  = "rank_normal_un",
         "normal_nonstd_un"  = "rank_normal_nonstnd_un")%>%   knitr::kable(format = "latex")
```  


<!-- # unordered -->

<!-- ```{r} -->
<!-- library(readr) -->
<!-- smart_normal <- read_rds("data/smart_harmony_normal_unordered.rds")  %>% mutate(rank_normal = row_number()) -->

<!-- smart_normal_nonstd <- read_rds("data/smart_harmony_nonstd_unordered.rds") %>% mutate(rank_normal_nonstnd = row_number()) -->

<!-- smart_normal %>%  -->
<!--   left_join(smart_normal_nonstd, by = c("facet_variable", "x_variable", "facet_levels", "x_levels")) %>%  -->
<!--    rename("normal" = "mean_max_variation.x", "normal_nonstd" = "mean_max_variation.y") %>%  -->
<!--   select(-c(normal, normal_nonstd))%>% -->
<!--   dplyr::rename("normal_unordered"  = "rank_normal", -->
<!--          "normal_nonstd_unordered"  = "rank_normal_nonstnd")%>%   knitr::kable(format = "latex") -->
<!-- ``` -->


## Graphical evidence

```{r, echo = FALSE}
smart_meter10 %>%
  filter(customer_id %in% c(10017936)) %>%
  prob_plot("wknd_wday",
    "hour_day",
    response = "general_supply_kwh",
    plot_type = "boxplot",
    #symmetric = TRUE,
    #quantile_prob = c(0.01, 0.1, 0.25, 0.5, 0.75, 0.9, 0.99)
  ) +
  scale_y_sqrt() +
  #ggtitle(" (b) Area quantile plot faceted by weekend-weekday") +
  ylab("electricity demand [KWh]") + xlab("hours of the day") + ggtitle("") + ylab("")+ 
  theme_minimal() + 
  scale_x_discrete(breaks = seq(0, 23, 5))

smart_meter10 %>%
  filter(customer_id %in% c(10017936)) %>% prob_plot( gran1 = "day_week", gran2 = "day_month", plot_type = "boxplot") + scale_x_discrete(breaks = seq(0, 31, 5))


smart_meter10 %>%
  filter(customer_id %in% c(10017936)) %>% prob_plot(gran1 = "wknd_wday", gran2 = "day_month", plot_type = "boxplot") + scale_x_discrete(breaks = seq(0, 31, 5))


smart_meter10 %>%
  filter(customer_id %in% c(10017936)) %>% 
  prob_plot(gran1 = "wknd_wday", gran2 = "hour_day", plot_type = "boxplot")


smart_meter10 %>%
  filter(customer_id %in% c(10017936)) %>%
  prob_plot("hour_day",
    "wknd_wday",
    response = "general_supply_kwh",
    plot_type = "boxplot",
    #symmetric = TRUE,
    #quantile_prob = c(0.01, 0.1, 0.25, 0.5, 0.75, 0.9, 0.99)
  ) +
  scale_y_sqrt() +
  #ggtitle(" (b) Area quantile plot faceted by weekend-weekday") +
  ylab("electricity demand [KWh]") + xlab("") + ggtitle("") + ylab("")+ 
  theme_minimal() + scale_x_discrete(labels = c('wday','wend'))


```

## cricket data


```{r cricket}
cricket_data <- read_rds("data/cricket_data.rds")

  hierarchy_model <- tibble::tibble(
      units = c("index", "over", "inning", "match"),
      convert_fct = c(1, 20, 2, 1))

hierarchy_tbl <- hierarchy_model

response <- "runs_per_over"

harmonies_cric <- cricket_data %>% harmony(lgran = "over", ugran = "match", filter_in = c("lag_field", "over"), hierarchy_tbl = hierarchy_model)
```


```{r cricket_lag}
cricket_data <- read_rds("data/cricket_data.rds")
cricket_data %>%
  filter(over!=1) %>%
  prob_plot("over", "lag_field",
  hierarchy_model,
  response = "run_rate",
  plot_type = "violin",
  symmetric = FALSE,
 quantile_prob = c(0.25, 0.5, 0.75)) +
   #ggtitle("(b) Runs per over across overs faceted by number of wickets in previous over") +
  ylab("runs per over")  +
  xlab("number of wickets in previous over") +
  ggtitle("b") +
   theme(plot.title = element_text(face = "bold")) +  theme_minimal()
```


```{r smart_harmony}
library(ggplot2)
library(gravitas)
sm <- smart_meter10 %>% dplyr::filter(customer_id %in% c("10017936"))

harmonies <- sm %>% 
  harmony(ugran = "month",
          filter_in = "wknd_wday",
          filter_out = c("hhour", "fortnight"))


harmony_tbl =  harmonies

smart_harmony <- sm %>% 
  rank_harmony(harmony_tbl = harmonies,
               response = "general_supply_kwh", 
               dist_ordered = FALSE)

smart_harmony %>% kable()

smart_harmony %>% ggplot(aes(x = x_levels, y =  r)) + geom_point()


smart_harmony %>% ggplot(aes(x = facet_levels, y =  r)) + geom_point()
```

