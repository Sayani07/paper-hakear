---
title: An automatic approach to find all possible calendar effects (periodic patterns) for an univariate time series
authors:
- name: Sayani Gupta
  affiliation: Department of Econometrics and Business Statistics, Monash University
  email: Sayani.Gupta@monash.edu

bibliography: bibliography.bib
preamble: >
  \usepackage{mathtools,booktabs,amsthm,todonotes,colortbl}
  \def\mod{~\text{mod}~}
  \newtheorem{definition}{Definition}
  \usepackage{mathptmx}
  \usepackage{caption}
  \usepackage{algorithm}
  \usepackage{algorithmicx}
  \usepackage{algpseudocode}
  \DeclareCaptionStyle{italic}{labelfont={bf},textfont={it},labelsep=colon}
  \captionsetup[figure]{style=italic,format=hang,singlelinecheck=true}
  \captionsetup[table]{style=italic,format=hang,singlelinecheck=true}
  \def\novspacing{\setlength{\aboverulesep}{0pt}\setlength{\belowrulesep}{0pt}}
  \def\vspacing{\setlength{\aboverulesep}{0.4ex}\setlength{\belowrulesep}{0.65ex}}
output:
  bookdown::pdf_book:
    #base_format: rticles::asa_article
    fig_height: 5
    fig_width: 8
    fig_caption: yes
    dev: "pdf"
---

```{r initial, echo = FALSE, cache = FALSE, include = FALSE}
options("knitr.graphics.auto_pdf" = TRUE,
        tinytex.verbose = FALSE)
library(knitr)
library(tidyverse)
library(lubridate)
library(lvplot)
library(ggridges)
library(viridis)
library(tsibble)
library(gravitas)
library(ggpubr)
library(readr)
library(kableExtra)
library(distributional)
library(ggplot2)
library(sugrrants)
library(here)

opts_chunk$set(
  echo = FALSE, warning = FALSE, message = FALSE, comment = "#>",
  fig.path = "figure/", fig.align = "center", fig.show = "hold",
  cache = TRUE, cache.path = "cache/",
  out.width = ifelse(is_html_output(), "100%", "\\textwidth")
)
knitr::opts_knit$set(root.dir = here::here())
#                                                                read_chunk('main.R')
here::here()
#knitr::read_chunk(here::here("paper/R/", "null_distribution.R"))
#knitr::read_chunk(here::here("paper/R/", "mean_null.R"))
#source(here::here("paper/R/sim_panel.R"))
# Set up plan
#source("_drake.R")
# Run all code required
#drake::r_make()
# load each object as required
# loadd()
```


```{r}
set.seed(321)
```


# Introduction

<!-- <introducing the problem> -->
<!-- background of the problem -->

Exploratory data analysis, as coined by John W. Tukey (Tukey 1965) involves many iterations of finding structures and patterns that allows the data to be informative. With temporal data available at finer scales, exploring periodicity and their relationships can become overwhelming with so many possible cyclic temporal granularities [@Gupta2020-vo] to explore.

```{r calendar-elec, fig.height = 10.5, fig.cap="Calendar display."}
elec <- read_rds(here("paper/data/elec.rds")) %>% 
  filter(date >= ymd("20180101"), date < ymd("20180701"))
rdbl <- c("Weekday" = "#d7191c", "Weekend" = "#2c7bb6")

elec <- elec %>% 
  mutate(
    wday = wday(date, label = TRUE, week_start = 1),
    weekday = if_else(wday %in% c("Sat", "Sun"), "Weekend", "Weekday")
  )
p_cal_elec <- elec %>% 
  filter(id %in% c(2, 4)) %>% 
  frame_calendar(x = time, y = kwh, date = date, nrow = 1) %>% 
    ggplot(aes(x = .time, y = .kwh, group = date)) +
    geom_line(aes(colour = as.factor(id)), size = 0.5) +
    scale_colour_brewer(name = "", palette = "Dark2", direction = 1) +
    facet_grid(id ~ ., labeller = label_both) +
    theme(legend.position = "bottom")
prettify(p_cal_elec, size = 2.5, label.padding = unit(0.1, "lines"))
```

\noindent Take the example of the calendar display of electricity smart meter data (\ref{fig:calendar-elec}) used in @wang2020calendar for four households in Melbourne, Australia. The authors show how hour-of-the-day interact with weekday and weekends and then move on to use calendar display to show daily schedules. The calendar display has several components in it, which helps us look at energy consumption across hour-of-the-day, day-of-the-week, week-of-the-month, and month-of-the-year at once. Some interaction of these cyclic granularities could also be interpreted from this display. This is a great start to have an overview of the energy consumption. However, if one wants to understand the periodicities in energy behavior and how the periodicities interact in greater details, it is not easy to comprehend the interactions of some periodicities' from this display, due to the combination of linear and cyclic representation of time. For example, this display might not be the best to understand how hour-of-the-day varies and month-of-year varies across week-of-the-month. Further, it is not clear what all interactions of cyclic granularities should be read from this display as there could be many combinations that one can look at. Moreover, calendar effects are not restricted to conventional day-of-week or month-of-year deconstructions (@Gupta2020-vo) and could include other cyclic granularities like hour-of-week or day-of-fortnight, which could potentially become useful depending on the context. 

```{r intro_all}

id2_tsibble <- elec %>% 
   filter(id == 2) %>% 
   as_tsibble(index = date_time)
  
id4_tsibble <- elec %>% 
   filter(id == 4) %>% 
   as_tsibble(index = date_time)

# hour-of-day and month-of-year (important pair) id2's behavior across different hours of the day very different across months, but for id4 behavior across different hours of the day is not likely a function of month.
p1 <- id2_tsibble %>%
   prob_plot("month_year",
             "hour_day",
             response = "kwh",
             plot_type = "quantile",
             symmetric = TRUE,
             quantile_prob = c(0.1, 0.25,0.5,0.75, 0.9)) +
  ggtitle("") + theme(
        strip.text = element_text(size = 10, margin = margin(b = 0, t = 0))) + 
  scale_colour_brewer(name = "", palette = "PiYG")

p2 <- id4_tsibble %>%
   prob_plot("month_year",
             "hour_day",
             response = "kwh",
             plot_type = "quantile",
             symmetric = TRUE,
             quantile_prob = c(0.1, 0.25,0.5,0.75, 0.9)) + 
  ggtitle("") + theme(
        strip.text = element_text(size = 10, margin = margin(b = 0, t = 0)))

# wknd_wday and week_month (important pair) id2's behavior across different hours of the day very different across months, but for id4 behavior across different hours of the day is not likely a function of month.

p3 <- id2_tsibble %>%
  create_gran("week_month") %>% 
  filter(week_month != 5) %>% 
   prob_plot("wknd_wday",
             "week_month",
             response = "kwh",
             plot_type = "quantile",
             symmetric = FALSE,
             quantile_prob = c(0.25,0.5,0.75)) +
   ggtitle("") +
#scale_x_discrete(breaks = seq(0, 23, 4))  + theme(
        theme(strip.text = element_text(size = 10, margin = margin(b = 0, t = 0)))

p4 <- id4_tsibble %>%
    create_gran("week_month") %>% 
  filter(week_month != 5) %>% 
   prob_plot("wknd_wday",
             "week_month",
             response = "kwh",
             plot_type = "quantile",
             symmetric = FALSE,
             quantile_prob = c(0.25,0.5,0.75)) +
  ggtitle("") +  #+ scale_x_discrete(breaks = seq(0, 23, 4)) + 
theme(
        strip.text = element_text(size = 10, margin = margin(b = 0, t = 0)))

```

```{r id2, fig.cap = "something"}
ggpubr::ggarrange(p1, p2, ncol = 2)
```

```{r id4, fig.cap = "something2"}
ggpubr::ggarrange(p3, p4, ncol = 2)
```

Moreover, there might be specific interactions that are interesting and others that are not and that too will vary with different households. For example, area distribution quantiles are plotted for household 2 and 4 in Figure \ref{fig:id2}a and b respectively. For the first household, the 75th and 90th percentile for Jan, Feb and July are very close, implying that energy usage for these months are generally on a much higher side due to the usage of air conditioners (in Jan and Feb) and heaters (in July). The energy consumption for household 2 is also higher relative to its own consumption for Jan, Feb and March but the 75th and 90th percentile are apart implying that contrary to the first household, the second household resorts to air conditioners and heaters much less regularly than the first one. Moreover, the 75th percentile distribution is not bimodal across hours of the day for the first household in those months, but the distribution looks similar for all months for the second household. Difference in the energy consumption seem to be varying both across month-of-year (facets) and hour-of-day (x-axis). And thus, both the cyclic granularities would deem important while studying the periodicities in the first household. However, it seems like energy consumption across hours of the day are not that different across different months for the second household. Differences seem to be more prominent across month-of-year (facets) than hour-of-day (x-axis). Again, look at \ref{fig:} c and d, where energy consumption for these two households are plotted against (weekend/weekday, week-of-month). Here, for both households, the pattern of energy consumption vary  across different weeks of the month irrespective of the fact it is a weekday or weekend. In that respect, the harmony pair (month-of-year, hour-of-day) seems to be more informative than (weekend/weekday, week-of-month) for the first household. It could be immensely useful to make the transition from all possible ways to only ways that could potentially be informative given a household. 

<!-- Take an example of a data set which are observed at fine temporal scales, like that of NYC bike usage available at https://www.citibikenyc.com/system-data. We use the `nyc_bikes` data set from the R package `tsibbledata` which takes a sample of 10 bikes for the year 2018. The `start_time` and the `stop_time` are recorded to a fineness of seconds. We can look at pair of cyclic granularities (hour_day, wknd_wday) or (week_month, day_week) to see how these periodicities interact. But there could be other pairs that are important too. How to understand which pairs are sufficient to explore given the data set without losing much information about the data. -->

<!-- When we need to understand the interplay of different periodicities in a high frequency temporal datasets, we have many choices to consider. In [@wang2019tsibble] and [@wang2020calendar], periodicities are explored across hour of the day and day of the week or months. But calendar effects are not restricted to conventional day-of-week or month-of-year deconstructions. -->

<!-- what is the dimension of the problem -->
The paper @Gupta2020-vo describes how we can compute all possible combinations of cyclic time granularities. If we have $n$ periodic linear granularities in the hierarchy table, then $n(n-1)/2$ circular or quasi-circular cyclic granularities could be constructed. Let $N_C$ be the total number of contextual circular, quasi-circular and aperiodic cyclic granularities that can originate from the underlying periodic and aperiodic linear granularities. The mapping of the graphical elements chosen in the paper implies that, for a numeric response variable, the graphics display distributions across combinations of cyclic granularities, one placed at x-axis and the other on the facet. That essentially implies there are $^{N_C}P_2$ possible pairwise plots exhaustively, where each plot would display a pair of cyclic granularities. This is large and overwhelming for human consumption.

<!-- Scagnostics literature -->
This is similar to Scagnostics (Scatterplot Diagnostics) by @tukey1988computer, which is used to discern meaningful patterns in large collections of scatterplots. Given a set of $v$ variables, there are $v(v-1)/2$ pairs of variables, and thus the same number of possible pairwise scatterplots. Therefore
for even small $v$, the number of scatterplots can be
large, and scatterplot matrices (SPLOMs) could easily run out of pixels when presenting high-dimensional data. @Dang2014-tw and @wilkinson2005graph provides potential solutions to this, where few characterizations help us to locate anomalies for defining several measures aimed to detect anomalies in density, shape, trend, and
other features in the 2D point scatters.

<!-- harmonies and why it is not enough -->
The paper (@Gupta2020-vo) narrows down the search from $^{N_C}P_2$ plots by identifying pairs of granularities that can be meaningfully examined together (a "harmony"), or when they cannot (a "clash"). However, even after excluding clashes, the list of harmonies left could be enormous for exhaustive exploration. Hence, there is a need to reduce the search even further by including only those harmonies which are informative enough. Also, ranking the remaining harmony pairs based on how well they capture the variation in the measured variable could be potentially useful.  

In this paper, we aim to build a new measure to follow through these two main objectives:

- To choose harmonies for which distributions of categories are significantly different 
- To rank the selected harmonies from highest to lowest variation in the distribution of their categories.

<!-- Talk about Scagnostics: Tukey -->

# The distance measure for quantifying patterns in harmonies

We are interested in assessing structure in probability distributions of the measured variable across bivariate cyclic granularities. We propose a measure called Weighted Maximum Pairwise Distances (wpd) to evaluate structure in such a design.


## Idea {#sec:idea}

The principle employed for building a new metric is explained through a simple example explained in Figure \ref{fig:null4by2}. Each of these figures have the same panel design with 2 x-axis categories and 4 facet levels. Figure \ref{fig:null4by2}a has all x categories drawn from N(5, 10) distribution for each facet. It is not an interesting display particularly, as distributions do not vary across x-axis or facet categories. Figure \ref{fig:null4by2}b has x categories drawn from the same distribution within a facet and different for different facet categories. Figure \ref{fig:null4by2}b exhibits an exact opposite situation where distribution between the x-axis categories within each facet is different but they are same across facets. Figure \ref{fig:null4by2}d takes a step further by varying the distribution across both facet and x-axis categories. If we are asked to rank the displays in order of importance from minimum to maximum, we might order it as a, b, c and then d. It might be argued that it is not clear if b should precede or succeed c. Gestalt theory suggests that when items are placed in close proximity, people assume that they are in the same group because they are close to one another and apart from other groups. Hence, displays that capture more variation within different categories in the same group would be important to bring out different patterns of the data. With this principle, display b could be considered less informative as compared to display c.   

With reference to the graphical design in \ref{@Gupta2020-vo}, therefore the idea would be to rate a harmony pair higher if the variation between different levels of the x-axis variable is higher on an average across all levels of the facet variables. Thus the metric could be obtained by computing maximum pairwise distances between distributions of the continuous random variable across x-axis categories for all facets and then taking the median of those maximum pairwise distances across facets. This would help capture the average maximum difference in distribution of the measurement variable explained by the two cyclic granularities together. We call this metric wpd which stands for Median Maximum Pairwise Distances. In the next section we shall see how we go about computing this measure.



<!-- To elaborate further, look at the examples in Figure \ref{}, where Figure \ref{}a represents the panel design with distribution of each x categories drawn from N(5, 10) distribution. It could be observed that the graph is not particularly interesting, as there is no significant change in distribution between x-axis levels or facets. Figure \ref{}b represents the same panel design with no difference in distribution of x-axis categories within a facet, but different distribution of x-axis categories for different facets. For example, if there are 4 facet levels and 2 x-axis levels, data is generated in the way as described in Table \ref{}. Figure \ref{}b exhibits an exact opposite situation where the x-axis within facets are different but not across facets. -->
<!-- Figure \ref{}d takes it further by varying the distribution across both facet and x-axis categories. -->



```{r null4by2,fig.cap=" A graphical display with two categories mapped to x-axis and 4 categories mapped to facets with the distribution of a continuous random variable plotted on the y-axis. Display a is not interesting as the distribution of the continuous rv does not depend across x-axis or facet categories. Display b and c are more interesting than a since there is a change in distribution either across facets(b) or x-axis(a). Display d is most interesting as distribution of the rv changes across both facet and x-axis variable.", eval = FALSE}

# sim_varf_dist1 = function(nx, nfacet){
#   rep(dist_normal(seq(mean,mean*nfacet, by = mean), sd), each = nx)}

p1 <- sim_panel(nx = 2, nfacet = 3, ntimes = 500) %>%
  ggplot(aes(x = as.factor(id_x), y = sim_data)) + facet_wrap(~id_facet) + geom_boxplot()

simulated_data <- sim_panel(nx = 2,
          nfacet = 3,
          ntimes = 500,
          sim_dist = rep(dist_normal(seq(5, 15, 5), 5), each = 2)) 


p2 <- simulated_data %>% ggplot(aes(x = as.factor(id_x), y = sim_data)) + facet_wrap(~id_facet) + geom_boxplot()

p3 <- simulated_data %>% ggplot(aes(x = as.factor(id_facet), y = sim_data)) + facet_wrap(~id_x) + geom_boxplot()

p4 <- sim_panel(nx = 2,
          nfacet = 3,
          ntimes = 500,
          sim_dist = dist_normal(seq(5,30, 5), 5)) %>% 
  ggplot(aes(x = as.factor(id_x), y = sim_data)) + facet_wrap(~id_facet) + geom_boxplot()


ggpubr::ggarrange(p1, p2, p3, p4, nrow = 2, ncol = 2,
                  common.legend = TRUE,
                  labels = c("a", "b", "c", "d"))

```


<!-- in the same group would be important to bring out different patterns of the data. -->

## Characterising distributions

Each of the data subsets in the data structure have multiple observations and may vary widely across different subsets due to the structure of the calendar, missing observations or uneven locations of events in the time domain. The set of observations corresponding to each combination is assumed to be a sample from an unknown probability density function.
While the whole population of observations has certain characteristics, we can typically never measure all of them. Often shape, central tendency, and variability are the common characteristics used to describe the distribution. Another way to describe the probability distribution is through quantiles. (Define quantiles here) <!--There are two broad approaches to quantile estimation, viz, parameteric and non-parameteric. The benefit of using a non-parametric estimator is that there are less rigid assumptions made about the nature of the underlying distribution of the data.--> Sample quantiles could be thought to estimate the population quantiles. But there are a large number of different definitions used for sample quantiles. The median-unbiased estimator is recommended (Rob's paper) because of its desirable properties of a quantile estimator and can be defined independently of the underlying distribution. 


## Distance between distributions

<!-- One of the most important class of divergence is the f-divergence and includes measures like Kullback-Leibler divergence, Hellinger distance etc. The continuous version of f -divergence is given by -->
<!-- $$D_f(P||Q) := \int q(x)f(\frac{p(x)}{q(x)})$$, where -->
<!-- $f : [0,\infty) \rightarrow R \cup \{\infty\}$ is a continuous convex function, and $f(1) = 0$.  -->
  
The most common divergence measure between distributions is the Kullback-Leibler (KL) divergence[@Kullback1951-jy] introduced by Solomon Kullback and Richard Leibler in 1951. The KL divergence, denoted $D(p(x), q(x))$ is a non-symmetric measure of the difference between two probability distributions $p(x)$ and $q(x)$ and is interpreted as the amount of information lost when $q(x)$ is used to approximate $p(x)$. Although the KL divergence measures the “distance” between two distributions, it is not a distance measure since it is not symmetric and does not satisfy the triangle inequality. The Jensen-Shannon divergence [@Menendez1997-in] based on the Kullback-Leibler divergence is symmetric and it always has a finite value. The square root of the Jensen-Shannon divergence is a metric, often referred to as Jensen-Shannon distance. Other common measures of distance are Hellinger distance, total variation distance and Fisher information metric. 

In the context of this paper, the pairwise distances between the distributions of the measured variable are computed through Jensen-Shannon distance (JSD) which is based on Kullback-Leibler divergence and is defined by,

$$JSD(P||Q) = \frac{1}{2}D(P||M) + \frac{1}{2}D(Q||M)$$
where $M = \frac{P+Q}{2}$ and 
$D(P||Q) := \int^\infty_{-\infty} p(x)f(\frac{p(x)}{q(x)})$ is the KL divergence between distributions $p(x)$ and $q(x)$. Probability distributions are estimated through quantiles instead of kernel density so that there is minimal dependency on selecting kernel or bandwidth.

<!-- The Jensen-Shanon distance between two probability distribution $p_1$ and $p_2$ is given by $$d = [D(p_1, r) + D(p_2, r)]/2 \quad where \quad r = (p_1 + p_2)/2$$ where, -->
<!-- $$D(p_1,p_2) = \int^{\infty}_{-\infty}p_1(x)log\frac{p_1(x)}{p_2(x)}\,dx$$ is the Kullback-Leibler divergence between $p_1$ and $p_2$.   -->

<!-- We call this measure of variation as  Median Maximum Pairwise Distances (MMPD). -->



<!-- #### Distribution of Jensen-Shannon distances -->

<!-- Jensen-Shannon distances (JSD) are distributed as chi-squared with $m$ df where we discretize the continuous distribution with $m$ discrete values. Taking sample percentiles to approximate the integral would mean taking $m = 99$. -->
<!-- With large $m$, chi-squared is asymptotically normal by the CLT. Thus, by CLT, ${\chi^2}_{m} \tilde{} N(m, 2m)$, which would depend on the number of discretization used to approximate the continuous distribution. Then $b_n = 1-1/n$ quantile of the normal distribution and $a_n = 1/[n*\phi(b_n)]$ where $\phi$ is the normal density function. $n$ is the number of pairwise comparisons being made. -->


## Definition of the distance measure

Consider two cyclic granularities $A$ and $B$, such that $A = \{ a_j: j = 1, 2, \dots, J\}$ and $B = \{ b_k: k = 1, 2, \dots, K\}$ with $A$ placed across x-axis and $B$ across facets. Let the pairwise distances between pairs $(a_{j} b_{k}, a_{j'}b_{k'})$ be denoted as $d_{(jk, j'k')} = JSD(a_{j}b_{k}, a_{j'}b_{k'})$. Pairwise distances could be within-facets or between-facets. Figure \ref{fig:distance-explain} illustrates how the within-facet or between-facet distances are defined. Pairwise distances are within-facets ($d_{w}$) when $b_{k} = b_{k'}$, that is, between pairs of the form $(a_{j}b_{k}, a_{j'}b_{k})$ as shown in panel (3) of Figure \ref{fig:distance-explain}. If categories are ordered (like all temporal cyclic granularities), then only distances between pairs where $a_{j'} = (a_{j+1})$ are considered (panel (4)). Pairwise distances are between-facets ($d_{b}$) when they are considered between pairs of the form $(a_{j}b_{k}, a_{j}b_{k'})$.


```{r distance-explain, fig.cap = "Within and between-facet distances shown for two cyclic granularities A and B, where A is mapped to x-axis and B is mapped to facets. The dotted lines represent the distances between different categories. Panel 1) and 2) show the between-facet distances. Panel 3) and 4) are used to illustrate within-facet distances when categories are un-ordered or ordered respectively. When categories are ordered, distances should only be considered for consecutive x-axis categories. Between-facet distances are distances between different facet levels for the same x-axis category, for example, distances between {($a_1$,$b_1$) and ($a_1$, $b_2$)} or {($a_1$,$b_1$) and ($a_1$, $b_3$)}."}
knitr::include_graphics(here::here("paper/Figs/dist_explain.png"))
```
  
From Section \ref{sec:idea}, the idea is to put more weights on within-facet distances than between-facet distances. Hence, for a suitable tuning parameter $0<\lambda<1$, the pairwise distances $d_{(jk, j'k')}$ are transformed based on the distance type as follows:

\begin{equation}
d*_{(j,k), (j'k')} =
\begin{cases}
\lambda d_{(jk), (j'k')},& \text{if } d = d_w\\
(1-\lambda)  d_{(jk), (j'k')},              & \text{if } d = d_b\\
\end{cases}
\end{equation}

The maximum weighted pairwise distances are defined as:
$$wpd = max_{j, j', k, k'}(d*_{(jk), (j'k')})
\forall j, j' \in \{1, 2, \dots, J\}, k, k' \in \{1, 2, \dots, K\}$$.


<!-- _j$ maps index set to a set $\{B_\ell \mid \ell =1,\dots,L\}$. Here, $A_k$ and $B_\ell$ are the levels/categories corresponding to $C_i$ and $C_j$ respectively. Let $S_{k\ell}$ be a subset of the index set such that for all $s \in S_{k\ell}$, $C_i(s) = A_k$ and $C_j(s) = B_\ell$. There are $KL$ such data subsets, one for each combination of levels ($A_k$, $B_\ell$). Moreover, consider that in the graphical space, $C_i$ is mapped to facets and $C_j$ is mapped to x-axis. -->


 <!-- old -->
<!-- Consider two cyclic granularities $C_i$ and $C_j$, such that $C_i$ maps index set to a set $\{A_k \mid k=1,\dots,K\}$ and $C_j$ maps index set to a set $\{B_\ell \mid \ell =1,\dots,L\}$. Here, $A_k$ and $B_\ell$ are the levels/categories corresponding to $C_i$ and $C_j$ respectively. Let $S_{k\ell}$ be a subset of the index set such that for all $s \in S_{k\ell}$, $C_i(s) = A_k$ and $C_j(s) = B_\ell$. There are $KL$ such data subsets, one for each combination of levels ($A_k$, $B_\ell$). Moreover, consider that in the graphical space, $C_i$ is mapped to facets and $C_j$ is mapped to x-axis.  -->


<!-- The algorithm employed for computing the distance measure is summarized as follows: -->

<!-- 1. Fix harmony pair $(C_i, C_j)$. -->

<!-- 2. Fix $k$. Then there are $L$ groups corresponding to level $A_k$ of $C_i$. -->

<!-- 3. Compute  $m = \binom{L}{2}$ pairwise distances between distributions of $L$ unordered levels and $m = L-1$ pairwise distances for $L$ ordered categories. -->

<!-- 4. Identify maximum within the $m$ computed distances. -->

<!-- <!-- 5. Compute distribution of maximum distance ($M$) by shuffling the data $200$ times and finishing Steps1-4 in each case. Scale $M$ using the mean and sd of the distribution.  --> 

<!-- 5. Use Steps 1-4 to compute maximum distance for $\forall k \in  \{1, 2, \ldots, K\}$. -->

<!-- 6. Compute the distance measure MMPD_raw = median $(M_1, M_2, \dots, M_K)$. -->


<!-- \begin{algorithm}[!thb] -->
<!-- 	\caption{Calculation for a raw distance measure between two cyclic granularities $A = \{ a_j: j = 1, 2, \dots, J\}$, $B = \{ b_k: k = 1, 2, \dots, K\}$ with $A$ placed across x-axis and $B$ across facets.}\label{alg:scoreopt}. -->
<!-- 	\begin{algorithmic}[1] -->
<!-- 		\Procedure{RawMMPD}{$A = \{ a_j: j = 1, 2, \dots, J\}$, $B = \{ b_k: k = 1, 2, \dots, K\}$, $v = \{ v_t: t = 1, 2, \dots, T\}$}. -->
<!-- 		\For{$k=1:K$, $j=1:J$} -->
<!-- 		\State Find distances between pairs of all possible combinations of categories $(a_jb_k,a_j'b_k')$ by computing JSD between quantiles of the measured variable $q(v)$ across these combinations. -->
<!-- 		\State $d \gets JSD(\tilde{q(v)_{a_{j}b_{k}}},\tilde{q(v)_{a_{j}'b_{k}'}})$ -->
<!-- 		\If {$b_k = b_k'$} -->
<!-- 		\State $d* \gets \lambda d$  \Comment{upweight within-facet distances} -->
<!-- 		\Else -->
<!-- 		\State $d* \gets 1/\lambda d $ \Comment{downweight across-facet distances} -->
<!-- 		\EndFor -->
<!-- 		\State Set the raw distance measure as $max(d*)$ where max is taken over all $j, j', k, k'$. -->

<!-- 		\EndProcedure -->
<!-- 	\end{algorithmic} -->
<!-- \end{algorithm} -->

<!-- A stronger measure "max" is chosen for aggregating x-axis categories compared to "median" for aggregating facet categories as the measure is intended to put more importance in pointing towards distributional differences between x-axis categories than for facet categories. -->

## Properties of the distance measure

A simulation study is carried out to explore how $wpd$ performs under various designs, its parameters and limitations. To this end, simulations were carried out for four different designs and the following factors that could potentially have an impact on the values of $wpd$:

- $nx$ (number of levels of x-axis)
- $nfacet$ (number of levels of facets)
- $\lambda$ (tuning parameter)
- $\omega$ (increment in each panel design)
- $dist$ (normal/non-normal distributions with different location and scale)
- $n$ (sample size for each combination of categories)
- $nsim$ (number of simulations)
- $nperm$ (number of permutations of data)  
- $designs$  
$D_{null}$  (No difference in distribution)  
$D_{var_f}$ (Difference in distribution only across facets)  
$D_{var_x}$ (Difference in distribution only across x-axis)  
$D_{var_{all}}$ (Difference in distribution in both facets and x-axis)

Results are presented in two parts. The dependence of $wpd$ on $nx$ and $nfacet$ under $D_{null}$ is presented here, which lays the foundation for the next section. The rest of the results that discusses the relationship of the $wpd$ with other factors is presented in the Supplementary section of the paper.

### Design of the simulation study

Observations are generated from a Gamma(2,1) distribution for each combination of $nx$ and $nfacet$ from the following sets: $nx = nfacet = \{2, 3, 5, 7, 14, 20, 31, 50\}$ to cover a wide range of levels from very low to moderately high. Each combination is being referred to as a _panel_. That is, data is being generated for each of the panels $\{nx = 2, nfacet = 2\}, \{nx = 2, nfacet = 3\}, \{nx = 2, nfacet = 5\},  \dots, \{nx = 50, nfacet = 31\}, \{nx = 50, nfacet = 50\}$. For each of the $64$ panels, $ntimes = 500$ observations are drawn for each combination of the categories. That is, if we consider the panel  $\{nx = 2, nfacet = 2\}$, $500$ observations are generated for each of the combination of categories from the panel, namely, $\{(1, 1), (1, 2), (2, 1), (2, 2)\}$. The values of $\lambda$ is set to $0.67$ and values of raw wpd $wpd$ is obtained. This entire design applies to the null cases and hence there is no difference in distribution between any categories in the panel.

### Results

Figure \ref{fig:raw} shows the distribution of $wpd$ plotted across different nx and nfacet categories. Both shape and scale of the distributions change across panels. This is not desirable as it would mean we would not be able to compare $wpd$ across different $nx$ and $nfacet$ as each of them are drawn from distributions with different locations and scale. In Figure \ref{fig:quadratic}, we see how the median of $wpd_{raw}$ varies with the total number of distances $nx*nfacet$ for each panel. The median increases abruptly for lower values of $nx*nfacet$ and slowly for higher $nx*nfacet$.


```{r raw, fig.cap = "Distribution of raw wpd is plotted across different nx and nfacet categories. Both shape and scale of the distribution changes for different nx and nfacet categories."}
G21 <- read_rds("simulations/raw/null_design_quantrans/data-agg/all_data_wpd_Gamma21.rds")

G21 %>% 
  ggplot(aes(x = value)) + 
  geom_density(fill = "blue") +
  facet_grid(nx~nfacet,
             labeller = "label_both") + 
  scale_x_continuous(breaks = scales::breaks_extended(3)) + 
  xlab("raw wpd")
```


```{r quadratic, fig.cap = "$wpd_{raw}$ is plotted against nx*nfacet and the blue line represents the median of the multiple values for each nx*nfacet levels."}
G21 %>% 
  ggplot(aes(x=nx*nfacet, y = value)) +
  geom_point() + stat_summary(fun=median, geom="line", aes(group=1), color = "blue") + xlab("nx*nfacet") + ylab("raw wpd")

```


# Normalisation of the distance measure

The distribution of wpd is different for different levels of facets and x-axis levels. This is because the statistic maximum which is used to define $wpd$ is affected by the number of categories. The measure would have higher values if $A$ or $B$ has higher levels. However, we would ideally want a higher value of the measure only if there is significant difference between distributions across facet or x-axis categories, and not because the number of categories $J$ or $K$ is high. Therefore, in order to compare $wpd$ across different combinations of facet and x-axis levels, we need to eliminate the impact of different levels of the facets and x-axis first and get a normalized measure. Henceforth we call the measure already discussed as $wpd_{raw}$ and the normalized measure as $wpd_{norm}$. The measure $wpd_{norm}$ could potentially lead to comparison of the measure across different panels and also identifying only the interesting panels from a data set. We discuss two approaches for normalization, both of which are based on the simulation results conducted in the earlier section.


<!-- The nodes and the storage used are as follows: -->

## Methodology

We need a transformation on ${wpd}$ which will make it independent of the values of $nx*nfacet$. Two approaches have been employed for that purpose, the first one involves fitting a model and the latter involves a permutation method to make the distribution of the transformed $wpd$ similar across different $nx$ and $nfacet$.

<!-- ### Notations -->

<!-- Let $\{nx_{i}, i = 1, 2, \dots, nx\}$, $\{nfacet_{j}, j = 1, 2, \dots, nfacet\}$ be the set of x-axis and facet categories respectively. Each combination of $nx_{i}$ and $nfacet_{j}$is being referred to as a _panel_. Then the total number of panel is $nx*nfacet$. Let the total number of pairwise distances that could result in each panel be $\{z_k, k = 1, 2 , \dots, nx*nfacet\}$. Here, $\{z_1 = nx_1*nfacet_1\}$, $\{z_2 = nx_2*nfacet_2\}$ and $\{z_k = nx*nfacet\}$. Now, let $\{x_{k,l}, k = 1, 2, \dots, nx*nfacet, l = 1, 2, \dots, nsim\}$ denote the values of $wpd_{raw}$ obtained from the simulation study for $k^{th}$ panel in the $i^{th}$ simulation. Hence, for each of those $k$ panel, we have $nsim$ values of $wpd_{raw}$. -->


### Permutation approach

The permutation approach ensures that the distribution of the normalized distance measure has the same mean and standard deviation across all combinations of $nx_i$ and $nfacet_j$. The normalized distances through permutation is computed as follows: $x^{perm}_{k} =  (x_{k} - mean_l(x_{k,l}))/sd_l(x_{k, l})$,  $x^{perm}_{k}$ is the value of the $wpd_{perm$ for the $k^{th}$ panel. Standardizing the variable $wpd_{perm}$ in this approach leads to $location = 0$ and $scale = 1$ for this variable.

While this works successfully to make the mean and standard deviation across different $nx$ and $nfacet$ (as seen in Figure \ref{fig:}), it is computationally heavy and time consuming, and hence less user friendly when being actually used in practice. Hence, we propose another approach to normalization which is more approximate than exact but still has the same accuracy when compared to the permutation approach.

*incorporate from the document combining_normalisation_method.Rmd*

### Modelling approach

A log-linear model is fitted to see how the values of $wpd_{raw}$ changes with the values of $nx$ and $nfacet$.  The model is of the form $$y_k = a+b*log(z_k) + e_k$$, where, $y_k = median_l(x_{k, l})$ and $e_k$ are idiosyncratic errors. We have gone with the approach of fitting a linear regression model to estimate the parameters $a$ and $b$. The estimates and other model summary is given in \ref{tab:linear-model}.

```{r linear-model}
G21 <- read_rds(here("simulations/raw/null_design_quantrans/data-agg/all_data_wpd_Gamma21.rds"))

G21_median <- G21 %>% 
  group_by(nx*nfacet) %>% 
  summarise(actual = median(value))


# fit model median to log(nx*nfacet)
fit_lm2 <- lm(actual ~ poly(log(`nx * nfacet`) ,1, raw=TRUE), data = G21_median)

summary(fit_lm2)
```


The final idea is to find a transformation on $wpd_{raw}$ which would remove the effect of $nx*nfacet$ on $wpd_{raw}$ and thus is defined as follows:
$y^* =  y - \hat b*log(z)$, where 
$y^*$ is the $median(wpd_{norm})$, 
$y$ is the $median(wpd_{raw})$,
$\hat b$ is the estimated value of the parameter $b$, 
and $z = nx*nfacet$.

The above takes care of the mean and the heterogeneity of the median transformed measure. But, the original distribution will still have some dissimilarities in shape and location specially for small values of $nx$ and $nfacet$ as could be seen in \ref{fig:}


```{r}

intercept <- fit_lm2$coefficients[1]
slope <- fit_lm2$coefficients[2]

G21 %>% 
  ggplot(aes(x=log(nx*nfacet), y = (value - slope*log(nx*nfacet)))) +
  geom_point() + stat_summary(fun=mean, geom="line", aes(group=1), color = "blue") + 
  ylab("wpd_norm =  wpd_raw - slope*log(nx*nfacet)")


```


<!-- Let ${x_p, p = 1, 2, \dots, npanel}$ denote the total number of distances $nx*nfacet$ obtained in each panel. So for each $nx*nfacet$, we have $nsim = 200$ values of ${y_i}$. -->



<!-- from $nx_{i}$ x-categories and $nfacet_{j}$ facet-categories is $nx_{i}*nfacet_{j}$ and  -->


## Results

This section reports the results of a simulation study that was carried out to evaluate the behavior of our distance measure across all potential factors. The results are reported in two parts: for the a) raw measure and then b) normalised one to show how the loopholes for the raw measures were removed using the normalized ones.

First, the behavior of $wpd_{raw}$ and $wpd_{norm}$ is explored in designs where there is no difference in distribution between x and facet categories. We have considered different initial distributions to study the impact of initial distribution under the null setup. Using two types of distributions, viz. normal and gamma (non-normal), we generated observations for each combination of $nx$ and $nfacet$ from the following sets: $nx = \{2, 3, 5, 7, 14, 20, 31, 50\}$ and $nfacet = \{2, 3, 5, 7, 14, 20, 31, 50\}$ to cover a wide range of levels from very low to moderately high. Each combination is being referred to as a _panel_. That is, data is being generated for each of the panels $\{nx = 2, nfacet = 2\}, \{nx = 2, nfacet = 3\}, \{nx = 2, nfacet = 5\},  \dots, \{nx = 50, nfacet = 31\}, \{nx = 50, nfacet = 50\}$. For each of the $64$ panels, $ntimes = 500$ observations are drawn for each combination of the categories. That is, if we consider the panel  $\{nx = 2, nfacet = 2\}$, $500$ observations are generated for each of the combination of categories from the panel, namely, $\{(1, 1), (1, 2), (2, 1), (2, 2)\}$. The values of $\lambda$ is set to $0.67$, since we want to up-weigh the within-facet distances and that of $\omega$ is set to $0$, since there is no significant differences between distributions in the null case. Observations were generated for each type of distribution changing the shape and scale to study the effect of shape, scale and type of distribution on wpd. The set of distributions considered for this purpose is ${N(0,1), N(5, 1), N(0,5), \Gamma(0.5, 1), \Gamma(2, 1)}$. Each of the scenario is run $nsim = 200$ times to see the distribution of wpd values for each scenario.

Secondly, the behavior of raw and normalized wpd is explored in designs where there is in fact difference in distribution between facet categories ($D_{var_f}$) or across x-categories ($D_{var_x}$) or both ($D_{var_{all}}$). Using $\omega =  \{1, 2, \dots, 10\}$ and $\lambda = seq(from  = 0.1, to = 0.9, by = 0.05)$, observations are drawn from a N(0,1) distribution for each combination of $nx$ and $nfacet$ from the following sets: $nx = nfacet =  \{2, 3, 5, 7, 14, 20, 31, 50\}$. $ntimes = 500$ is assumed for this setup as well. Furthermore, to generate different distributions across different combination of facet and x levels, the following method is deployed - suppose the distribution of the combination of first levels of x and facet category is $N(\mu,\sigma)$ and $\mu_{jk}$ denotes the mean of the combination $(a_jb_k)$, then $\mu_{j.} = \mu + j\omega$ (for design $D_{var_x}$) and $\mu_{.k} = \mu + k\omega$ (for design $D_{var_f}$). 

The tabulated values and graphical representations of the simulation results are provided in Appendix. The learning from the simulations are as follows:
The values of the measure $wpd_{raw}$ is least for $D_{null}$, followed by 
$D_{var_f}$, $D_{var_x}$) and $D_{var_{all}}$). This is a desirable result since the measure $wpd_{raw}$ was designed such that this relationship holds.
Furthermore, the distribution of the measure $wpd_{raw}$ changes for different facet and x categories. The location of the distribution shifts to the right and it also becomes more skewed for more higher facet and x-axis categories. Now this is not desirable, as it would mean that we can't compare the $wpd_{raw}$ values across different panels. The distribution of $wpd_{norm}$ looks more similar with at least the mean and standard of the distributions being uniform across panels. This means,  $wpd_{norm}$ could be used to measure differences in distribution across panels. Also, note that since the data is processed using normal-quantile-transform, this measure is independent of the intial distribution of the underlying data and hence is also comparable across different data sets. This is valid for the case when sample size $ntimes$ for each combination of categories is at least 30 and  $nperm$ used for computing $wpd_{norm}$ is at least 100. More detailed results about the properties of $wpd_{raw}$ and $wpd_{norm}$ could be found in Appendix.

## Simulation environment

Simulation studies were carried out to study the behavior of $wpd$, build the normalization method as well as compare and evaluate different normalization approaches. R version 4.0.1 (2020-06-06) is used with the platform: x86_64-apple-darwin17.0 (64-bit) running under: macOS Mojave 10.14.6 and MonaRCH, which is a next-generation HPC/HTC Cluster, designed from the ground up to address the computing needs of the Monash HPC community.


# Ranking and selecting significant harmonies

Complete randomness in the measured variable indicates that the process follows a homogeneous underlying distribution over the whole time series, which essentially implies there is no interesting distinction across any different categories of the cyclic granularities. We can remove the harmonies for which no interesting patterns are observed through a randomization permutation method. Essentially, the assumption is that under the null hypothesis, there is no difference in categories between the pair of cyclic granularities in the chosen harmony. This method is based on the generation of randomly chosen reassignments (permutations) of the data across different cyclic granularities and the computation of 
$wpd_{norm}$ for each of these reassignments. The percentages of times the theoretical distribution greater than or equal to the respective observed $wpd_{norm}$ values are calculated and are used to obtain the P value. The procedure for the permutation test is:

<!-- **Assumption:** random permutation of the data keeping the categories of the cyclic granularities constant. -->

1. Given the data; $\{v_t: t=0, 1, 2, \dots, T-1\}$, the $wpd_{norm}$ is computed and is represented by $wpd_{obs}$.

2. From the original sequence a random permutation is obtained: $\{v_t^*: t=0, 1, 2, \dots, T-1\}$.

3. $wpd_{norm}$ is computed for the permuted sequence of the data and is represented by $wpd_{perm_1}$.

4.  Steps (2) and (3) are repeated a large number
of times M (M = 200).

5. For each permutation, one $wpd_{perm_i}$ is obtained. Define $wpd_{sample} = \{wpd_{perm_1}, wpd_{perm_2}, \dots, wpd_{perm_M}\}$.

6. $95^{th}$ percentile of this $wpd_{sample}$ distribution is computed and stored in $wpd_{threshold}$.

7. If $wpd_{obs}> wpd_{threshold}$, harmony pairs are accepted. Only one threshold for all harmony pairs.


The p-value of the design $D_{null}$ is size.
The p-value of other designs is power.
Confidence interval of the 
  

```{r, eval = FALSE, echo = FALSE}
smart_harmony <-read_rds("data/smart_harmony_nonst.rds")
smart_harmony
```



```{r smart_harmony,eval = FALSE, echo = FALSE}

sm <- smart_meter10 %>% dplyr::filter(customer_id %in% c("10017936"))

harmonies <- sm %>% 
  harmony(ugran = "month",
          filter_in = "wknd_wday",
          filter_out = c("hhour", "fortnight"))


harmony_tbl =  harmonies

smart_harmony <- sm %>% 
  rank_harmony(harmony_tbl = harmonies,
               response = "general_supply_kwh", 
               dist_ordered = TRUE)

smart_harmony %>% 
  mutate(MMPD = round(MMPD, 3), max_pd = round(max_pd, 3)) %>% 
  mutate(rankn = row_number()) %>%
  rename("rankun" = "r") %>% kable()
```

The p-value is almost always greater than 0.05, which means there is no significant differences between the different categories, which is true from the simulation design.


```{r size}
library(readr)
library(tidyverse)
data_N01 <- read_rds(here("simulations/norm/null_design_quantrans_nperm/data-agg/all_data_wpd_N01.rds"))

data_N01_obs <- data_N01 %>% filter(perm_id==1)
data_N01_samp <- data_N01 %>% filter(perm_id!=1)

#plot_mmpd_null_grid(data_N01_samp, data_N01_obs)

mmpd_dist_null_grid  = data_N01_samp

mmpd_null_orig = data_N01_obs
compute_p_value <- left_join(mmpd_dist_null_grid, mmpd_null_orig,
                               by = c("nx", "nfacet")) %>% 
    group_by(nx, nfacet) %>% 
    summarise(p_value = sum(if_else(abs(value.x)>abs(value.y),1,0))/n(), .groups = 'drop')

  ggplot() + 
    geom_histogram(data = mmpd_dist_null_grid, aes(x = value))  + 
    geom_vline(data = mmpd_null_orig, aes(xintercept = value),colour = "red") +
    geom_text(data = round(compute_p_value, 3), size = 3,  
              aes(x = -Inf,
                  y =  Inf,
                  label = paste("p-value:",p_value),
                  hjust   = 0,
                  vjust   = 1)) + 
    facet_grid(nx ~ nfacet)
```


```{r power}
library(readr)
library(tidyverse)
data_N01 <- read_rds(here("simulations/norm/null_design_quantrans_nperm/data-agg/all_data_wpd_N01.rds"))

data_N01_obs <- data_N01 %>% filter(perm_id==1)
data_N01_samp <- data_N01 %>% filter(perm_id!=1)

#plot_mmpd_null_grid(data_N01_samp, data_N01_obs)

mmpd_dist_null_grid  = data_N01_samp

mmpd_null_orig = data_N01_obs
compute_p_value <- left_join(mmpd_dist_null_grid, mmpd_null_orig,
                               by = c("nx", "nfacet")) %>% 
    group_by(nx, nfacet) %>% 
    summarise(p_value = sum(if_else(abs(value.x)>abs(value.y),1,0))/n(), .groups = 'drop')

  ggplot() + 
    geom_histogram(data = mmpd_dist_null_grid, aes(x = value))  + 
    geom_vline(data = mmpd_null_orig, aes(xintercept = value),colour = "red") +
    geom_text(data = round(compute_p_value, 3), size = 3,  
              aes(x = -Inf,
                  y =  Inf,
                  label = paste("p-value:",p_value),
                  hjust   = 0,
                  vjust   = 1)) + 
    facet_grid(nx ~ nfacet)
```




#### Characteristics under different simulation designs   
A set of simulation runs that are conducted and some outputs of which are reported.


```{r sim_all, echo = FALSE}
bind_files = readr::read_rds("../hakear-drake/data/compute_p_value.rds")

bind_files$design = 
  factor(bind_files$design,
         levels = c("null","vary_f", "vary_x", "vary_all"), labels = c("D1", "D2", "D3", "D4"))

ggplot(bind_files %>% 
         filter(distribution == "normal")) +
  geom_point(aes(x=design, y = p_value),
                 alpha = 0.5)+
  facet_grid(nx~nfacet) +
  geom_line(aes(x = design, y = p_value, group = distribution, color = distribution))

ggplot(bind_files %>% 
         filter(distribution == "exponential")) +
  geom_point(aes(x=design, y = p_value),
                 alpha = 0.5)+
  facet_grid(nx~nfacet) +
  geom_line(aes(x = design, y = p_value, group = distribution, color = distribution))

ggplot(bind_files %>% 
         filter(distribution == "gamma")) +
  geom_point(aes(x=design, y = p_value),
                 alpha = 0.5)+
  facet_grid(nx~nfacet) +
  geom_line(aes(x = design, y = p_value, group = distribution, color = distribution))

ggplot(bind_files %>% 
         filter(distribution == "weibull")) +
  geom_point(aes(x=design, y = p_value),
                 alpha = 0.5)+
  facet_grid(nx~nfacet) +
  geom_line(aes(x = design, y = p_value, group = distribution, color = distribution))
```

```{r sim_conf, echo = FALSE, eval = FALSE}
library(dplyr)
library(ggplot2)
ggplot2::ggplot(design_all %>% 
                      filter(design == "D1", distribution == "norm")) +
  geom_boxplot(aes(x = as.factor(nx), 
                   y = mmpd.x), width = 0.1) + 
  facet_wrap(~nfacet) +
  scale_fill_viridis_d() +
  xlab("number of x levels") +
  coord_flip()

```



# Application in residential smart meter data {#sec:application}

```{r household2and4}
id2_tsibble <- elec %>% 
   filter(id == 2) %>% 
   as_tsibble(index = date_time)
  
id4_tsibble <- elec %>% 
   filter(id == 4) %>% 
   as_tsibble(index = date_time)



harmonies2 <- id2_tsibble %>%
  harmony(
    ugran = "month",
    filter_in = "wknd_wday",
    filter_out = c("hhour", "fortnight")
  )




harmonies4 <- id4_tsibble %>%
  harmony(
    ugran = "month",
    filter_in = "wknd_wday",
    filter_out = c("hhour", "fortnight")
  )


library(tictoc)
tic()

all_harmony2 <- hakear::select_harmonies(id2_tsibble,
   harmony_tbl = harmonies2,
   response = kwh,
   nperm = 200,
   nsamp = 200
 )

toc()


library(tictoc)
tic()
all_harmony4 <- hakear::select_harmonies(id2_tsibble,
   harmony_tbl = harmonies2,
   response = kwh,
   nperm = 200,
   nsamp = 20
 )
toc()

```




# Discussion points and future work

Exploratory data analysis involve many iterations of finding and summarizing patterns. With temporal data available at ever finer scales, exploring periodicity has become overwhelming with so many possible granularities to explore. This work refines the selection of appropriate pairs of granularities by identifying those for which the differences between the displayed distributions is greatest, and rating these selected harmony pairs in order of importance for exploration.

A future direction of work could be to look at more individuals/subjects and group them according to similar periodic behavior. Behaviors across different cyclic granularities would be different for different subjects and one way to find groups would be to actually locate clusters who have similar periodic behavior.

<!-- patterns are interesting and others are not. The subjects for which behaviors across a group of cyclic granularities are similar, could be grouped together as their periodic behavior is similar.  to group subjects  -->

# Appendix

## Null distribution

### Size: Simulated same distribution for all combinations of categories for all harmony pairs.

Failure to reject the null hypothesis when there is in fact no significant effect.

### Normalised maximum distances follow standard Gumbel distribution

### Limiting distribution of median of normalised maximum distances is normal

Let a continuous population be given with cdf F(x) (cumulative distribution function) and median $\xi$ (assumed to exist uniquely). For a sample of size $2n + 1$, let $\tilde{x}$ denote the sample median. The distribution of $\tilde{x}$,under certain conditions, to be asymptotically normal with mean $\xi$ and variance $\sigma_n^2 = \frac{1}{4} [f(\xi)]^2(2n + 1)$, where $f(x) = F'(x)$ is the pdf (probability density function).


<!-- ### Confidence interval of test statistic -->

## Power

## Confidence interval

Failure to reject the null hypothesis when there is in fact a significant effect.

To estimate the sampling distribution of the test statistic we need many samples generated under the null hypothesis. If the null hypothesis is true, changing the exposure would have no effect on the outcome. By randomly shuffling the exposures we can make up as many data sets as we like. If the null hypothesis is true the shuffled data sets should look like the real data, otherwise they should look different from the
real data. The ranking of the real test statistic among the shuffled test statistics gives a p-value.

<!-- Consider two cyclic granularities $A$ and $B$ with $2$ and $3$categories. Thus, the harmony table consisting of all possible harmony pairs (assuming all pairs are harmonies), would look like the following: -->

```{r harmony_min}
# harmonies <- tibble::tibble(facet_variable = c("A", "B", "A", "C", "B", "C"),
#                             x_variable  = c("B","A", "C", "A", "C", "B"),
#                             facet_levels = c(2, 3, 2, 4, 3, 4),
#                             x_levels = c(3, 2, 4, 2, 4, 3))
# 
# harmonies <- tibble::tibble(facet_variable = c("A", "B"),
#                             x_variable  = c("B","A"),
#                             facet_levels = c(2, 3),
#                             x_levels = c(3, 2))
#                             
# harmonies %>% knitr::kable()
```

<!-- The output table has the value of MMPD (normalized median maximum pairwise distances), gt_MMPD(global threshold of MMPD indicator). -->

<!-- # ```{r samenull_2by4, eval = FALSE} -->
<!-- #  -->
<!-- # ``` -->

<!-- # ```{r normalv21_power} -->
<!-- #  -->
<!-- # ``` -->
<!-- #  -->
<!-- #  -->
<!-- # ```{r normalv22_power} -->
<!-- #  -->
<!-- # ``` -->

### Varying distribution across facet
### Varying distribution across x-axis
### Varying distribution across both facets and x-axis
### Repeat all with varying facet and x-axis levels

<!-- ### Power: Simulated same distribution for all combinations of categories for all harmony pairs. -->



<!-- # ```{r normalv23_power} -->
<!-- #  -->
<!-- # ``` -->
<!-- #  -->
<!-- #  -->
<!-- # ```{r normalv24_power} -->
<!-- #  -->
<!-- # ``` -->


*Conclusion*: The test should reject the null hypothesis if distributions are different.

<!-- ### Scenario 2: Simulated different distributions for all combinations of categories for harmony pairs for few levels. -->



<!-- ```{r diffnull_2by4, eval = FALSE} -->

<!-- ``` -->


<!-- *Conclusion*: The test select the harmony pair for which distribution of x-axis categories are significantly different -->


<!-- ### Scenario 3: Simulated different distributions for all combinations of categories for all harmony pairs with many levels. -->


<!-- ```{r diffnull_7by11, eval = FALSE} -->
<!-- ``` -->

<!-- *Conclusion*: The test indicates that both harmony pairs do not have significant variation. -->


<!-- ### Scenario 4: Simulated different distributions for all combinations of categories for all harmony pairs with many levels - very different distribution across x-axis -->


<!-- ```{r diffnull_7by11normal, eval = FALSE} -->
<!-- ``` -->

<!-- *Conclusion*: The test indicates that only the first harmony pair has significant variation. -->


<!-- ### Scenario 5: Simulated different distributions for all combinations of categories for all harmony pairs with many levels - very different distribution across facets -->


<!-- ```{r diffnull_7by11normal2, eval = FALSE} -->
<!-- ``` -->


<!-- *Conclusion*:  -->



<!-- ## Scenario 4: Cumulative 3 levels with 2, 7 and 11 and testing level and power -->

<!-- ```{r samenull_3levels} -->

<!-- ``` -->


<!-- *Conclusion*: With 3 levels the test incorrectly chooses 1 harmony pair with similar distribution. The harmony pair which is displayed. -->

<!-- <!-- ```{r diffnull_3levels} --> 

<!-- <!-- ``` --> 

<!-- *Conclusion*: The test with MMPD selects just one pair, as opposed to the test with maximum. This needs to be checked against what we expect from the test. The harmony pairs which are selected (either through MMPD or maximum) are displayed. -->


<!-- # ```{r} -->
<!-- # harmonies <- tibble::tibble(facet_variable = c("A", "B"),x_variable  = c("B","A"), facet_levels = c(2, 3),x_levels = c(3, 2)) -->
<!-- #  -->
<!-- # har1 <- harmonies[1,] -->
<!-- #  -->
<!-- # sim_dist1 = c(rep(distributional::dist_normal(mu = 10, sigma = 5),2),rep(distributional::dist_exponential(10),2), rep(distributional::dist_weibull(0.5, 2),2)) -->
<!-- #  -->
<!-- # data1 <- sim_distharmony1(har1, sim_dist = sim_dist1) -->
<!-- # data1 -->
<!-- #  -->
<!-- # data1 %>% unnest(sim_dist) %>% -->
<!-- #   ggplot(aes(x = Var2, y = sim_dist)) + -->
<!-- #   facet_wrap(~Var1) + geom_boxplot() + ggtitle("Same distribution 2 by 3") -->
<!-- #  -->
<!-- # response = "sim_dist" -->
<!-- #  -->
<!-- # MMPD_distribution <- data1 %>% -->
<!-- #   select(-dist) %>%  -->
<!-- #   unnest(sim_dist) %>%  -->
<!-- #   list() %>%  -->
<!-- #   global_threshold(harmony_tbl = har1, -->
<!-- #                    response = "sim_dist", -->
<!-- #                    dist_distribution = "normal", -->
<!-- #                    dist_ordered = TRUE, -->
<!-- #                    create_gran_data = FALSE, nsamp = 20) -->
<!-- #  -->
<!-- # # as_tibble(sample_MMPD) %>% mutate(id = row_number()) %>%  -->
<!-- # #   ggplot() + geom_histogram(aes(x = value)) -->
<!-- #  -->
<!-- # ``` -->
<!-- #  -->

<!-- # Visualisation -->

<!-- Leader plots like in Scagnostics paper -->

