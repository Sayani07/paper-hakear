---
title: Selecting and ranking interesting pairs of cyclic temporal granularities
authors:
- name: Sayani Gupta
  affiliation: Department of Econometrics and Business Statistics, Monash University
  email: Sayani.Gupta@monash.edu

bibliography: bibliography.bib
preamble: >
  \usepackage{mathtools,booktabs,amsthm,todonotes,colortbl}
  \def\mod{~\text{mod}~}
  \newtheorem{definition}{Definition}
  \usepackage{mathptmx}
  \usepackage{caption}
  \usepackage{algorithm}
  \usepackage{algorithmicx}
  \usepackage{algpseudocode}
  \DeclareCaptionStyle{italic}{labelfont={bf},textfont={it},labelsep=colon}
  \captionsetup[figure]{style=italic,format=hang,singlelinecheck=true}
  \captionsetup[table]{style=italic,format=hang,singlelinecheck=true}
  \def\novspacing{\setlength{\aboverulesep}{0pt}\setlength{\belowrulesep}{0pt}}
  \def\vspacing{\setlength{\aboverulesep}{0.4ex}\setlength{\belowrulesep}{0.65ex}}
output:
  bookdown::pdf_book:
    #base_format: rticles::asa_article
    fig_height: 5
    fig_width: 8
    fig_caption: yes
    dev: "pdf"
---

```{r initial, echo = FALSE, cache = FALSE, include = FALSE}
options("knitr.graphics.auto_pdf" = TRUE,
        tinytex.verbose = FALSE)
library(knitr)
library(tidyverse)
library(lubridate)
library(lvplot)
library(ggridges)
library(viridis)
library(tsibble)
library(gravitas)
library(ggpubr)
library(readr)
library(kableExtra)
library(distributional)
library(ggplot2)
library(sugrrants)
library(here)

opts_chunk$set(
  echo = FALSE, warning = FALSE, message = FALSE, comment = "#>",
  fig.path = "figure/", fig.align = "center", fig.show = "hold",
  cache = TRUE, cache.path = "cache/",
  out.width = ifelse(is_html_output(), "100%", "\\textwidth")
)
knitr::opts_knit$set(root.dir = here::here())
#                                                                read_chunk('main.R')
here::here()
#knitr::read_chunk(here::here("paper/R/", "null_distribution.R"))
#knitr::read_chunk(here::here("paper/R/", "mean_null.R"))
#source(here::here("paper/R/sim_panel.R"))
# Set up plan
#source("_drake.R")
# Run all code required
#drake::r_make()
# load each object as required
# loadd()
```


```{r}
set.seed(321)
```


# Introduction

<!-- <introducing the problem> -->
<!-- background of the problem -->

Exploratory data analysis, as coined by John W. Tukey (Tukey 1965) involves many iterations of finding structures and patterns that allows the data to be informative. With temporal data available at finer scales, exploring periodicity and their relationships can become overwhelming with so many possible cyclic temporal granularities [@Gupta2020-vo] to explore.

```{r calendar-elec, fig.height = 10.5, fig.cap="Calendar display."}
elec <- read_rds(here("paper/data/elec.rds")) %>% 
  filter(date >= ymd("20180101"), date < ymd("20180701"))
rdbl <- c("Weekday" = "#d7191c", "Weekend" = "#2c7bb6")

elec <- elec %>% 
  mutate(
    wday = wday(date, label = TRUE, week_start = 1),
    weekday = if_else(wday %in% c("Sat", "Sun"), "Weekend", "Weekday")
  )
p_cal_elec <- elec %>% 
  filter(id %in% c(2, 4)) %>% 
  frame_calendar(x = time, y = kwh, date = date, nrow = 1) %>% 
    ggplot(aes(x = .time, y = .kwh, group = date)) +
    geom_line(aes(colour = as.factor(id)), size = 0.5) +
    scale_colour_brewer(name = "", palette = "Dark2", direction = 1) +
    facet_grid(id ~ ., labeller = label_both) +
    theme(legend.position = "bottom")
prettify(p_cal_elec, size = 2.5, label.padding = unit(0.1, "lines"))
```

\noindent Take the example of the calendar display of electricity smart meter data (\ref{fig:calendar-elec}) used in @wang2020calendar for four households in Melbourne, Australia. The authors show how hour-of-the-day interact with weekday and weekends and then move on to use calendar display to show daily schedules. The calendar display has several components in it, which helps us look at energy consumption across hour-of-the-day, day-of-the-week, week-of-the-month, and month-of-the-year at once. Some interaction of these cyclic granularities could also be interpreted from this display. This is a great start to have an overview of the energy consumption. However, if one wants to understand the periodicities in energy behavior and how the periodicities interact in greater details, it is not easy to comprehend the interactions of some periodicities' from this display, due to the combination of linear and cyclic representation of time. For example, this display might not be the best to understand how hour-of-the-day varies and month-of-year varies across week-of-the-month. Further, it is not clear what all interactions of cyclic granularities should be read from this display as there could be many combinations that one can look at. Moreover, calendar effects are not restricted to conventional day-of-week or month-of-year deconstructions (@Gupta2020-vo) and could include other cyclic granularities like hour-of-week or day-of-fortnight, which could potentially become useful depending on the context. 

```{r intro_all}

id2_tsibble <- elec %>% 
   filter(id == 2) %>% 
   as_tsibble(index = date_time)
  
id4_tsibble <- elec %>% 
   filter(id == 4) %>% 
   as_tsibble(index = date_time)

# hour-of-day and month-of-year (important pair) id2's behavior across different hours of the day very different across months, but for id4 behavior across different hours of the day is not likely a function of month.
p1 <- id2_tsibble %>%
   prob_plot("month_year",
             "hour_day",
             response = "kwh",
             plot_type = "quantile",
             symmetric = TRUE,
             quantile_prob = c(0.1, 0.25,0.5,0.75, 0.9)) +
  ggtitle("") + theme(
        strip.text = element_text(size = 10, margin = margin(b = 0, t = 0))) + 
  scale_colour_brewer(name = "", palette = "PiYG")

p2 <- id4_tsibble %>%
   prob_plot("month_year",
             "hour_day",
             response = "kwh",
             plot_type = "quantile",
             symmetric = TRUE,
             quantile_prob = c(0.1, 0.25,0.5,0.75, 0.9)) + 
  ggtitle("") + theme(
        strip.text = element_text(size = 10, margin = margin(b = 0, t = 0)))

# wknd_wday and week_month (important pair) id2's behavior across different hours of the day very different across months, but for id4 behavior across different hours of the day is not likely a function of month.

p3 <- id2_tsibble %>%
  create_gran("week_month") %>% 
  filter(week_month != 5) %>% 
   prob_plot("wknd_wday",
             "week_month",
             response = "kwh",
             plot_type = "quantile",
             symmetric = FALSE,
             quantile_prob = c(0.25,0.5,0.75)) +
   ggtitle("") +
#scale_x_discrete(breaks = seq(0, 23, 4))  + theme(
        theme(strip.text = element_text(size = 10, margin = margin(b = 0, t = 0)))

p4 <- id4_tsibble %>%
    create_gran("week_month") %>% 
  filter(week_month != 5) %>% 
   prob_plot("wknd_wday",
             "week_month",
             response = "kwh",
             plot_type = "quantile",
             symmetric = FALSE,
             quantile_prob = c(0.25,0.5,0.75)) +
  ggtitle("") +  #+ scale_x_discrete(breaks = seq(0, 23, 4)) + 
theme(
        strip.text = element_text(size = 10, margin = margin(b = 0, t = 0)))

```

```{r id2, fig.cap = "something"}
ggpubr::ggarrange(p1, p2, ncol = 2)
```

```{r id4, fig.cap = "something2"}
ggpubr::ggarrange(p3, p4, ncol = 2)
```

Moreover, there might be specific interactions that are interesting and others that are not and that too will vary with different households. For example, area distribution quantiles are plotted for household 2 and 4 in Figure \ref{fig:id2}a and b respectively. For the first household, the 75th and 90th percentile for Jan, Feb and July are very close, implying that energy usage for these months are generally on a much higher side due to the usage of air conditioners (in Jan and Feb) and heaters (in July). The energy consumption for household 2 is also higher relative to its own consumption for Jan, Feb and March but the 75th and 90th percentile are apart implying that contrary to the first household, the second household resorts to air conditioners and heaters much less regularly than the first one. Moreover, the 75th percentile distribution is not bimodal across hours of the day for the first household in those months, but the distribution looks similar for all months for the second household. Difference in the energy consumption seem to be varying both across month-of-year (facets) and hour-of-day (x-axis). And thus, both the cyclic granularities would deem important while studying the periodicities in the first household. However, it seems like energy consumption across hours of the day are not that different across different months for the second household. Differences seem to be more prominent across month-of-year (facets) than hour-of-day (x-axis). Again, look at \ref{fig:} c and d, where energy consumption for these two households are plotted against (weekend/weekday, week-of-month). Here, for both households, the pattern of energy consumption vary  across different weeks of the month irrespective of the fact it is a weekday or weekend. In that respect, the harmony pair (month-of-year, hour-of-day) seems to be more informative than (weekend/weekday, week-of-month) for the first household. It could be immensely useful to make the transition from all possible ways to only ways that could potentially be informative given a household. 

<!-- Take an example of a data set which are observed at fine temporal scales, like that of NYC bike usage available at https://www.citibikenyc.com/system-data. We use the `nyc_bikes` data set from the R package `tsibbledata` which takes a sample of 10 bikes for the year 2018. The `start_time` and the `stop_time` are recorded to a fineness of seconds. We can look at pair of cyclic granularities (hour_day, wknd_wday) or (week_month, day_week) to see how these periodicities interact. But there could be other pairs that are important too. How to understand which pairs are sufficient to explore given the data set without losing much information about the data. -->

<!-- When we need to understand the interplay of different periodicities in a high frequency temporal datasets, we have many choices to consider. In [@wang2019tsibble] and [@wang2020calendar], periodicities are explored across hour of the day and day of the week or months. But calendar effects are not restricted to conventional day-of-week or month-of-year deconstructions. -->

<!-- what is the dimension of the problem -->
The paper @Gupta2020-vo describes how we can compute all possible combinations of cyclic time granularities. If we have $n$ periodic linear granularities in the hierarchy table, then $n(n-1)/2$ circular or quasi-circular cyclic granularities could be constructed. Let $N_C$ be the total number of contextual circular, quasi-circular and aperiodic cyclic granularities that can originate from the underlying periodic and aperiodic linear granularities. The mapping of the graphical elements chosen in the paper implies that, for a numeric response variable, the graphics display distributions across combinations of cyclic granularities, one placed at x-axis and the other on the facet. That essentially implies there are $^{N_C}P_2$ possible pairwise plots exhaustively, where each plot would display a pair of cyclic granularities. This is large and overwhelming for human consumption.

<!-- Scagnostics literature -->
This is similar to Scagnostics (Scatterplot Diagnostics) by @tukey1988computer, which is used to discern meaningful patterns in large collections of scatterplots. Given a set of $v$ variables, there are $v(v-1)/2$ pairs of variables, and thus the same number of possible pairwise scatterplots. Therefore
for even small $v$, the number of scatterplots can be
large, and scatterplot matrices (SPLOMs) could easily run out of pixels when presenting high-dimensional data. @Dang2014-tw and @wilkinson2005graph provides potential solutions to this, where few characterizations help us to locate anomalies for defining several measures aimed to detect anomalies in density, shape, trend, and
other features in the 2D point scatters.

<!-- harmonies and why it is not enough -->
The paper (@Gupta2020-vo) narrows down the search from $^{N_C}P_2$ plots by identifying pairs of granularities that can be meaningfully examined together (a "harmony"), or when they cannot (a "clash"). However, even after excluding clashes, the list of harmonies left could be enormous for exhaustive exploration. Hence, there is a need to reduce the search even further by including only those harmonies which are informative enough. Also, ranking the remaining harmony pairs based on how well they capture the variation in the measured variable could be potentially useful.  

In this paper, we aim to build a new measure to follow through these two main objectives:

- To choose harmonies for which distributions of categories are significantly different 
- To rank the selected harmonies from highest to lowest variation in the distribution of their categories.

<!-- Talk about Scagnostics: Tukey -->

# The proposed distance measure

We are interested in assessing structure in probability distributions of the measured variable across bivariate cyclic granularities. We propose a measure called Weighted Maximum Pairwise Distances (wpd) to evaluate structure in such a design.


## Idea {#sec:idea}

The principle employed for building a new metric is explained through a simple example explained in Figure \ref{fig:null4by2}. Each of these figures have the same panel design with 2 x-axis categories and 4 facet levels. Figure \ref{fig:null4by2}a has all x categories drawn from N(5, 10) distribution for each facet. It is not an interesting display particularly, as distributions do not vary across x-axis or facet categories. Figure \ref{fig:null4by2}b has x categories drawn from the same distribution within a facet and different for different facet categories. Figure \ref{fig:null4by2}b exhibits an exact opposite situation where distribution between the x-axis categories within each facet is different but they are same across facets. Figure \ref{fig:null4by2}d takes a step further by varying the distribution across both facet and x-axis categories. If we are asked to rank the displays in order of importance from minimum to maximum, we might order it as a, b, c and then d. It might be argued that it is not clear if b should precede or succeed c. Gestalt theory suggests that when items are placed in close proximity, people assume that they are in the same group because they are close to one another and apart from other groups. Hence, displays that capture more variation within different categories in the same group would be important to bring out different patterns of the data. With this principle, display b could be considered less informative as compared to display c.

With reference to the graphical design in \ref{@Gupta2020-vo}, therefore the idea would be to rate a harmony pair higher if the variation between different levels of the x-axis variable is higher on an average across all levels of the facet variables. Thus the metric could be obtained by computing maximum pairwise distances between distributions of the continuous random variable across x-axis categories for all facets and then taking the median of those maximum pairwise distances across facets. This would help capture the average maximum difference in distribution of the measurement variable explained by the two cyclic granularities together. We call this metric wpd which stands for Median Maximum Pairwise Distances. In the next section we shall see how we go about computing this measure.



<!-- To elaborate further, look at the examples in Figure \ref{}, where Figure \ref{}a represents the panel design with distribution of each x categories drawn from N(5, 10) distribution. It could be observed that the graph is not particularly interesting, as there is no significant change in distribution between x-axis levels or facets. Figure \ref{}b represents the same panel design with no difference in distribution of x-axis categories within a facet, but different distribution of x-axis categories for different facets. For example, if there are 4 facet levels and 2 x-axis levels, data is generated in the way as described in Table \ref{}. Figure \ref{}b exhibits an exact opposite situation where the x-axis within facets are different but not across facets. -->
<!-- Figure \ref{}d takes it further by varying the distribution across both facet and x-axis categories. -->



```{r null4by2,fig.cap=" A graphical display with two categories mapped to x-axis and 4 categories mapped to facets with the distribution of a continuous random variable plotted on the y-axis. Display a is not interesting as the distribution of the continuous rv does not depend across x-axis or facet categories. Display b and c are more interesting than a since there is a change in distribution either across facets(b) or x-axis(a). Display d is most interesting as distribution of the rv changes across both facet and x-axis variable."}


sim_varf_dist1 = function(nx, nfacet){
  rep(dist_normal(seq(mean,mean*nfacet, by = mean), sd), each = nx)}

p1 <- sim_panel(nx = 2, nfacet = 3, ntimes = 500) %>%
  ggplot(aes(x = as.factor(id_x), y = sim_data)) + facet_wrap(~id_facet) + geom_boxplot()

simulated_data <- sim_panel(nx = 2,
          nfacet = 3,
          ntimes = 500,
          sim_dist = rep(dist_normal(seq(5, 15, 5), 5), each = 2)) 


p2 <- simulated_data %>% ggplot(aes(x = as.factor(id_x), y = sim_data)) + facet_wrap(~id_facet) + geom_boxplot()

p3 <- simulated_data %>% ggplot(aes(x = as.factor(id_facet), y = sim_data)) + facet_wrap(~id_x) + geom_boxplot()

p4 <- sim_panel(nx = 2,
          nfacet = 3,
          ntimes = 500,
          sim_dist = dist_normal(seq(5,30, 5), 5)) %>% 
  ggplot(aes(x = as.factor(id_x), y = sim_data)) + facet_wrap(~id_facet) + geom_boxplot()


ggpubr::ggarrange(p1, p2, p3, p4, nrow = 2, ncol = 2,
                  common.legend = TRUE,
                  labels = c("a", "b", "c", "d"))

```


<!-- in the same group would be important to bring out different patterns of the data. -->

## Characterising distributions

Each of the data subsets in the data structure have multiple observations and may vary widely across different subsets due to the structure of the calendar, missing observations or uneven locations of events in the time domain. The set of observations corresponding to each combination is assumed to be a sample from an unknown probability density function.
While the whole population of observations has certain characteristics, we can typically never measure all of them. Often shape, central tendency, and variability are the common characteristics used to describe the distribution. Another way to describe the probability distribution is through quantiles. (Define quantiles here) <!--There are two broad approaches to quantile estimation, viz, parameteric and non-parameteric. The benefit of using a non-parametric estimator is that there are less rigid assumptions made about the nature of the underlying distribution of the data.--> Sample quantiles could be thought to estimate the population quantiles. But there are a large number of different definitions used for sample quantiles. The median-unbiased estimator is recommended (Rob's paper) because of its desirable properties of a quantile estimator and can be defined independently of the underlying distribution. 


## Distance between distributions

<!-- One of the most important class of divergence is the f-divergence and includes measures like Kullback-Leibler divergence, Hellinger distance etc. The continuous version of f -divergence is given by -->
<!-- $$D_f(P||Q) := \int q(x)f(\frac{p(x)}{q(x)})$$, where -->
<!-- $f : [0,\infty) \rightarrow R \cup \{\infty\}$ is a continuous convex function, and $f(1) = 0$.  -->
  
The most common divergence measure between distributions is the Kullback-Leibler (KL) divergence[@Kullback1951-jy] introduced by Solomon Kullback and Richard Leibler in 1951. The KL divergence, denoted $D(p(x), q(x))$ is a non-symmetric measure of the difference between two probability distributions $p(x)$ and $q(x)$ and is interpreted as the amount of information lost when $q(x)$ is used to approximate $p(x)$. Although the KL divergence measures the “distance” between two distributions, it is not a distance measure since it is not symmetric and does not satisfy the triangle inequality. The Jensen-Shannon divergence [@Menendez1997-in] based on the Kullback-Leibler divergence is symmetric and it always has a finite value. The square root of the Jensen-Shannon divergence is a metric, often referred to as Jensen-Shannon distance. Other common measures of distance are Hellinger distance, total variation distance and Fisher information metric. 

In the context of this paper, the pairwise distances between the distributions of the measured variable are computed through Jensen-Shannon distance (JSD) which is based on Kullback-Leibler divergence and is defined by,

$$JSD(P||Q) = \frac{1}{2}D(P||M) + \frac{1}{2}D(Q||M)$$
where $M = \frac{P+Q}{2}$ and 
$D(P||Q) := \int^\infty_{-\infty} p(x)f(\frac{p(x)}{q(x)})$ is the KL divergence between distributions $p(x)$ and $q(x)$. Probability distributions are estimated through quantiles instead of kernel density so that there is minimal dependency on selecting kernel or bandwidth.

<!-- The Jensen-Shanon distance between two probability distribution $p_1$ and $p_2$ is given by $$d = [D(p_1, r) + D(p_2, r)]/2 \quad where \quad r = (p_1 + p_2)/2$$ where, -->
<!-- $$D(p_1,p_2) = \int^{\infty}_{-\infty}p_1(x)log\frac{p_1(x)}{p_2(x)}\,dx$$ is the Kullback-Leibler divergence between $p_1$ and $p_2$.   -->

<!-- We call this measure of variation as  Median Maximum Pairwise Distances (MMPD). -->



<!-- #### Distribution of Jensen-Shannon distances -->

<!-- Jensen-Shannon distances (JSD) are distributed as chi-squared with $m$ df where we discretize the continuous distribution with $m$ discrete values. Taking sample percentiles to approximate the integral would mean taking $m = 99$. -->
<!-- With large $m$, chi-squared is asymptotically normal by the CLT. Thus, by CLT, ${\chi^2}_{m} \tilde{} N(m, 2m)$, which would depend on the number of discretization used to approximate the continuous distribution. Then $b_n = 1-1/n$ quantile of the normal distribution and $a_n = 1/[n*\phi(b_n)]$ where $\phi$ is the normal density function. $n$ is the number of pairwise comparisons being made. -->


## Definition of the proposed distance measure

Consider two cyclic granularities $A$ and $B$, such that $A = \{ a_j: j = 1, 2, \dots, J\}$ and $B = \{ b_k: k = 1, 2, \dots, K\}$ with $A$ placed across x-axis and $B$ across facets. Let the pairwise distances between pairs $(a_{j} b_{k}, a_{j'}b_{k'})$ be denoted as $d_{(jk, j'k')} = JSD(a_{j}b_{k}, a_{j'}b_{k'})$. Pairwise distances could be within-facets or between-facets. Figure \ref{fig:distance-explain} illustrates how the within-facet or between-facet distances are defined. Pairwise distances are within-facets ($d_{w}$) when $b_{k} = b_{k'}$, that is, between pairs of the form $(a_{j}b_{k}, a_{j'}b_{k})$ as shown in panel (3) of Figure \ref{fig:distance-explain}. If categories are ordered (like all temporal cyclic granularities), then only distances between pairs where $a_{j'} = (a_{j+1})$ are considered (panel (4)). Pairwise distances are between-facets ($d_{b}$) when they are considered between pairs of the form $(a_{j}b_{k}, a_{j}b_{k'})$.


```{r distance-explain, fig.cap = "Within and between-facet distances shown for two cyclic granularities A and B, where A is mapped to x-axis and B is mapped to facets. The dotted lines represent the distances between different categories. Panel 1) and 2) show the between-facet distances. Panel 3) and 4) are used to illustrate within-facet distances when categories are un-ordered or ordered respectively. When categories are ordered, distances should only be considered for consecutive x-axis categories. Between-facet distances are distances between different facet levels for the same x-axis category, for example, distances between {($a_1$,$b_1$) and ($a_1$, $b_2$)} or {($a_1$,$b_1$) and ($a_1$, $b_3$)}."}
knitr::include_graphics(here::here("paper/Figs/dist_explain.png"))
```
  
From Section \ref{sec:idea}, the idea is to put more weights on within-facet distances than between-facet distances. Hence, for a suitable tuning parameter $\lambda > 1$, the pairwise distances $d_{(jk, j'k')}$ are transformed based on the distance type as follows:

\begin{equation}
d*_{(j,k), (j'k')} =
\begin{cases}
\lambda d_{(jk), (j'k')},& \text{if } d = d_w\\
(1-\lambda)  d_{(jk), (j'k')},              & \text{if } d = d_b\\
\end{cases}
\end{equation}

The maximum weighted pairwise distances are defined as:
$$WPD = max_{j, j', k, k'}(d*_{(jk), (j'k')})
\forall j, j' \in \{1, 2, \dots, J\}, k, k' \in \{1, 2, \dots, K\}$$.


<!-- _j$ maps index set to a set $\{B_\ell \mid \ell =1,\dots,L\}$. Here, $A_k$ and $B_\ell$ are the levels/categories corresponding to $C_i$ and $C_j$ respectively. Let $S_{k\ell}$ be a subset of the index set such that for all $s \in S_{k\ell}$, $C_i(s) = A_k$ and $C_j(s) = B_\ell$. There are $KL$ such data subsets, one for each combination of levels ($A_k$, $B_\ell$). Moreover, consider that in the graphical space, $C_i$ is mapped to facets and $C_j$ is mapped to x-axis. -->


 <!-- old -->
<!-- Consider two cyclic granularities $C_i$ and $C_j$, such that $C_i$ maps index set to a set $\{A_k \mid k=1,\dots,K\}$ and $C_j$ maps index set to a set $\{B_\ell \mid \ell =1,\dots,L\}$. Here, $A_k$ and $B_\ell$ are the levels/categories corresponding to $C_i$ and $C_j$ respectively. Let $S_{k\ell}$ be a subset of the index set such that for all $s \in S_{k\ell}$, $C_i(s) = A_k$ and $C_j(s) = B_\ell$. There are $KL$ such data subsets, one for each combination of levels ($A_k$, $B_\ell$). Moreover, consider that in the graphical space, $C_i$ is mapped to facets and $C_j$ is mapped to x-axis.  -->


<!-- The algorithm employed for computing the distance measure is summarized as follows: -->

<!-- 1. Fix harmony pair $(C_i, C_j)$. -->

<!-- 2. Fix $k$. Then there are $L$ groups corresponding to level $A_k$ of $C_i$. -->

<!-- 3. Compute  $m = \binom{L}{2}$ pairwise distances between distributions of $L$ unordered levels and $m = L-1$ pairwise distances for $L$ ordered categories. -->

<!-- 4. Identify maximum within the $m$ computed distances. -->

<!-- <!-- 5. Compute distribution of maximum distance ($M$) by shuffling the data $200$ times and finishing Steps1-4 in each case. Scale $M$ using the mean and sd of the distribution.  --> 

<!-- 5. Use Steps 1-4 to compute maximum distance for $\forall k \in  \{1, 2, \ldots, K\}$. -->

<!-- 6. Compute the distance measure MMPD_raw = median $(M_1, M_2, \dots, M_K)$. -->


<!-- \begin{algorithm}[!thb] -->
<!-- 	\caption{Calculation for a raw distance measure between two cyclic granularities $A = \{ a_j: j = 1, 2, \dots, J\}$, $B = \{ b_k: k = 1, 2, \dots, K\}$ with $A$ placed across x-axis and $B$ across facets.}\label{alg:scoreopt}. -->
<!-- 	\begin{algorithmic}[1] -->
<!-- 		\Procedure{RawMMPD}{$A = \{ a_j: j = 1, 2, \dots, J\}$, $B = \{ b_k: k = 1, 2, \dots, K\}$, $v = \{ v_t: t = 1, 2, \dots, T\}$}. -->
<!-- 		\For{$k=1:K$, $j=1:J$} -->
<!-- 		\State Find distances between pairs of all possible combinations of categories $(a_jb_k,a_j'b_k')$ by computing JSD between quantiles of the measured variable $q(v)$ across these combinations. -->
<!-- 		\State $d \gets JSD(\tilde{q(v)_{a_{j}b_{k}}},\tilde{q(v)_{a_{j}'b_{k}'}})$ -->
<!-- 		\If {$b_k = b_k'$} -->
<!-- 		\State $d* \gets \lambda d$  \Comment{upweight within-facet distances} -->
<!-- 		\Else -->
<!-- 		\State $d* \gets 1/\lambda d $ \Comment{downweight across-facet distances} -->
<!-- 		\EndFor -->
<!-- 		\State Set the raw distance measure as $max(d*)$ where max is taken over all $j, j', k, k'$. -->

<!-- 		\EndProcedure -->
<!-- 	\end{algorithmic} -->
<!-- \end{algorithm} -->

<!-- A stronger measure "max" is chosen for aggregating x-axis categories compared to "median" for aggregating facet categories as the measure is intended to put more importance in pointing towards distributional differences between x-axis categories than for facet categories. -->


## Normalisation

The distribution of wpd is different for different levels of facets and x-axis levels. This is because the statistic maximum which is used to define wpd is affected by the number of categories. The measure would have higher values if $C_i$ or $C_j$ has higher levels. However, we would ideally want a higher value of the measure only if there is significant difference between distributions across facet or x-axis categories, and not because the number of categories are higher. Therefore, in order to compare wpd across different combinations of facet and x-axis levels, we need to eliminate the impact of different levels of the facets and x-axis first and get a normalized measure. Henceforth we call the measure discussed as $wpd_{raw}$ and the normalised measure as $wpd_{norm}$. The measure $wpd_{norm}$ could potentially lead to comparison of the measure across different panels and also identifying only the interesting panels from a dataset.


## Simulation study

Most of the behavior of the measure wpd was studied via simulation. The simulations explore how wpd performs under various designs and parameters and its limitations. To study the behavior of wpd, simulations were carried out for four different designs and the following factors that could potentially have an impact on the values of wpd:


<!-- Numerous simulations were carried out in a wide range of scenarios. -->

<!-- Same scenarios were used, when possible with normalized wpd, keeping all other simulation variables constant. -->

- $nx$ (number of levels of x-axis)
- $nfacet$ (number of levels of facets)
- $\lambda$ (tuning parameter)
- $\omega$ (increment in each panel design)
- $dist$ (normal/non-normal distributions with different location and scale)
- $n$ (sample size for each combination of categories)
- $nsim$ (number of simulations)a
- $nperm$ (number of permutations of data)  
- $designs$  
$D_{null}$  (No difference in distribution)  
$D_{var_f}$ (Difference in distribution only across facets)  
$D_{var_x}$ (Difference in distribution only across x-axis)  
$D_{var_{all}}$ (Difference in distribution in both facets and x-axis)


### Environment

R version 4.0.1 (2020-06-06) is used with platform: x86_64-apple-darwin17.0 (64-bit) running under: macOS Mojave 10.14.6 and MonaRCH, which is a next-generation HPC/HTC Cluster, designed from the ground up to address the computing needs of the Monash HPC community. The nodes and the storage used are as follows:


### Results

This section reports the results of a simulation study that was carried out to evaluate the
behavior of our distance measure across all potential factors. The results are reported in two parts: for the a) raw measure and then b) normalised one to show how the loopholes for the raw measures were removed using the normalized ones.

First, the behavior of $wpd_{raw}$ and $wpd_{norm}$ is explored in designs where there is no difference in distribution between x and facet categories. We have considered different initial distributions to study the impact of initial distribution under the null setup. Using two types of distributions, viz. normal and gamma (non-normal), we generated observations for each combination of $nx$ and $nfacet$ from the following sets: $nx = \{2, 3, 5, 7, 14, 20, 31, 50\}$ and $nfacet = \{2, 3, 5, 7, 14, 20, 31, 50\}$ to cover a wide range of levels from very low to moderately high. Each combination is being referred to as a _panel_. That is, data is being generated for each of the panels $\{nx = 2, nfacet = 2\}, \{nx = 2, nfacet = 3\}, \{nx = 2, nfacet = 5\},  \dots, \{nx = 50, nfacet = 31\}, \{nx = 50, nfacet = 50\}$. For each of the $64$ panels, $ntimes = 500$ observations are drawn for each combination of the categories. That is, if we consider the panel  $\{nx = 2, nfacet = 2\}$, $500$ observations are generated for each of the combination of categories from the panel, namely, $\{(1, 1), (1, 2), (2, 1), (2, 2)\}$. The values of $\lambda$ is set to $0.67$, since we want to up-weigh the within-facet distances and that of $\omega$ is set to $0$, since there is no significant differences between distributions in the null case. Observations were generated for each type of distribution changing the shape and scale to study the effect of shape, scale and type of distribution on wpd. The set of distributions considered for this purpose is ${N(0,1), N(5, 1), N(0,5), \Gamma(0.5, 1), \Gamma(2, 1)}$. Each of the scenario is run $nsim = 200$ times to see the distribution of wpd values for each scenario.

Secondly, the behavior of raw and normalized wpd is explored in designs where there is in fact difference in distribution between facet categories ($D_{var_f}$) or across x-categories ($D_{var_x}$) or both ($D_{var_{all}}$). Using $\omega =  \{1, 2, \dots, 10\}$ and $\lambda = seq(from  = 0.1, to = 0.9, by = 0.05)$, observations are drawn from a N(0,1) distribution for each combination of $nx$ and $nfacet$ from the following sets: $nx = nfacet =  \{2, 3, 5, 7, 14, 20, 31, 50\}$. $ntimes = 500$ is assumed for this setup as well. Furthermore, to generate different distributions across different combination of facet and x levels, the following method is deployed - suppose the distribution of the combination of first levels of x and facet category is $N(\mu,\sigma)$ and $\mu_{jk}$ denotes the mean of the combination $(a_jb_k)$, then $\mu_{j.} = \mu + j\omega$ (for design $D_{var_x}$) and $\mu_{.k} = \mu + k\omega$ (for design $D_{var_f}$). 

The tabulated values and graphical representations of the simulation results are provided in Appendix. The learning from the simulations are as follows:
The values of the measure $wpd_{raw}$ is least for $D_{null}$, followed by 
$D_{var_f}$, $D_{var_x}$) and $D_{var_{all}}$). This is a desirable result since the measure $wpd_{raw}$ was designed such that this relationship holds.
Furthermore, the distribution of the measure $wpd_{raw}$ changes for different facet and x categories. The location of the distribution shifts to the right and it also becomes more skewed for more higher facet and x-axis categories. Now this is not desirable, as it would mean that we can't compare the $wpd_{raw}$ values across different panels. The distribution of $wpd_{norm}$ looks more similar with at least the mean and standard of the distributions being uniform across panels. This means,  $wpd_{norm}$ could be used to measure differences in distribution across panels. Also, note that since the data is processed using normal-quantile-transform, this measure is independepent of the intial distribution of the underlying data and hence is also comparable across different datasets. This is valid for the case when sample size $ntimes$ for each combination of categories is at least 30 and  $nperm$ used for computing $wpd_{norm}$ is at least 100. More detailed results about the properties of $wpd_{raw}$ and $wpd_{norm}$ could be found in Appendix.


# Choosing harmonies with significant wpd




# Applications {#sec:application}

## Smart meter data of Australia {#sec:smartmeter}

<!-- # how data looks -->


Smart meters provide large quantities of measurements on energy usage for households across Australia. One of the customer trials [@smart-meter] conducted as part of the Smart Grid Smart City project in Newcastle, New South Wales and some parts of Sydney provides customer wise data on energy consumption for every half hour from February 2012 to March 2014. <!--It would be interesting to explore the energy consumption distribution for these customers and gain insights on their energy behavior which are lost either due to aggregation or looking only at coarser temporal units.-->The idea here is to show how to visualize the distribution of the energy consumption across different cyclic granularities in a systematic way to identify different behavioral patterns.


### 50 households together



### Multidimensional scaling


### Putting similar households on linear scale 




## T20 cricket data of Indian Premiere League {#sec:cricket}

The method is not only restricted to temporal data, and can be generalized to many hierarchical granularities (with  continuous and uni-directional nature). We illustrate this with an application to the sport cricket. Although there is no conventional time component in cricket, each ball can be thought to represent an ordering from past to future with the game progressing forward with each ball. In the Twenty20 format, an over will consist of 6 balls (with some exceptions), an inning is restricted to a maximum of 20 overs, a match will consist of 2 innings and a season consists of several matches. Thus, similar to time, there is a hierarchy where ball is nested within overs, overs nested within innings and innings within matches. The idea of cyclic granularities can be likewise mapped to this hierarchy. Example granularites then include ball of the over, over of the inning and ball of the inning. Although most of these cyclic granularities are circular in design of the hierarchy, in application of the rules some granularities are aperiodic. For example, in most cases an over will consist of 6 balls with some exceptions like wide balls or when an inning finishes before the over finishes. Thus, the cyclic granularity ball-of-over will be circular in most cases and aperiodic in others.

<!-- However, irrespective of the type of cyclic granularities, it can be interesting to visualize the distribution of a measured variable across these cyclic granularities to throw light on the periodic behavior of a non-temporal data set similar to any temporal data set. -->

The Indian Premier League (IPL) is a professional Twenty20 cricket league in India contested by eight teams representing eight different cities in India. The ball by ball data for IPL season 2008 to 2016 is fetched from [Kaggle](https://www.kaggle.com/josephgpinto/ipl-data-analysis/data). The `cricket` data set in the `gravitas` package summarizes the ball-by-ball data across overs and contains information for a sample of 214 matches spanning 9 seasons (2008 to 2016) such that each over has 6 balls, each inning has 20 overs and each match has 2 innings. This could be useful in a periodic world when we wish to compute any circular/quasi-circular granularity based on a hierarchy table which look like \autoref{tab:hierarchy-cric}.

```{r hierarchy-cric}
library(gravitas)
library(tibble)
hierarchy_model <- tibble::tibble(
  `linear (G)` = c("over", "inning", "match", "season"),
  `single-order-up cyclic (C)` = c("over-of-inning", "inning-of-match", "match-of-season", 1),
  `period length/conversion operator (K)` = c(20, 2, "k(match, season)", 1)
)
knitr::kable(hierarchy_model,
             format = "latex",
             booktabs = TRUE,
             caption = "Hierarchy table for cricket where overs are nested within an inning, innings nested within a match and matches within a season.") %>%
  #row_spec(0, bold = TRUE)%>%
  kable_styling()
```


However, even if the situation is not periodic and a similar hierarchy can not be formed, it can be interesting to visualize the distribution of a measured variable across relevant cyclic granularities to shed light on the aperiodic behavior of a non-temporal data set similar to aperiodic events like formal meetings, workshops, conferences, school semesters in a temporal set up. There are many interesting questions that could possibly be answered with such a data set irrespective of the type of cyclic granularities. <!--We will explore a few interesting questions and understand how the proposed approach in the paper can help answer some of the questions.-->

<!-- the two teams have a single innings each, which is restricted to a maximum of 20 overs. Hence, in this format of cricket, a match will consist of 2 innings, an innings will consist of 20 overs, an over will consist of 6 balls with some exceptions. -->

<!-- ```{r hierarchy, echo=FALSE} -->
<!-- hierarchy_model <- tibble::tibble(linear gran = c("ball", "over", "inning", "match"),  -->
<!--                                   convert_fct = c(6, 20, 2, 1)) -->
<!-- knitr::kable(hierarchy_model, caption = " A hierarchy table for T20 cricket") -->
<!-- ``` -->

<!-- Each team is given a two-and-a-half-minute "strategic timeout" during each innings; one must be taken by the bowling team between the ends of the 6th and 9th overs, and one by the batting team between the ends of the 13th and 16th overs. -->

<!-- Suppose, we are interested to see how the distribution of scores vary from the start to the end of the game. Let us brainstorm some of the questions that might help us comprehend that. -->

<!-- a) What is the most common pattern for batting and bowling teams across balls, overs, innings and matches? Which are the teams which are typical and which are exceptions? -->

<!-- How the scores per over vary across granularities/categorizations like innings of a match or matches of a season? Are these different for the winning teams in that season and the teams that couldn't qualify for the playoffs? -->

<!-- Is the outcome of the game dependent on who bats first? Do some teams have more chance to win if they are batting in the first innings? -->

<!-- We will look at the ball by ball data for all batting teams. Since we want a periodic world, where each over consists of 6 balls and each match consists of two innings, we shall filter out the matches or overs for which that is not true. Also, we look at runs per over as that would have more variability compared to runs per ball and it be easier to observe the strategies of the winning team through that.  -->

<!-- Making it short -->

<!-- First, we look at the distribution of runs (measured variable) across over-of-inning (circular granularity) and match-of-season (aperiodic cyclic granularity) in \autoref{fig:seas-over-inning}. The distribution of runs per over has not significantly changed from 2008 to 2016. There is no clear pattern/trend that runs per over is increasing or decreasing across seasons. Hence, we work with subsets of seasons to answer some of the questions: -->

First, it would be interesting to see if the distribution of total runs vary depending on if a team bats in the first or second innings. The Mumbai Indians (MI) and Chennai Super kings (CSK) <!--are considered one of the best teams in IPL with multiple winning titles and --> appeared in final playoffs from 2010 to 2015. We take their example in order to dive deeper into this question. <!--Circular granularities "over-of-inning" and "inning-of-match" can be computed using \ref{sec:circular-gran-def} with over as index of the tsibble.--> From Figure \ref{fig:cricex}(a), it can be observed that for the team batting in the first inning there is an upward trend of runs per over, while there is no clear upward trend in median and quartile deviation of runs for the teams batting in the second inning. This seem to indicate that players feel mounting pressure to score more runs as they approach towards the end of the first inning. Whereas teams batting in the second inning have a set target in mind and are not subjected to such mounting pressure and may adopt a more conservative strategy, to score runs. Thus winning teams like CSK and MI seem to employ different inning strategies when it comes to their batting order.

<!-- Also longer and more distinct letter values in the second innings suggests that the variability is more in the second innings. -->
<!-- - Q1: How their run rates vary depending on if they bat first or 2nd? Is there a chance that they are more likely to win if they bat first? -->

<!-- - Q2: Which team is more consistent in their approach in terms of run rate across different overs of the innings? -->

<!-- # ```{r seas-over-inning, fig.cap = "Quantile plot of runs per over across overs of different seasons. There is no pattern on increase or decrease of runs across overs for seasons."} -->
<!-- #   cricket_tsibble_all %>%  -->
<!-- #   prob_plot("over",  -->
<!-- #             "season", -->
<!-- #             hierarchy_model, -->
<!-- #             response = "runs_per_over", -->
<!-- #             plot_type = "quantile", -->
<!-- #             quantile_prob = c(0.25, 0.5, 0.75),  -->
<!-- #             symmetric = FALSE)  + -->
<!-- #      theme( # remove the vertical grid lines -->
<!-- #             panel.grid.major.x = element_blank() , -->
<!-- #             # explicitly set the horizontal lines (or they will disappear too) -->
<!-- #             panel.grid.major.y = element_blank()) + scale_x_discrete(breaks = seq(2008, 2016, 3)) -->
<!-- # ``` -->


Another interesting question could be: do runs per over decrease in the subsequent over if fielding (defending) was good in the previous over? For establishing the fielding quality, we apply an indicator function on dismissals (1 if there was at least one wicket in the previous over due to run out or catch, 0 otherwise). Runs in the current over is then the observation variable.  <!--If a batsman is bowled out, it does not necessarily signify good fielding. So we only include number of catches and run out in an over as a measure of good fielding.
Difference in runs across overs are likely to be negative if good fielding has an impact on the runs scored in the subsequent overs. --> Dismissals in the previous over can lead to a batsman adopting a more defensive play style. Figure \ref{fig:cricex}(b) shows that no dismissals in the previous over leads to a higher median and quartile spread of runs per over as compared to the case when there has been at least one dismissal in the previous over.

<!-- Difference in runs across over should be negative if good fielding has an impact on the runs scored in the subsequent overs.  -->

<!-- fetching raw data since dot and fielding information not available in dismissal type not available in cricket data gravitas. Also `cricket` is aggregated across overs -->

```{r cricex, fig.cap= "Runs per over shown with different distribution displays, and granularities. Plot (a) shows letter value plot across overs faceted by innings. For the team batting in the first innings there is an upward trend of runs per over, while there is no such pattern of runs for the teams batting in the second innings. Plot (b) shows quantile plot of runs per over across an indicator of wickets in previous over faceted by current over. This indicates that at least one wicket in the previous over leads to lower median run rate and quartile spread in the subsequent over.", warning = FALSE, message = FALSE, out.width = "90%"}

library(tsibble)
cricket_tsibble <- cricket %>%
  mutate(data_index = row_number()) %>%
  as_tsibble(index = data_index)

hierarchy_model <- tibble::tibble(
  units = c("index", "over", "inning", "match"),
  convert_fct = c(1, 20, 2, 1)
)

cricket_tsibble %>%
  filter(batting_team %in% c(
    "Mumbai Indians",
    "Chennai Super Kings"
  )) %>%
  mutate(inning = paste0("innings: ", inning)) %>%
  prob_plot("inning",
    "over",
    response = "runs_per_over",
    hierarchy_model,
    plot_type = "lv"
  ) +
  scale_fill_brewer(palette = "Dark2") +
  #ggtitle("(a) Runs per over across over faceted by inning") +
  theme(legend.position = "right") +
  ggtitle("a") +
  ylab("runs per over") +
  xlab("overs of the innings") +
  theme(plot.title = element_text(face = "bold")) +
  ggplot2::theme(
       strip.text = ggplot2::element_text(
        size = 10,
         margin = ggplot2::margin(b=0, t=0)
      )
     ) +  theme_minimal() 
#geom_smooth(aes( x = over,
#                               y=runs_per_over), method = lm, #formula = y ~ splines::bs(x, 3), se = FALSE)


library(tsibble)

cricket_all <- read_csv("paper/data-raw/deliveries_all.csv")
matches_all <- read_csv("paper/data-raw/matches_all.csv")

cricket_season <- cricket_all %>% left_join(matches_all, by = c("match_id" = "id"))

# cricket_per_over <- cricket_season %>%
#   group_by(season,
#            match_id,
#            batting_team,
#            bowling_team,
#            inning,
#            over) %>%
#   summarise(runs_per_over = sum(total_runs),
#             run_rate = sum(total_runs)/length(total_runs))
#
# cricket_tsibble_all <- cricket_per_over %>%
#   ungroup() %>%
#   mutate(data_index = row_number()) %>%
#   as_tsibble(index = data_index)

cricket_dot_field <- cricket_season %>%
  mutate(
    fielding_proxy = if_else(dismissal_kind %in%
      c("caught", "caught and bowled"), 1, 0),
    dot_ball_proxy = if_else(total_runs == 0, 1, 0),
    wicket_proxy = if_else(is.na(dismissal_kind), 0, 1)
  ) %>%
  group_by(
    season,
    match_id,
    batting_team,
    bowling_team,
    inning,
    over
  ) %>%
  summarise(
    runs_per_over = sum(total_runs),
    run_rate = sum(total_runs)*6 / length(total_runs),
    fielding_wckts = sum(fielding_proxy),
    dot_balls = sum(dot_ball_proxy)
  ) %>%
  mutate(diff_run_rate = c(0, diff(run_rate)))

cricket_tsibble <- cricket_dot_field %>%
  ungroup() %>%
  mutate(data_index = row_number()) %>%
  as_tsibble(index = data_index)

cricket_data <- cricket_tsibble %>%
  mutate(
    field = if_else(fielding_wckts == 0, "0", "1+"),
    dot = if_else(dot_balls == 0, "no dot balls", ">0 dot balls"),
    lag_field = lag(field),
    lag_dot = lag(dot)
  ) %>%
  filter(lag_field != 0, lag_dot != 0) 

cricket_data$lag_field <- factor(cricket_data$field, levels = c("0", "1+"))

# filter(fielding_wckts %in% c(0,1)) %>%
#
 cricket_data %>%
  filter(over!=1) %>%
  prob_plot("over", "lag_field",
  hierarchy_model,
  response = "run_rate",
  plot_type = "quantile",
  symmetric = FALSE,
 quantile_prob = c(0.25, 0.5, 0.75)) +
   #ggtitle("(b) Runs per over across overs faceted by number of wickets in previous over") +
  ylab("runs per over")  +
  xlab("number of wickets in previous over") +
  ggtitle("b") +
   theme(plot.title = element_text(face = "bold")) +
        theme(axis.ticks = element_blank(), legend.background = element_blank(),
            legend.key = element_blank(), panel.background = element_blank(), strip.background = element_blank(),
            plot.background = element_blank(), complete = TRUE, panel.grid.major = element_line(colour = "#E0E0E0"),
            panel.border = element_rect(colour = "#E0E0E0", fill = NA))
```

<!-- Q2: Among good fielding and bowling - which affect the runs of the subsequent overs more? -->

<!-- Q3: Are runs set to reduce in the next over for dot balls in the previous over? -->

<!-- A dot ball is a delivery bowled without any runs scored off it. The number of dot balls is reflective of the quality of bowling in the game. Run rate of an over should ideally decrease if the number of dot balls increase. However, what is the effect of dot balls on runs scored in the subsequent over. Will players batsman likely to go for big shots because they couldn't score good runs in the previous over? Or they should play consistently and avoid scoring high? Figure \ref{fig:exdot} shows the quantile plot of runs across overs for at least one dot ball per over (facet 1) or no dot balls per over (facet 2). -->
<!-- With at least one dot balls per over, the distribution of run rates in facet 1 increase slower compared to that in facet 2. This implies that run rates are likely to decrease in the subsequent over as a result of dot balls in the previous over. -->


<!-- ```{r exdot, fig.cap="25th, 50th, 75th quantiles of runs per over are drawn across overs of the innings with no (facet 2), more than zero (facet 1) dot balls per over. For all quantiles, run rates mostly increase at a higher rate in facet 2 compared to facet 1 implying run rates decrease with at least one dot ball in the previous over.", fig.pos="ht"} -->


<!-- cricket_data %>% -->
<!--   # filter(dot_balls %in% c(0, 1, 2)) %>% -->
<!--   prob_plot("lag_dot", -->
<!--     "over", -->
<!--     hierarchy_model, -->
<!--     response = "run_rate", -->
<!--     plot_type = "quantile", -->
<!--     quantile_prob = c(0.25, 0.5, 0.75), -->
<!--     symmetric = FALSE -->
<!--   ) + ggtitle("") -->
<!-- ``` -->

Wickets per over are considered as an aperiodic cyclic granularity with wickets as an aperiodic linear granularity. These granularities do not appear in the hierarchy table since it is difficult to position them in a hierarchy. These are similar to holidays or special events in temporal data.
<!-- CONTENT CUT -->
<!--While any special event that corresponds to a time domain can be treated as an aperiodic linear granularity in a temporal xacase, dot balls or wickets that corresponds to certain balls (index) could be treated as aperiodic events in cricket.-->


# Discussion points and future work

Exploratory data analysis involve many iterations of finding and summarizing patterns. With temporal data available at ever finer scales, exploring periodicity has become overwhelming with so many possible granularities to explore. This work refines the selection of appropriate pairs of granularities by identifying those for which the differences between the displayed distributions is greatest, and rating these selected harmony pairs in order of importance for exploration.

A future direction of work could be to look at more individuals/subjects and group them according to similar periodic behavior. Behaviors across different cyclic granularities would be different for different subjects and one way to find groups would be to actually locate clusters who have similar periodic behavior.

<!-- patterns are interesting and others are not. The subjects for which behaviors across a group of cyclic granularities are similar, could be grouped together as their periodic behavior is similar.  to group subjects  -->

# Appendix

## Null distribution

### Size: Simulated same distribution for all combinations of categories for all harmony pairs.

Failure to reject the null hypothesis when there is in fact no significant effect.

### Normalised maximum distances follow standard Gumbel distribution

### Limiting distribution of median of normalised maximum distances is normal

Let a continuous population be given with cdf F(x) (cumulative distribution function) and median $\xi$ (assumed to exist uniquely). For a sample of size $2n + 1$, let $\tilde{x}$ denote the sample median. The distribution of $\tilde{x}$,under certain conditions, to be asymptotically normal with mean $\xi$ and variance $\sigma_n^2 = \frac{1}{4} [f(\xi)]^2(2n + 1)$, where $f(x) = F'(x)$ is the pdf (probability density function).


<!-- ### Confidence interval of test statistic -->

## Power

## Confidence interval

Failure to reject the null hypothesis when there is in fact a significant effect.

To estimate the sampling distribution of the test statistic we need many samples generated under the null hypothesis. If the null hypothesis is true, changing the exposure would have no effect on the outcome. By randomly shuffling the exposures we can make up as many data sets as we like. If the null hypothesis is true the shuffled data sets should look like the real data, otherwise they should look different from the
real data. The ranking of the real test statistic among the shuffled test statistics gives a p-value.

<!-- Consider two cyclic granularities $A$ and $B$ with $2$ and $3$categories. Thus, the harmony table consisting of all possible harmony pairs (assuming all pairs are harmonies), would look like the following: -->

```{r harmony_min}
# harmonies <- tibble::tibble(facet_variable = c("A", "B", "A", "C", "B", "C"),
#                             x_variable  = c("B","A", "C", "A", "C", "B"),
#                             facet_levels = c(2, 3, 2, 4, 3, 4),
#                             x_levels = c(3, 2, 4, 2, 4, 3))
# 
# harmonies <- tibble::tibble(facet_variable = c("A", "B"),
#                             x_variable  = c("B","A"),
#                             facet_levels = c(2, 3),
#                             x_levels = c(3, 2))
#                             
# harmonies %>% knitr::kable()
```

<!-- The output table has the value of MMPD (normalized median maximum pairwise distances), gt_MMPD(global threshold of MMPD indicator). -->

<!-- # ```{r samenull_2by4, eval = FALSE} -->
<!-- #  -->
<!-- # ``` -->

<!-- # ```{r normalv21_power} -->
<!-- #  -->
<!-- # ``` -->
<!-- #  -->
<!-- #  -->
<!-- # ```{r normalv22_power} -->
<!-- #  -->
<!-- # ``` -->

### Varying distribution across facet
### Varying distribution across x-axis
### Varying distribution across both facets and x-axis
### Repeat all with varying facet and x-axis levels

<!-- ### Power: Simulated same distribution for all combinations of categories for all harmony pairs. -->



<!-- # ```{r normalv23_power} -->
<!-- #  -->
<!-- # ``` -->
<!-- #  -->
<!-- #  -->
<!-- # ```{r normalv24_power} -->
<!-- #  -->
<!-- # ``` -->


*Conclusion*: The test should reject the null hypothesis if distributions are different.

<!-- ### Scenario 2: Simulated different distributions for all combinations of categories for harmony pairs for few levels. -->



<!-- ```{r diffnull_2by4, eval = FALSE} -->

<!-- ``` -->


<!-- *Conclusion*: The test select the harmony pair for which distribution of x-axis categories are significantly different -->


<!-- ### Scenario 3: Simulated different distributions for all combinations of categories for all harmony pairs with many levels. -->


<!-- ```{r diffnull_7by11, eval = FALSE} -->
<!-- ``` -->

<!-- *Conclusion*: The test indicates that both harmony pairs do not have significant variation. -->


<!-- ### Scenario 4: Simulated different distributions for all combinations of categories for all harmony pairs with many levels - very different distribution across x-axis -->


<!-- ```{r diffnull_7by11normal, eval = FALSE} -->
<!-- ``` -->

<!-- *Conclusion*: The test indicates that only the first harmony pair has significant variation. -->


<!-- ### Scenario 5: Simulated different distributions for all combinations of categories for all harmony pairs with many levels - very different distribution across facets -->


<!-- ```{r diffnull_7by11normal2, eval = FALSE} -->
<!-- ``` -->


<!-- *Conclusion*:  -->



<!-- ## Scenario 4: Cumulative 3 levels with 2, 7 and 11 and testing level and power -->

<!-- ```{r samenull_3levels} -->

<!-- ``` -->


<!-- *Conclusion*: With 3 levels the test incorrectly chooses 1 harmony pair with similar distribution. The harmony pair which is displayed. -->

<!-- <!-- ```{r diffnull_3levels} --> 

<!-- <!-- ``` --> 

<!-- *Conclusion*: The test with MMPD selects just one pair, as opposed to the test with maximum. This needs to be checked against what we expect from the test. The harmony pairs which are selected (either through MMPD or maximum) are displayed. -->


<!-- # ```{r} -->
<!-- # harmonies <- tibble::tibble(facet_variable = c("A", "B"),x_variable  = c("B","A"), facet_levels = c(2, 3),x_levels = c(3, 2)) -->
<!-- #  -->
<!-- # har1 <- harmonies[1,] -->
<!-- #  -->
<!-- # sim_dist1 = c(rep(distributional::dist_normal(mu = 10, sigma = 5),2),rep(distributional::dist_exponential(10),2), rep(distributional::dist_weibull(0.5, 2),2)) -->
<!-- #  -->
<!-- # data1 <- sim_distharmony1(har1, sim_dist = sim_dist1) -->
<!-- # data1 -->
<!-- #  -->
<!-- # data1 %>% unnest(sim_dist) %>% -->
<!-- #   ggplot(aes(x = Var2, y = sim_dist)) + -->
<!-- #   facet_wrap(~Var1) + geom_boxplot() + ggtitle("Same distribution 2 by 3") -->
<!-- #  -->
<!-- # response = "sim_dist" -->
<!-- #  -->
<!-- # MMPD_distribution <- data1 %>% -->
<!-- #   select(-dist) %>%  -->
<!-- #   unnest(sim_dist) %>%  -->
<!-- #   list() %>%  -->
<!-- #   global_threshold(harmony_tbl = har1, -->
<!-- #                    response = "sim_dist", -->
<!-- #                    dist_distribution = "normal", -->
<!-- #                    dist_ordered = TRUE, -->
<!-- #                    create_gran_data = FALSE, nsamp = 20) -->
<!-- #  -->
<!-- # # as_tibble(sample_MMPD) %>% mutate(id = row_number()) %>%  -->
<!-- # #   ggplot() + geom_histogram(aes(x = value)) -->
<!-- #  -->
<!-- # ``` -->
<!-- #  -->

<!-- # Visualisation -->

<!-- Leader plots like in Scagnostics paper -->

