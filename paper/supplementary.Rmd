---
title: Supplementary materials 
authors:
- name: Sayani Gupta
  affiliation: Department of Econometrics and Business Statistics, Monash University
  email: Sayani.Gupta@monash.edu

bibliography: bibliography.bib
preamble: >
  \usepackage{mathtools,booktabs,amsthm,todonotes,colortbl}
  \def\mod{~\text{mod}~}
  \newtheorem{definition}{Definition}
  \usepackage{mathptmx}
  \usepackage{caption}
  \usepackage{algorithm}
  \usepackage{algorithmicx}
  \usepackage{algpseudocode}
  \DeclareCaptionStyle{italic}{labelfont={bf},textfont={it},labelsep=colon}
  \captionsetup[figure]{style=italic,format=hang,singlelinecheck=true}
  \captionsetup[table]{style=italic,format=hang,singlelinecheck=true}
  \def\novspacing{\setlength{\aboverulesep}{0pt}\setlength{\belowrulesep}{0pt}}
  \def\vspacing{\setlength{\aboverulesep}{0.4ex}\setlength{\belowrulesep}{0.65ex}}
output:
  bookdown::pdf_book:
    #base_format: rticles::asa_article
    fig_height: 5
    fig_width: 8
    fig_caption: yes
    dev: "pdf"
---

```{r initial, echo = FALSE, cache = FALSE, include = FALSE}
options("knitr.graphics.auto_pdf" = TRUE,
        tinytex.verbose = FALSE)
library(knitr)
library(tidyverse)
library(lubridate)
library(lvplot)
library(ggridges)
library(viridis)
library(tsibble)
library(gravitas)
library(ggpubr)
library(readr)
library(kableExtra)
library(distributional)
library(ggplot2)
library(sugrrants)
library(here)

opts_chunk$set(
  echo = FALSE, warning = FALSE, message = FALSE, comment = "#>",
  fig.path = "figure/", fig.align = "center", fig.show = "hold",
  cache = TRUE, cache.path = "cache/",
  out.width = ifelse(is_html_output(), "100%", "\\textwidth")
)
knitr::opts_knit$set(root.dir = here::here())
#                                                                read_chunk('main.R')
here::here()
read_chunk(here::here("paper/R/", "null_distribution.R"))
read_chunk(here::here("paper/R/", "mean_null.R"))
source(here::here("paper/R/sim_panel.R"))
# Set up plan
#source("_drake.R")
# Run all code required
#drake::r_make()
# load each object as required
# loadd()
```

# Notations and Definitions

Consider two cyclic granularities $A$ and $B$, such that $A = \{ a_j: j = 1, 2, \dots, J\}$ and $B = \{ b_k: k = 1, 2, \dots, K\}$ with $A$ placed across x-axis and $B$ across facets. Let the pairwise distances between pairs $(a_{j} b_{k}, a_{j'}b_{k'})$ b   e denoted as $d_{(jk, j'k')} = JSD(a_{j}b_{k}, a_{j'}b_{k'})$. Pairwise distances could be within-facets or between-facets. Figure \ref{fig:distance-explain} illustrates how the within-facet or between-facet distances are defined. Pairwise distances are within-facets ($d_{w}$) when $b_{k} = b_{k'}$, that is, between pairs of the form $(a_{j}b_{k}, a_{j'}b_{k})$ as shown in panel (3) of Figure \ref{fig:distance-explain}. If categories are ordered (like all temporal cyclic granularities), then only distances between pairs where $a_{j'} = (a_{j+1})$ are considered (panel (4)). Pairwise distances are between-facets ($d_{b}$) when they are considered between pairs of the form $(a_{j}b_{k}, a_{j}b_{k'})$.


```{r distance-explain, fig.cap = "Within and between-facet distances shown for two cyclic granularities A and B, where A is mapped to x-axis and B is mapped to facets. The dotted lines represent the distances between different categories. Panel 1) and 2) show the between-facet distances. Panel 3) and 4) are used to illustrate within-facet distances when categories are un-ordered or ordered respectively. When categories are ordered, distances should only be considered for consecutive x-axis categories. Between-facet distances are distances between different facet levels for the same x-axis category, for example, distances between {($a_1$,$b_1$) and ($a_1$, $b_2$)} or {($a_1$,$b_1$) and ($a_1$, $b_3$)}."}
knitr::include_graphics(here::here("paper/Figs/dist_explain.png"))
```

# Behavior of raw wpd

Most of the behavior of the measure wpd was studied via simulation. The simulations explore how wpd performs under various designs and parameters and its limitations. To study the behavior of wpd, simulations were carried out for four different designs and the following factors that could potentially have an impact on the values of wpd:


<!-- Numerous simulations were carried out in a wide range of scenarios. -->

<!-- Same scenarios were used, when possible with normalized wpd, keeping all other simulation variables constant. -->

- $nx$ (number of levels of x-axis)
- $nfacet$ (number of levels of facets)
- $\lambda$ (tuning parameter)
- $\omega$ (increment in each panel design)
- $dist$ (normal/non-normal distributions with different location and scale)
- $n$ (sample size for each combination of categories)
- $nsim$ (number of simulations)
- $nperm$ (number of permutations of data)  
- $designs$  
$D_{null}$  (No difference in distribution)  
$D_{var_f}$ (Difference in distribution only across facets)  
$D_{var_x}$ (Difference in distribution only across x-axis)  
$D_{var_{all}}$ (Difference in distribution in both facets and x-axis)  

```{r simtable, eval = FALSE}
variable = c("nx", "nfacet", "lambda", "omega", "dist", "n", "nsim", "nperm", "design")

description = c("number of levels of x-axis", "number of levels of facets",
                "tuning parameter","increment in each panel design", "normal/non-normal distributions with different location and scale", "sample size", "number of simulations", "number of permutations of data", 
                "$D_{null}$ (No difference in distribution), $D_{var_f}$ (Difference in distribution only across facets), $D_{var_x}$ (Difference in distribution only across x-axis), $D_{var_all}$ (Difference in distribution in both facets and x-axis)")
table = tibble::tibble(variable, description)

table %>% 
knitr::kable(format = "latex",
             escape = TRUE) %>% 
  kableExtra::kable_styling(
    bootstrap_options = "striped", 
    full_width = F, 
    font_size = 7)

```

## Null design

This section explores the behavior of wpd in designs where there is no difference in distribution between x and facet categories. We have considered different initial distributions to study the impact of initial distribution under the null setup. Since the measure wpd is essentially set up to detect differences in distributions irrespective of underlying distribution, it would be ideal if it has minimal dependency on the type, location and scale of the initial distribution. To that end, some pre-processing of the data is preferred to bring it to the same scale, location and type. The Normal Score Transform or NQT has been applied in various fields of geo-statistics in order to make most asymmetrical distributed real world measured variables more
treatable and normal-like.

Following the work of Krzysztofowicz (1997) the empirical NQT involves the following steps:
1. Sort the sample of measured variable $X$ from the smallest to the largest observation $x_{(1)},\dots, x_{(i)}, .., x_{(n)}$.
2. Estimate the cumulative probabilities $p_{(1)},\dots, p_{(i)}, .., p_{(n)}$.
using a plotting position like $i/(n + 1)$ such that $p_{(i)} = P(X \leq x_{(i)})$.
3. Transforming each observation $x_(i)$ of $X$ into observation $y(i) = Q^{-1}(p(i))$ of the standard normal variate $Y$ , with $Q$ denoting the standard normal distribution and
$Q^{-1}$ its inverse, applying discrete mapping.

Further, we want to study the distribution of wpd for different $nx$ and $nfacet$.


### Simulation setup

<!-- Study the behavior of wpd under different initial distributions for different $nx$ and $nfacet$ -->

Using two types of distributions, viz. normal and gamma (non-normal), we generated observations for each combination of $nx$ and $nfacet$ from the following sets: $nx = \{2, 3, 5, 7, 14, 20, 31, 50\}$ and $nfacet = \{2, 3, 5, 7, 14, 20, 31, 50\}$ to cover a wide range of levels from very low to moderately high. Each combination is being referred to as a _panel_. That is, data is being generated for each of the panels $\{nx = 2, nfacet = 2\}, \{nx = 2, nfacet = 3\}, \{nx = 2, nfacet = 5\},  \dots, \{nx = 50, nfacet = 31\}, \{nx = 50, nfacet = 50\}$. For each of the $64$ panels, $ntimes = 500$ observations are drawn for each combination of the categories. That is, if we consider the panel  $\{nx = 2, nfacet = 2\}$, $500$ observations are generated for each of the combination of categories from the panel, namely, $\{(1, 1), (1, 2), (2, 1), (2, 2)\}$. The values of $\lambda$ is set to $0.67$, since we want to up-weigh the within-facet distances and that of $\omega$ is set to $0$, since there is no significant differences between distributions in the null case. Observations were generated for each type of distribution changing the shape and scale to study the effect of shape, scale and type of distribution on wpd. The set of distributions considered for this purpose is ${N(0,1), N(5, 1), N(0,5), \Gamma(0.5, 1), \Gamma(2, 1)}$. Each of the scenario is run $nsim = 200$ times to see the distribution of wpd values for each scenario.

<!-- wpd is computed for different normal and non-normal distributions to see how the underlying distribution has a role to play in the value of wpd. Since we are concerned with detecting the differences in distributions, it would be ideal if wpd has minimal dependency on the type, location and scale of the  underlying distribution. To that end, some pre-processing of the data is preferred to bring it to the same scale, location and type. -->


<!-- Null design only where all combinations are equal for fixed values of $\mu$ and $\sigma$ -->
<!-- Dist 1: $N(0,1)$ individual graph -->
<!-- Dist 2: $N(\mu, 1)$ (faceted with different values of $\mu$: not yet just for one value now) -->
<!-- Dist 3: $N(0, \sigma)$ (faceted with different values of $\sigma$: not yet just for one value now) -->
<!-- Dist 4: $N(\mu, \sigma)$ faceted with different values of mu and sigma, for all levels of x and facet to see how value of wpd changes with that of change in parameters. -->


<!-- **Assumptions:** There is no difference in distribution between any facet or x-category -->
<!-- nsim = 200 -->
<!-- lambda = 0.67 -->

<!-- **Questions:**  -->
<!-- - How raw value of wpd changes with different nx and nfacet for different location and scale of a Normal and non-normal distribution -->

Figure \ref{fig:normal-diff-quantrans} and \ref{fig:gamma-diff-quantrans} show distribution of wpd for different initial normal and gamma distribution to study the effect of changing location and scale on the distribution of wpd. It seems like the  distribution changes across different facet and x levels but look the same for each panel, which implies wpd value is unaffected by the change in location and scale of the the normal distribution. Figure \ref{fig:mean-sd-ns-nfacet} shows how mean and sd of the distribution of wpd changes with the increasing x and facet levels. It seems like both mean and standard deviation are affected more by change in the x-axis levels than the facet levels. Figure \ref{fig:nxbyfacet-ridge-N05} gives another way to look at the effect of changing facet and x levels on the distribution of wpd for an initial distribution $N(0,5)$. Clearly, the location of the distribution shifts to the right for increasing x levels and scale is different for low and high values of facet levels with a longer left tail for lower facet levels. We have considered alternate distribution, location and scale for this simulation setting, but do not present the results as they are behaviorally similar. 

<!-- # ```{r normal-diff, fig.cap="Ridge plots of raw wpd is shown for N(0,1) and N(5,1) distribution. The densities change across different facet and x levels but look same for the two distributions, which implies wpd value is unaffected by the change in mean and standard deviation of the normal distribution", eval = FALSE} -->
<!-- # knitr::include_graphics(here::here("simulations/null_design/figs/normal_ridge_nxbynfacet_wpd_N01.png")) -->
<!-- # ``` -->

```{r normal-diff-quantrans, fig.cap = "Ridge plots of raw wpd is shown for N(0,1), N(5,1) and N(0,5) distribution. The densities change across different facet and x levels but look same for each panel, which implies wpd value is unaffected by the change in mean and standard deviation of the normal distribution"}
knitr::include_graphics(here::here("simulations/raw/null_design_quantrans/figs/diff_mean3_normal.png"))
```


```{r gamma-diff-quantrans, fig.cap="Ridge plots of raw wpd is shown for Gamma(0.5,1), Gamma(2,1) distribution. The densities change across different facet and x levels but look same for the two distributions, which implies wpd value is unaffected by the change in the shape paramter of the gamma distribution"}
knitr::include_graphics(here::here("simulations/raw/null_design_quantrans/figs/diff_mean3_gamma.png"))
```


```{r mean-sd-ns-nfacet, fig.cap="Movement of mean and sd for raw wpd is shown for different number of levels (nlevel) of x-axis and facets through line plots. Mean increases and sd decreases more sharply for increasing x-axis levels as compared to facet levels. It seems like both mean and standard deviation are affected more by change in the x-axis levels than the facet levels.", fig.pos="h"}
knitr::include_graphics(here::here("simulations/raw/null_design_quantrans/figs/mean_sd_nx_nfacet.png"))

```


```{r nxbyfacet-ridge-N05, fig.cap="Ridge plots of raw wpd is shown for N(0,5) distribution. For each panel, it could be seen that the location shifts to the right for increasing x levels. Across each panel, the scale of the distribution seems to change for low/moderately lower values and higher values of nfacets and left tails are longer for lower facet levels."}
knitr::include_graphics(here::here("simulations/raw/null_design_quantrans/figs/nxbyfacet_ridge_wpd_N05.png"))
```





```{r gamma-diff, fig.cap="Ridge plots of raw wpd is shown for G(0.5,1) and G(2,1) distribution. The densities change across different facet and x levels and also for the two distributions, which implies wpd value is affected by the change in location value when distributions are not normal.", eval = FALSE}
knitr::include_graphics(here::here("simulations/null_design/figs/gamma_ridge_nxbynfacet.png"))
```

```{r gamma-diff-trans, fig.cap="Ridge plots of raw wpd is shown for G(0.5,1) and G(2,1) distribution after quantile transformation looks similar and hence is unaffected by change in location.", fig.pos="h"}
knitr::include_graphics(here::here("simulations/raw/null_design_quantrans/figs/diff_mean3_gamma.png"))
```



<!-- ### Choice of alternate designs -->

<!-- A normal distribution is taken for this purpose. We would calibrate the values of $WPD$ for different designs illustrated in Section \ref{sec:idea}. -->

<!-- $$\mu_{j.} = \mu + j\omega$$ -->
<!-- or, $$\mu_{.k} = \mu + k\omega$$ where,    -->
<!-- $j$ and $k$ are the index of the x and facet category respectively  -->
<!-- $\mu$ is the mean of the first category and $\omega$ is the increment from the starting value. -->


<!-- mean = 0 -->
<!-- range_mean = c(0, 1, 3,  5, 7, 15, 20) -->
<!-- sd = 1 -->
<!-- range_sd = c(1, 3,  5, 7, 15, 20) -->
<!-- range_w =  c(1, 2, 3, 4, 5) -->
<!-- range_lambda = seq(0.1, 0.9, 0.05) -->

## Alternate designs

This section explores the behavior of wpd in designs where there is infact difference in distribution between facet categories ($D_{var_f}$) or across x-categories ($D_{var_x}$) or both ($D_{var_{all}}$). Since it is established in the last section that after preprocessing the data through NQT, the initial distribution does not have a role to play in the values of wpd, we proceed with a N(0,1) distribution only. Supposably, the tuning parameter ($\lambda$) and increment parameter ($\omega$) should impact the values of wpd.


### Simulation setup

Using $\omega =  \{1, 2, \dots, 10\}$ and $\lambda = seq(from  = 0.1, to = 0.9, by = 0.05)$, observations are drawn from a N(0,1) distribution for each combination of $nx$ and $nfacet$ from the following sets: $nx = nfacet =  \{2, 3, 5, 7, 14, 20, 31, 50\}$. $ntimes = 500$ is assumed for this setup as well. Furthermore, to generate different distributions across different combination of facet and x levels, the following method is deployed - suppose the distribution of the combination of first levels of x and facet category is $N(\mu,\sigma)$ and $\mu_{jk}$ denotes the mean of the combination $(a_jb_k)$, then $\mu_{j.} = \mu + j\omega$ (for design $D_{var_x}$) and $\mu_{.k} = \mu + k\omega$ (for design $D_{var_f}$). Table \ref{tab:explain-design} shows an example of how initial distributions are assigned in a panel with $nfacet = 3$ and $nx = 2$ for different designs using $\omega = 1$.


```{r explain-design}
sim_varx_normal = function(nx, nfacet, mean, sd, w)
{
  rep(dist_normal((mean + seq(0, nx-1, by  = 1)*w), sd), nfacet)
}

sim_varf_normal = function(nx, nfacet, mean, sd, w)
{
  rep(dist_normal((mean + seq(0, nfacet-1, by  = 1)*w), sd), each = nx)
}
  sim_varall_normal = function(nx, nfacet, mean, sd, w)
  {
    dist_normal((mean + seq(0, (nx*nfacet - 1), by  = 1)*w), sd)
  }
  
mean = 0
sd = 1
w = 1
nx = 2
nfacet = 3


raw_levels = expand.grid(facet = c("$b_1$", "$b_2$", "$b_3$"),
                         x = c("$a_1$", "$a_2$"))

facet = rep(c("$b_1$", "$b_2$", "$b_3$"), each = nx)
x =  rep(c("$a_1$", "$a_2$"), nfacet)

vary_f <-  sim_varf_normal(nx, nfacet, mean, sd, w) %>% tibble()
vary_x <-  sim_varx_normal(nx, nfacet, mean, sd, w) %>% tibble()
vary_all <-  sim_varall_normal(nx, nfacet, mean, sd, w) %>% tibble()

raw_table <- bind_cols(x = x, 
                       facet = facet, 
                       vary_f = vary_f, 
                       vary_x = vary_x, 
                       vary_all = vary_all) %>% 
  tibble() 
names(raw_table) = c("x", "facet", "$D_{var_f}$", "$D_{var_x}$", "$D_{var_{all}}$" )
raw_table %>% 
  kable(format = "latex",
    booktabs = TRUE, 
    escape = FALSE,
    caption = "Simulation setup for a panel with 3 facet levels and 2 x-axis levels for different designs starting from an initial distribution N(0, 1) for the combination $(a_1, b_1)$.") %>% kable_styling()
```


<!--  - Exploring the effect of tuning parameter $\lambda$: -->

We now discuss the effect of different tuning parameters $\lambda$  with the help of two alternate designs ($D_{var_x}$ and $D_{var_f}$) and $\omega$. \autoref{fig:tuning-oneomega} displays different values of $\lambda$ for a relatively small and higher $\omega$ for $nx = nfacet =  \{2, 3, 5, 7, 9\}$. The $\lambda$ for which the two designs intersect will then be chosen as the optimal $\lambda$ that could then be weighed appropriately to up-weigh the within-facet distances and down-weigh the between-facet distances. The design $D_{var_x}$ increases linearly with increasing $\lambda$, whereas $D_{var_f}$ decreases linearly with increasing $\lambda$. This is expected as wpd has a linear relationship with $\lambda$ by construction. The two designs mostly intersect at $\lambda = 0.5$ for a higher value of $\omega$.  \autoref{fig:tuning-parameter-inter} shows how the value of $\lambda$ changes with increasing $\omega$ for $\omega =  \{1, 2, \dots, 10\}$ and $\lambda = seq(from  = 0.1, to = 0.9, by = 0.05)$.


<!-- Assumptions: The initial combination has a $N(\mu,\sigma)$ distribution and then every combination increases as follows: -->
<!-- - $$\mu_{j.} = \mu + j\omega$$ (for design vary_x) -->
<!-- - $$\mu_{.k} = \mu + k\omega$$ (for design vary_f) -->
<!-- Value of the parameters chosen for this simulation are $\mu = 0$, $\sigma = 1$ and $\omega = {1, 2, \dots, 10}$ -->

```{r tuning-oneomega, fig.caption = "WPD from two designs are plotted for different values of lambda for different x and facet categories. For omega = 1, the designs intersect for 0.6<lamba<=0.75, whereas for higher omega, design intersects at lambda = 0.5"}
knitr::include_graphics(here::here("simulations/tuning_param/figs/fixed_omega.png"))
```


```{r tuning-parameter-inter, fig.cap ="For most panels it is observed that the most common value of the tuning paramter for which the designs interact is 0.5, which implies any value greater than 0.5 could be chosen to up-weigh the within-facet distances and down-weigh the between-facet distances for most sitatuions."}
knitr::include_graphics(here::here("simulations/tuning_param/figs/intersection_plot.png"))
```


We now discuss the values wpd takes for different designs. Ideally the wpd should have the higherst values for $D_{var_{all}}$, followed by $D_{var_x}$ and $D_{var_y}$ for $\lambda \geq 0.5$. We test this for lower and higher values of $\omega = c(1, 8, 15, 50)$


```{r all-design-relative, fig.cap = "Distribution of wpd under different designs are overlapped to see how they measure relative to each other. We would have expected values of wpd to be such that vary_facet is less than vary_x is less than vary_all but distribution of vary_x to lie above vary_facet."}

library(readr)
library(tidyverse)

vary_x <- read_rds("simulations/vary_x/null_design_quantrans/data-agg/all_data_wpd_N01.rds")

vary_all <- read_rds("simulations/vary_all/raw/data-agg/all_data_wpd_N01.rds")

vary_facet <- read_rds("simulations/vary_facet/raw/data-agg/all_data_wpd_N01.rds")

all_design <- bind_rows(vary_facet, vary_x, vary_all, .id = "design") %>% 
  mutate(design = case_when(
    design=="1" ~ "vary_facet",
    design=="2" ~ "vary_x",
    design=="3" ~ "vary_all",
    TRUE ~ as.character(design)                                                                 ))

all_design %>% 
  ggplot() +
  geom_histogram(aes(x=value, fill = design), 
                 alpha = 0.7) +
  scale_fill_brewer(palette = "Dark2")  +
  facet_wrap(~w, labeller = "label_both")
```


<!-- How value of lambda changes with increasing omega and mean for fixed nx, nfacet and standard deviation? -->

<!-- # ```{r lambda-omega-mean, eval = FALSE} -->
<!-- # knitr::include_graphics(here::here("simulations/result_report/lambda_omega_mean_3_2.png")) -->
<!-- # ``` -->
<!-- #  -->
<!-- # How value of lambda changes with increasing omega and sd for fixed nx, nfacet and mean? -->
<!-- #  -->
<!-- # ```{r lambda-omega-sd, eval = FALSE} -->
<!-- # knitr::include_graphics(here::here("simulations/result_report/lambda_omega_sd_3_2.png")) -->
<!-- # ``` -->
<!-- #  -->
<!-- # ```{r lamba-omega-alternate-design} -->
<!-- # knitr::include_graphics((here::here("simulations/result_report/wpd_alterate_designs.png"))) -->
<!-- # ``` -->


 <!-- Distribution across facet and x categories -->
<!-- ### Need for normalisation -->


### Discussion

The distribution of wpd is different for different levels of facets and x-axis levels. This is because the statistic maximum which is used to define wpd is affected by the number of categories. The measure would have higher values if $C_i$ or $C_j$ has higher levels. However, we would ideally want a higher value of the measure only if there is significant difference between distributions across facet or x-axis categories, and not because the number of categories are higher. Therefore, in order to compare wpd across different combinations of facet and x-axis levels, we need to eliminate the impact of different levels of the facets and x-axis first and get a normalized measure. Henceforth we call the measure discussed as $wpd_{raw}$ and the normalised measure as $wpd_{norm}$. The measure $wpd_{norm}$ could potentially lead to comparison of the measure across different panels and also identifying only the interesting panels from a dataset.


<!-- In Figures \ref{fig:dist-across-facets} and \ref{fig:dist-across-x}, both the cyclic granularities $C_i$ and $C_j$ are considered such that their levels vary in the range $(2, 5,7 ,9, 14, 21, 30, 45)$. Each of these combinations is considered a panel for each of which $MMPD_{raw}$ has been constructed $100$ times to compute the distribution. <!--More specifically, Figure \ref{fig:mean-sd-max} shows the marginal contribution of increasing levels of $C_i$ and $C_j$ on distribution of $MMPD_raw$. This shows that with the increase in the number of levels of $C_i$, the location of the distribution shift rightward, whereas for increasing x-axis levels, the scale of the distribution decreases.--> 


```{r hist-nx-nfacet, eval = FALSE}
knitr::include_graphics(here::here("simulations/result_report/hist_nxbyfacet.png"))
```

```{r dist-across-facets, fig.cap = "Distribution of $MMPD_{raw}$ for different facet levels are shown. The location of the distribution shifts rightwards implying that as the number of facets increase, it is more likely that a higher value of $MMPD_{raw}$ will be obtained.", eval = FALSE}
here::here()
knitr::include_graphics(here::here("simulations/result_report","nx_by_facet_raw.png"))
```


<!-- # ```{r dist-across-facets, fig.cap = "Distribution of $MMPD_{raw}$ for different facet levels are shown. The location of the distribution shifts rightwards implying that as the number of facets increase, it is more likely that a higher value of $MMPD_{raw}$ will be obtained. "} -->
<!-- # mmpd_raw = read_rds("../hakear-drake/data/data_all23457914n.rds")  -->
<!-- # mmpd_xmore = read_rds("../hakear-drake/data/data_all213045x.rds")  -->
<!-- # mmpd_fmore = read_rds("../hakear-drake/data/data_all_213045f_allx.rds") -->
<!-- #  -->
<!-- # data_all = bind_rows(mmpd_raw, mmpd_xmore) -->
<!-- #  -->
<!-- # data_long = data_all %>% pivot_longer(c(1:2), names_to = "category", values_to = "levels") -->
<!-- #  -->
<!-- # g1 <- data_all %>%  -->
<!-- #   filter(!(nx %in% c(3, 4))) %>%  -->
<!-- #   ggplot() + -->
<!-- #   ggridges::geom_density_ridges(aes(x = raw_mmpd,  -->
<!-- #                                     y = as.factor(nfacet))) + -->
<!-- #   facet_wrap(~nx, nrow = 2) -->
<!-- # g1 -->
<!-- # ``` -->

```{r dist-across-x, fig.cap = "Distribution of $MMPD_{raw}$ for different x levels are shown. The scale of the distribution becomes less and less implying that as the number of x levels increase, it is more likely that a higher value of $MMPD_{raw}$ will be obtained as the spread of the distribution decreases. ", eval = FALSE}
knitr::include_graphics(here::here("simulations/result_report/","nfacet_by_nx_raw.png"))
```


<!-- # ```{r dist-across-x, fig.cap = "Distribution of $MMPD_{raw}$ for different x levels are shown. The scale of the distribution becomes less and less implying that as the number of x levels increase, it is more likely that a higher value of $MMPD_{raw}$ will be obtained as the spread of the distribution decreases. "} -->
<!-- # g2 <- data_all %>%  -->
<!-- #   filter(nfacet<=14, nfacet!=3) %>%  -->
<!-- #   ggplot() + -->
<!-- #   geom_boxplot(aes(y = raw_mmpd,  -->
<!-- #                                     x = as.factor(nx))) + -->
<!-- #   facet_wrap(~nfacet) + coord_flip() -->
<!-- #  -->
<!-- # #  hist_plot = data_all %>%  -->
<!-- # #       ggplot() + -->
<!-- # #       geom_density(aes(x = raw_mmpd), fill = "blue") + -->
<!-- # #       facet_grid(nx~nfacet) -->
<!-- # # hist_plot -->
<!-- # g2 -->
<!-- # ``` -->


<!-- both mean and standard deviation of the distribution of maximum and median varies for different sample sizes ($n$). There is a rightward shift in the location and decrease in scale with increasing $n$. -->

# Normalisation

In an attempt to make the densities \ref{fig:hist_plot} same across different levels, we want to start by making their scale and location same. In that regard, we shuffle the data multiple times and compute the sampling distribution of  for each combination of facet and x-axis levels. 

The null hypothesis is that the two cyclic granularities do not differ on the outcome (i.e., that the outcome is observed independently of treatment assignment). When we permute the outcome values during the test, we therefore see all of the possible alternative treatment assignments we could have had and where the mean-difference in our observed data falls relative to all of the differences we could have seen if the outcome was independent of treatment assignment. While a permutation test requires that we see all possible permutations of the data (which can become quite large), we can easily conduct “approximate permutation tests” by simply conducting a vary large number of resamples. That process should, in expectation, approximate the permutation distribution.

Finally, we run some simulation experiments to see if normalisation works. If normalisation has worked, it should work for both x levle and facet-levels.

Thus these median maximum pairwise distances need to be normalized for different harmonies in a way that eliminates the effect of different levels, consequently enabling comparison across different harmonies. The Fisher–Tippett–Gnedenko theorem in the field of Extreme Value Theory states that the maximum of a sample of iid random variables after proper re-normalization can converge in distribution to only one of Weibull, Gumbel or Freschet distribution, independent of the underlying data or process.

```{r normal01-norm, fig.cap="Density plots of normalised wpd is shown for Normal(0,1) distribution. The mean and sd of the distribution looks almost similar for different facet and x-axis categories.", fig.pos="h"}

knitr::include_graphics(here::here("simulations/norm/null_design_quantrans_nperm/figs/nxbyfacet_density_wpd_N01.png"))
```


## Methodology

The mean and sd for each combination of facet and x levels could be computed by shuffling the data repeatedly and obtaining the distribution of $MMPD_{raw}$ for different combinations. If $MMPD_{raw}$ is then adjusted by the location and scale of this distribution, we could assume that the distribution of the resultant $MMPD_{norm}$ will have same distribution across different combinations of x and facet levels. All data is repeatedly shuffled $nperm$ times in random manner to obtain the measure $MMPD_{raw}$. Then the $MMPD_{norm}$ is obtained by scaling the observed value by the mean and sd of the distribution of $MMPD_{raw}$ obtained from the permuted data.

\noindent Step 7 in the Algorithm defined in Section \ref{sec:} need to be revised in order to compute $MMPD_{norm}$ instead of $MMPD_{raw}$. Step 1-6 stays the same. The entire algorithm will have to repeated for all harmony pairs considered in the context.

A simulation study is conducted to see if this methodology is working.

## Null design

## Alternate designs


The behavior of the measure is monitored and understood through simulation experiments. A single simulation consisting of computational operations on a panel generating MMPD the value of which represents to what extent a pair of cyclic granularities would be interesting when displayed in the design. In comparing different simulation runs, we distinguish between different distributions and simulation scenarios (also iterations may be).

### Simulated designs

 D1. Same distribution of the measured variable across all x-axis and facet categories
 D2. Different distribution across facet categories but same across x-axis categories
 D3. Different distribution across x-axis categories but same across facet categories
 D4. Different across both x-axis and facet categories 
 
Each of these case scenarios tried against Normal and a non-normal (Gamma) distribution to check if underlying distribution has a role to play.

### Environment

R version 4.0.1 (2020-06-06) is used with platform: x86_64-apple-darwin17.0 (64-bit) running under: macOS Mojave 10.14.6


## Sample size

How smaller or different sample size play a role in the distribution of the measure.

## Number of permutations

Find the number of permutations which are sufficient for consistent estimation of mean and standard deviation

